{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目標：利用openpose和神經網路辨識T-POSE和DAB姿勢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 組員：\n",
    "# 應數一 108701011 游能澤\n",
    "# 應數一 108701034 柯里橫\n",
    "# 應數一 108701018 池欣霓\n",
    "# 應數一 108701019 許辰宇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分工：\n",
    "# 構想與建設環境：游能澤、柯里橫\n",
    "# 程式建構：柯里橫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 由於一直無法使用pyopenpose函式，無法透過\n",
    "# openpose取得樣本，只好找別人做好的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 到https://github.com/burningion/dab-and-tpose-controlled-lights/tree/master/data\n",
    "# 載下作者生成好的數據，開個data資料夾放進去\n",
    "# dabs.npy tposes.npy other.npy\n",
    "# more-dabs.npy more-tposes.npy more-other.npy\n",
    "# test-dabs.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 這幾個檔案是以numpy儲存的二進制文件\n",
    "# 裡頭有我們需要的特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dabDataset = np.load('data/dabs.npy')\n",
    "tposeDataset = np.load('data/tposes.npy')\n",
    "otherDataset = np.load('data/other.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8832416e+02, 2.9433704e+02, 7.2265184e-01],\n",
       "       [5.8239331e+02, 3.5126093e+02, 8.0205584e-01],\n",
       "       [5.0984329e+02, 3.4919385e+02, 7.5316119e-01],\n",
       "       [4.1784265e+02, 3.1985785e+02, 8.1164622e-01],\n",
       "       [3.6101605e+02, 2.9243521e+02, 8.0296052e-01],\n",
       "       [6.5091376e+02, 3.6097537e+02, 6.4161348e-01],\n",
       "       [6.3724268e+02, 2.7274924e+02, 7.8188539e-01],\n",
       "       [4.9614203e+02, 2.4154723e+02, 8.3243752e-01],\n",
       "       [5.4315808e+02, 6.4114813e+02, 4.4807938e-01],\n",
       "       [4.8636816e+02, 6.2938318e+02, 3.6906898e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [6.0191382e+02, 6.4702966e+02, 3.8946095e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [5.7648334e+02, 2.7475522e+02, 6.1822432e-01],\n",
       "       [6.0389270e+02, 2.8454663e+02, 4.1854110e-01],\n",
       "       [5.5686536e+02, 2.6891223e+02, 2.7014270e-01],\n",
       "       [6.1959991e+02, 2.9243130e+02, 7.0310913e-02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 25, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding our Labels\n",
    "# Our labels come from the [BODY_25 Pose Output format](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/output.md#pose-output-format-body_25) available at the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Nose\", \"Neck\", \"RShoulder\", \"RElbow\", \"RWrist\", \"LShoulder\", \"LElbow\",\n",
    " \"LWrist\", \"MidHip\", \"RHip\", \"RKnee\", \"RAnkle\", \"LHip\", \"LKnee\", \"LAnkle\",\n",
    " \"REye\", \"LEye\", \"REar\", \"LEar\", \"LBigToe\", \"LSmallToe\", \"LHeel\", \"RBigToe\",\n",
    " \"RSmallToe\", \"RHeel\", \"Background\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看數據有三個維度分別是X、Ｙ、Confidence，不需要用到Confidence。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "properLabels = []\n",
    "for label in labels:\n",
    "    properLabels.append(label + 'X')\n",
    "    properLabels.append(label + 'Y')\n",
    "    properLabels.append(label + 'Confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/dabs.csv', 'w+') as dabcsv:\n",
    "    dabwriter = csv.writer(dabcsv, delimiter=',')\n",
    "    dabwriter.writerow(properLabels)\n",
    "    for cell in dabDataset:\n",
    "        dabwriter.writerow(cell.flatten())\n",
    "        \n",
    "with open('data/tposes.csv', 'w+') as tposecsv:\n",
    "    tposewriter = csv.writer(tposecsv, delimiter=',')\n",
    "    tposewriter.writerow(properLabels)\n",
    "    for cell in tposeDataset:\n",
    "        tposewriter.writerow(cell.flatten())\n",
    "        \n",
    "with open('data/other.csv', 'w+') as othercsv:\n",
    "    otherwriter = csv.writer(othercsv, delimiter=',')\n",
    "    otherwriter.writerow(properLabels)\n",
    "    for cell in otherDataset:\n",
    "        otherwriter.writerow(cell.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用CSV檔看訓練資料略少，但還是試著訓練看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Labeled Dataset for Training and Testing\n",
    "# We'll use 0 for other poses, 1 for dabs, and 2 for tposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "56 total examples for training.\n"
     ]
    }
   ],
   "source": [
    "labels = np.zeros(len(otherDataset))\n",
    "labels = np.append(labels, np.full((len(dabDataset)), 1))\n",
    "labels = np.append(labels, np.full((len(tposeDataset)), 2))\n",
    "print(labels)\n",
    "print(\"%i total examples for training.\" % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[488.3213     147.51425      0.83340967]\n",
      "  [494.22372    284.5734       0.8012297 ]\n",
      "  [386.4863     270.83716      0.66853976]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[515.7737     112.18818      0.83487195]\n",
      "  [478.48004    274.7029       0.8005627 ]\n",
      "  [368.77948    257.2105       0.6782713 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[547.1316     112.15151      0.79948723]\n",
      "  [464.79065    268.88403      0.73338044]\n",
      "  [360.98135    243.43745      0.62600124]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[509.97504    257.06958      0.892523  ]\n",
      "  [460.9663     351.17117      0.7867987 ]\n",
      "  [372.75305    333.54434      0.6111988 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[554.90063    286.50854      0.88104486]\n",
      "  [496.1236     374.6841       0.7804795 ]\n",
      "  [415.7811     353.13678      0.74092144]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[570.5084     268.88422      0.855286  ]\n",
      "  [509.95016    370.85114      0.7977039 ]\n",
      "  [431.50925    353.08978      0.7552353 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.append(otherDataset, dabDataset, axis=0)\n",
    "dataset = np.append(dataset, tposeDataset, axis=0)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 25, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讓數值變成0~1之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11524551, 0.22232297, 0.21159153, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.08764701, 0.21461165, 0.2009457 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.08761837, 0.21006565, 0.19018552, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.20083562, 0.2743525 , 0.26058152, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.2238348 , 0.29272196, 0.27588812, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.2100658 , 0.28972745, 0.2758514 , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:,:,1] / 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(dataset, labels)\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y, 3)\n",
    "print(y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 架設神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.88321289e+02, 1.47514252e+02, 8.33409667e-01],\n",
       "       [4.94223724e+02, 2.84573395e+02, 8.01229715e-01],\n",
       "       [3.86486298e+02, 2.70837158e+02, 6.68539762e-01],\n",
       "       [3.37498718e+02, 4.31440033e+02, 8.06459844e-01],\n",
       "       [2.76727325e+02, 5.92155334e+02, 6.95721209e-01],\n",
       "       [6.01926575e+02, 2.96297577e+02, 6.77372575e-01],\n",
       "       [6.17621460e+02, 4.47154175e+02, 8.15527081e-01],\n",
       "       [6.33207092e+02, 6.13721497e+02, 7.50288665e-01],\n",
       "       [4.49166534e+02, 6.23515259e+02, 3.33123893e-01],\n",
       "       [3.68768433e+02, 6.15664124e+02, 2.96909660e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.29464417e+02, 6.35266663e+02, 3.00662249e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.72626495e+02, 1.25848732e+02, 7.93599010e-01],\n",
       "       [5.09897217e+02, 1.25915306e+02, 8.75047982e-01],\n",
       "       [4.47158661e+02, 1.31820786e+02, 9.30340886e-01],\n",
       "       [5.51045410e+02, 1.35715973e+02, 8.41542602e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(len(X), 75)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "56/56 [==============================] - 1s 12ms/step - loss: 255.9729 - accuracy: 0.2679\n",
      "Epoch 2/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 2857.6001 - accuracy: 0.2679\n",
      "Epoch 3/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 25834.7285 - accuracy: 0.2679\n",
      "Epoch 4/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 13238.0859 - accuracy: 0.4643\n",
      "Epoch 5/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 1.0981 - accuracy: 0.3750\n",
      "Epoch 6/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 14.2869 - accuracy: 0.4464\n",
      "Epoch 7/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0957 - accuracy: 0.4107\n",
      "Epoch 8/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.0938 - accuracy: 0.4107\n",
      "Epoch 9/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0922 - accuracy: 0.4107\n",
      "Epoch 10/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 1.0937 - accuracy: 0.3571\n",
      "Epoch 11/200\n",
      "56/56 [==============================] - 0s 96us/step - loss: 1.0930 - accuracy: 0.4643\n",
      "Epoch 12/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0891 - accuracy: 0.4821\n",
      "Epoch 13/200\n",
      "56/56 [==============================] - 0s 96us/step - loss: 1.0855 - accuracy: 0.4643\n",
      "Epoch 14/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0875 - accuracy: 0.3571\n",
      "Epoch 15/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.0790 - accuracy: 0.4286\n",
      "Epoch 16/200\n",
      "56/56 [==============================] - 0s 94us/step - loss: 1.0978 - accuracy: 0.3393\n",
      "Epoch 17/200\n",
      "56/56 [==============================] - 0s 96us/step - loss: 1.0874 - accuracy: 0.4821\n",
      "Epoch 18/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.0842 - accuracy: 0.3929\n",
      "Epoch 19/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0856 - accuracy: 0.4286\n",
      "Epoch 20/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.0782 - accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "56/56 [==============================] - 0s 96us/step - loss: 1.0673 - accuracy: 0.5179\n",
      "Epoch 22/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.0905 - accuracy: 0.4286\n",
      "Epoch 23/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.0732 - accuracy: 0.4107\n",
      "Epoch 24/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.0736 - accuracy: 0.3750\n",
      "Epoch 25/200\n",
      "56/56 [==============================] - 0s 94us/step - loss: 1.0744 - accuracy: 0.4286\n",
      "Epoch 26/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0548 - accuracy: 0.4464\n",
      "Epoch 27/200\n",
      "56/56 [==============================] - 0s 94us/step - loss: 1.0707 - accuracy: 0.4107\n",
      "Epoch 28/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.0915 - accuracy: 0.4464\n",
      "Epoch 29/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.1089 - accuracy: 0.4107\n",
      "Epoch 30/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0929 - accuracy: 0.4464\n",
      "Epoch 31/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0460 - accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0972 - accuracy: 0.4464\n",
      "Epoch 33/200\n",
      "56/56 [==============================] - 0s 97us/step - loss: 1.0857 - accuracy: 0.4821\n",
      "Epoch 34/200\n",
      "56/56 [==============================] - 0s 96us/step - loss: 1.0636 - accuracy: 0.4643\n",
      "Epoch 35/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0983 - accuracy: 0.4643\n",
      "Epoch 36/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0684 - accuracy: 0.4643\n",
      "Epoch 37/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0695 - accuracy: 0.4643\n",
      "Epoch 38/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0782 - accuracy: 0.4643\n",
      "Epoch 39/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0623 - accuracy: 0.4643\n",
      "Epoch 40/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0992 - accuracy: 0.4643\n",
      "Epoch 41/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0719 - accuracy: 0.4643\n",
      "Epoch 42/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0782 - accuracy: 0.4643\n",
      "Epoch 43/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.0920 - accuracy: 0.4643\n",
      "Epoch 44/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0747 - accuracy: 0.4643\n",
      "Epoch 45/200\n",
      "56/56 [==============================] - 0s 97us/step - loss: 1.0764 - accuracy: 0.4643\n",
      "Epoch 46/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0603 - accuracy: 0.4643\n",
      "Epoch 47/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.0714 - accuracy: 0.4643\n",
      "Epoch 48/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 1.1094 - accuracy: 0.4643\n",
      "Epoch 49/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0754 - accuracy: 0.4643\n",
      "Epoch 50/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0962 - accuracy: 0.4643\n",
      "Epoch 51/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0735 - accuracy: 0.4643\n",
      "Epoch 52/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0974 - accuracy: 0.4643\n",
      "Epoch 53/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0848 - accuracy: 0.4643\n",
      "Epoch 54/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0680 - accuracy: 0.4643\n",
      "Epoch 55/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0649 - accuracy: 0.4643\n",
      "Epoch 56/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.0876 - accuracy: 0.4643\n",
      "Epoch 57/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0777 - accuracy: 0.4643\n",
      "Epoch 58/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0910 - accuracy: 0.4643\n",
      "Epoch 59/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0677 - accuracy: 0.4643\n",
      "Epoch 60/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0919 - accuracy: 0.4643\n",
      "Epoch 61/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0581 - accuracy: 0.4643\n",
      "Epoch 62/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.1035 - accuracy: 0.4643\n",
      "Epoch 63/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0767 - accuracy: 0.4643\n",
      "Epoch 64/200\n",
      "56/56 [==============================] - 0s 97us/step - loss: 1.0614 - accuracy: 0.4643\n",
      "Epoch 65/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.0575 - accuracy: 0.4643\n",
      "Epoch 66/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0914 - accuracy: 0.4643\n",
      "Epoch 67/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0767 - accuracy: 0.4643\n",
      "Epoch 68/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0862 - accuracy: 0.4643\n",
      "Epoch 69/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 1.0760 - accuracy: 0.4643\n",
      "Epoch 70/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0603 - accuracy: 0.4643\n",
      "Epoch 71/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0743 - accuracy: 0.4643\n",
      "Epoch 72/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0828 - accuracy: 0.4643\n",
      "Epoch 73/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0760 - accuracy: 0.4643\n",
      "Epoch 74/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0783 - accuracy: 0.4643\n",
      "Epoch 75/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0657 - accuracy: 0.4643\n",
      "Epoch 76/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0701 - accuracy: 0.4643\n",
      "Epoch 77/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0673 - accuracy: 0.4643\n",
      "Epoch 78/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 1.0700 - accuracy: 0.4643\n",
      "Epoch 79/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.1062 - accuracy: 0.4643\n",
      "Epoch 80/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.1011 - accuracy: 0.4643\n",
      "Epoch 81/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.1018 - accuracy: 0.4643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0571 - accuracy: 0.4643\n",
      "Epoch 83/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.1010 - accuracy: 0.4643\n",
      "Epoch 84/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 1.0722 - accuracy: 0.4643\n",
      "Epoch 85/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 1.0837 - accuracy: 0.4643\n",
      "Epoch 86/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0637 - accuracy: 0.4643\n",
      "Epoch 87/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 1.0577 - accuracy: 0.4643\n",
      "Epoch 88/200\n",
      "56/56 [==============================] - 0s 127us/step - loss: 1.0952 - accuracy: 0.4643\n",
      "Epoch 89/200\n",
      "56/56 [==============================] - 0s 124us/step - loss: 1.0825 - accuracy: 0.4643\n",
      "Epoch 90/200\n",
      "56/56 [==============================] - 0s 135us/step - loss: 1.0684 - accuracy: 0.4643\n",
      "Epoch 91/200\n",
      "56/56 [==============================] - 0s 126us/step - loss: 1.0905 - accuracy: 0.4643\n",
      "Epoch 92/200\n",
      "56/56 [==============================] - 0s 138us/step - loss: 1.0660 - accuracy: 0.4643\n",
      "Epoch 93/200\n",
      "56/56 [==============================] - 0s 129us/step - loss: 1.0964 - accuracy: 0.4643\n",
      "Epoch 94/200\n",
      "56/56 [==============================] - 0s 151us/step - loss: 1.0880 - accuracy: 0.4643\n",
      "Epoch 95/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0884 - accuracy: 0.4643\n",
      "Epoch 96/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.0883 - accuracy: 0.4643\n",
      "Epoch 97/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0915 - accuracy: 0.4643\n",
      "Epoch 98/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0798 - accuracy: 0.4643\n",
      "Epoch 99/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 1.0772 - accuracy: 0.4643\n",
      "Epoch 100/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0637 - accuracy: 0.4643\n",
      "Epoch 101/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0910 - accuracy: 0.4643\n",
      "Epoch 102/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0764 - accuracy: 0.4643\n",
      "Epoch 103/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 1.0744 - accuracy: 0.4643\n",
      "Epoch 104/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0934 - accuracy: 0.4643\n",
      "Epoch 105/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0797 - accuracy: 0.4643\n",
      "Epoch 106/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 1.0808 - accuracy: 0.4643\n",
      "Epoch 107/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 1.0986 - accuracy: 0.4643\n",
      "Epoch 108/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 1.0688 - accuracy: 0.4643\n",
      "Epoch 109/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 1.0632 - accuracy: 0.4643\n",
      "Epoch 110/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0748 - accuracy: 0.4643\n",
      "Epoch 111/200\n",
      "56/56 [==============================] - 0s 123us/step - loss: 1.0734 - accuracy: 0.4643\n",
      "Epoch 112/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0900 - accuracy: 0.4643\n",
      "Epoch 113/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 1.0909 - accuracy: 0.4643\n",
      "Epoch 114/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 1.0500 - accuracy: 0.4643\n",
      "Epoch 115/200\n",
      "56/56 [==============================] - 0s 126us/step - loss: 1.0886 - accuracy: 0.4643\n",
      "Epoch 116/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 1.0721 - accuracy: 0.4643\n",
      "Epoch 117/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 1.0737 - accuracy: 0.4643\n",
      "Epoch 118/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.1023 - accuracy: 0.4643\n",
      "Epoch 119/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.0712 - accuracy: 0.4643\n",
      "Epoch 120/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 1.0916 - accuracy: 0.4643\n",
      "Epoch 121/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 1.0843 - accuracy: 0.4643\n",
      "Epoch 122/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 1.0691 - accuracy: 0.4643\n",
      "Epoch 123/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0639 - accuracy: 0.4643\n",
      "Epoch 124/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0778 - accuracy: 0.4643\n",
      "Epoch 125/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0681 - accuracy: 0.4643\n",
      "Epoch 126/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0742 - accuracy: 0.4643\n",
      "Epoch 127/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0872 - accuracy: 0.4643\n",
      "Epoch 128/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.0564 - accuracy: 0.4643\n",
      "Epoch 129/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0771 - accuracy: 0.4643\n",
      "Epoch 130/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0692 - accuracy: 0.4643\n",
      "Epoch 131/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 1.0848 - accuracy: 0.4643\n",
      "Epoch 132/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0832 - accuracy: 0.4643\n",
      "Epoch 133/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 1.0806 - accuracy: 0.4643\n",
      "Epoch 134/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0748 - accuracy: 0.4643\n",
      "Epoch 135/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0679 - accuracy: 0.4643\n",
      "Epoch 136/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0936 - accuracy: 0.4643\n",
      "Epoch 137/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0780 - accuracy: 0.4643\n",
      "Epoch 138/200\n",
      "56/56 [==============================] - 0s 117us/step - loss: 1.1015 - accuracy: 0.4643\n",
      "Epoch 139/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.0783 - accuracy: 0.4643\n",
      "Epoch 140/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.0598 - accuracy: 0.4643\n",
      "Epoch 141/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0732 - accuracy: 0.4643\n",
      "Epoch 142/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 1.0916 - accuracy: 0.4643\n",
      "Epoch 143/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0714 - accuracy: 0.4643\n",
      "Epoch 144/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.0625 - accuracy: 0.4643\n",
      "Epoch 145/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0764 - accuracy: 0.4643\n",
      "Epoch 146/200\n",
      "56/56 [==============================] - 0s 96us/step - loss: 1.0646 - accuracy: 0.4643\n",
      "Epoch 147/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0677 - accuracy: 0.4643\n",
      "Epoch 148/200\n",
      "56/56 [==============================] - 0s 96us/step - loss: 1.0785 - accuracy: 0.4643\n",
      "Epoch 149/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0812 - accuracy: 0.4643\n",
      "Epoch 150/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0853 - accuracy: 0.4643\n",
      "Epoch 151/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0792 - accuracy: 0.4643\n",
      "Epoch 152/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0670 - accuracy: 0.4643\n",
      "Epoch 153/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0541 - accuracy: 0.4643\n",
      "Epoch 154/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0927 - accuracy: 0.4643\n",
      "Epoch 155/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 1.0711 - accuracy: 0.4643\n",
      "Epoch 156/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.1018 - accuracy: 0.4643\n",
      "Epoch 157/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0898 - accuracy: 0.4643\n",
      "Epoch 158/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 1.0698 - accuracy: 0.4643\n",
      "Epoch 159/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0758 - accuracy: 0.4643\n",
      "Epoch 160/200\n",
      "56/56 [==============================] - 0s 96us/step - loss: 1.0630 - accuracy: 0.4643\n",
      "Epoch 161/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0717 - accuracy: 0.4643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200\n",
      "56/56 [==============================] - 0s 97us/step - loss: 1.0634 - accuracy: 0.4643\n",
      "Epoch 163/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0649 - accuracy: 0.4643\n",
      "Epoch 164/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0903 - accuracy: 0.4643\n",
      "Epoch 165/200\n",
      "56/56 [==============================] - 0s 98us/step - loss: 1.1139 - accuracy: 0.4643\n",
      "Epoch 166/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 1.0757 - accuracy: 0.4643\n",
      "Epoch 167/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0862 - accuracy: 0.4643\n",
      "Epoch 168/200\n",
      "56/56 [==============================] - 0s 140us/step - loss: 1.0654 - accuracy: 0.4643\n",
      "Epoch 169/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 1.0687 - accuracy: 0.4643\n",
      "Epoch 170/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 1.0751 - accuracy: 0.4643\n",
      "Epoch 171/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0796 - accuracy: 0.4643\n",
      "Epoch 172/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0635 - accuracy: 0.4643\n",
      "Epoch 173/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0655 - accuracy: 0.4643\n",
      "Epoch 174/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 1.0729 - accuracy: 0.4643\n",
      "Epoch 175/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0867 - accuracy: 0.4643\n",
      "Epoch 176/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 1.0848 - accuracy: 0.4643\n",
      "Epoch 177/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0656 - accuracy: 0.4643\n",
      "Epoch 178/200\n",
      "56/56 [==============================] - 0s 125us/step - loss: 1.0871 - accuracy: 0.4643\n",
      "Epoch 179/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0720 - accuracy: 0.4643\n",
      "Epoch 180/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0682 - accuracy: 0.4643\n",
      "Epoch 181/200\n",
      "56/56 [==============================] - 0s 99us/step - loss: 1.0820 - accuracy: 0.4643\n",
      "Epoch 182/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 1.0623 - accuracy: 0.4643\n",
      "Epoch 183/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 1.0851 - accuracy: 0.4643\n",
      "Epoch 184/200\n",
      "56/56 [==============================] - 0s 122us/step - loss: 1.0700 - accuracy: 0.4643\n",
      "Epoch 185/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0836 - accuracy: 0.4643\n",
      "Epoch 186/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.0693 - accuracy: 0.4643\n",
      "Epoch 187/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.0640 - accuracy: 0.4643\n",
      "Epoch 188/200\n",
      "56/56 [==============================] - 0s 125us/step - loss: 1.0492 - accuracy: 0.4643\n",
      "Epoch 189/200\n",
      "56/56 [==============================] - 0s 127us/step - loss: 1.0572 - accuracy: 0.4643\n",
      "Epoch 190/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 1.0841 - accuracy: 0.4643\n",
      "Epoch 191/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 1.0605 - accuracy: 0.4643\n",
      "Epoch 192/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 1.0653 - accuracy: 0.4643\n",
      "Epoch 193/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 1.0871 - accuracy: 0.4643\n",
      "Epoch 194/200\n",
      "56/56 [==============================] - 0s 130us/step - loss: 1.0332 - accuracy: 0.4643\n",
      "Epoch 195/200\n",
      "56/56 [==============================] - 0s 101us/step - loss: 1.0780 - accuracy: 0.4643\n",
      "Epoch 196/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 1.0940 - accuracy: 0.4643\n",
      "Epoch 197/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 1.0906 - accuracy: 0.4643\n",
      "Epoch 198/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 1.0547 - accuracy: 0.4643\n",
      "Epoch 199/200\n",
      "56/56 [==============================] - 0s 102us/step - loss: 1.0798 - accuracy: 0.4643\n",
      "Epoch 200/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 1.0700 - accuracy: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8a07b043c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_shape = (75,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "model.compile(optimizer = SGD(lr = 0.005),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(X, y, epochs = 200, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up data further¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy too low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 25, 3)\n",
      "(56, 25, 2)\n",
      "(56, 50)\n"
     ]
    }
   ],
   "source": [
    "X, y = shuffle(dataset, labels)\n",
    "y = to_categorical(y, 3)\n",
    "print(X.shape)\n",
    "X[:,:,0] = X[:,:,0] / 720 \n",
    "X[:,:,1] = X[:,:,1] / 1280\n",
    "X = X[:,:,:2]\n",
    "print(X.shape)\n",
    "X = X.reshape(56, 50)     \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "56/56 [==============================] - 1s 20ms/step - loss: 1.2190 - accuracy: 0.2679\n",
      "Epoch 2/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.1808 - accuracy: 0.3571\n",
      "Epoch 3/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 1.1225 - accuracy: 0.3571\n",
      "Epoch 4/200\n",
      "56/56 [==============================] - 0s 119us/step - loss: 1.1092 - accuracy: 0.4107\n",
      "Epoch 5/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 1.0194 - accuracy: 0.4464\n",
      "Epoch 6/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 1.0504 - accuracy: 0.4286\n",
      "Epoch 7/200\n",
      "56/56 [==============================] - 0s 130us/step - loss: 1.0893 - accuracy: 0.3750\n",
      "Epoch 8/200\n",
      "56/56 [==============================] - 0s 124us/step - loss: 1.0746 - accuracy: 0.3929\n",
      "Epoch 9/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 1.0616 - accuracy: 0.5000\n",
      "Epoch 10/200\n",
      "56/56 [==============================] - 0s 129us/step - loss: 1.1203 - accuracy: 0.3929\n",
      "Epoch 11/200\n",
      "56/56 [==============================] - 0s 128us/step - loss: 1.1162 - accuracy: 0.3750\n",
      "Epoch 12/200\n",
      "56/56 [==============================] - 0s 123us/step - loss: 1.0734 - accuracy: 0.4107\n",
      "Epoch 13/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 1.0604 - accuracy: 0.4286\n",
      "Epoch 14/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0990 - accuracy: 0.3750\n",
      "Epoch 15/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 1.1341 - accuracy: 0.3393\n",
      "Epoch 16/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0356 - accuracy: 0.5000\n",
      "Epoch 17/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 1.0365 - accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 1.0269 - accuracy: 0.5714\n",
      "Epoch 19/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 1.0821 - accuracy: 0.3929\n",
      "Epoch 20/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 1.0442 - accuracy: 0.4286\n",
      "Epoch 21/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 1.0710 - accuracy: 0.4107\n",
      "Epoch 22/200\n",
      "56/56 [==============================] - 0s 119us/step - loss: 1.0370 - accuracy: 0.4643\n",
      "Epoch 23/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 1.0326 - accuracy: 0.4821\n",
      "Epoch 24/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 1.0861 - accuracy: 0.4464\n",
      "Epoch 25/200\n",
      "56/56 [==============================] - 0s 121us/step - loss: 1.0087 - accuracy: 0.5179\n",
      "Epoch 26/200\n",
      "56/56 [==============================] - 0s 128us/step - loss: 1.0477 - accuracy: 0.4286\n",
      "Epoch 27/200\n",
      "56/56 [==============================] - 0s 125us/step - loss: 1.0565 - accuracy: 0.4286\n",
      "Epoch 28/200\n",
      "56/56 [==============================] - 0s 130us/step - loss: 1.0354 - accuracy: 0.5536\n",
      "Epoch 29/200\n",
      "56/56 [==============================] - 0s 127us/step - loss: 1.0193 - accuracy: 0.5714\n",
      "Epoch 30/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 1.0021 - accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "56/56 [==============================] - 0s 119us/step - loss: 1.0636 - accuracy: 0.4107\n",
      "Epoch 32/200\n",
      "56/56 [==============================] - 0s 128us/step - loss: 0.9487 - accuracy: 0.5357\n",
      "Epoch 33/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.9696 - accuracy: 0.5714\n",
      "Epoch 34/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 1.0286 - accuracy: 0.5536\n",
      "Epoch 35/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 0.9896 - accuracy: 0.5357\n",
      "Epoch 36/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.9850 - accuracy: 0.6071\n",
      "Epoch 37/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 1.0411 - accuracy: 0.4643\n",
      "Epoch 38/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 0.9994 - accuracy: 0.4821\n",
      "Epoch 39/200\n",
      "56/56 [==============================] - 0s 121us/step - loss: 0.9706 - accuracy: 0.5893\n",
      "Epoch 40/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.9751 - accuracy: 0.5357\n",
      "Epoch 41/200\n",
      "56/56 [==============================] - 0s 129us/step - loss: 0.9408 - accuracy: 0.5357\n",
      "Epoch 42/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.9681 - accuracy: 0.5536\n",
      "Epoch 43/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.9505 - accuracy: 0.5536\n",
      "Epoch 44/200\n",
      "56/56 [==============================] - 0s 125us/step - loss: 0.9648 - accuracy: 0.5357\n",
      "Epoch 45/200\n",
      "56/56 [==============================] - 0s 119us/step - loss: 0.9471 - accuracy: 0.5714\n",
      "Epoch 46/200\n",
      "56/56 [==============================] - 0s 119us/step - loss: 0.9861 - accuracy: 0.4821\n",
      "Epoch 47/200\n",
      "56/56 [==============================] - 0s 131us/step - loss: 0.9619 - accuracy: 0.5714\n",
      "Epoch 48/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 1.0070 - accuracy: 0.5536\n",
      "Epoch 49/200\n",
      "56/56 [==============================] - 0s 137us/step - loss: 0.9483 - accuracy: 0.5179\n",
      "Epoch 50/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 0.9437 - accuracy: 0.6250\n",
      "Epoch 51/200\n",
      "56/56 [==============================] - 0s 117us/step - loss: 0.9219 - accuracy: 0.5893\n",
      "Epoch 52/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.8709 - accuracy: 0.5893\n",
      "Epoch 53/200\n",
      "56/56 [==============================] - 0s 127us/step - loss: 0.9521 - accuracy: 0.5714\n",
      "Epoch 54/200\n",
      "56/56 [==============================] - 0s 126us/step - loss: 0.9068 - accuracy: 0.6964\n",
      "Epoch 55/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.9543 - accuracy: 0.5714\n",
      "Epoch 56/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 0.9734 - accuracy: 0.5357\n",
      "Epoch 57/200\n",
      "56/56 [==============================] - 0s 121us/step - loss: 0.9224 - accuracy: 0.6786\n",
      "Epoch 58/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 0.9428 - accuracy: 0.5357\n",
      "Epoch 59/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.9607 - accuracy: 0.5357\n",
      "Epoch 60/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 0.9676 - accuracy: 0.5000\n",
      "Epoch 61/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.8919 - accuracy: 0.6250\n",
      "Epoch 62/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 0.8762 - accuracy: 0.5357\n",
      "Epoch 63/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.8879 - accuracy: 0.6607\n",
      "Epoch 64/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.8962 - accuracy: 0.5357\n",
      "Epoch 65/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 0.8957 - accuracy: 0.6786\n",
      "Epoch 66/200\n",
      "56/56 [==============================] - 0s 127us/step - loss: 0.8524 - accuracy: 0.6786\n",
      "Epoch 67/200\n",
      "56/56 [==============================] - 0s 119us/step - loss: 0.9028 - accuracy: 0.6071\n",
      "Epoch 68/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 0.9165 - accuracy: 0.5536\n",
      "Epoch 69/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 0.8536 - accuracy: 0.6786\n",
      "Epoch 70/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.8544 - accuracy: 0.6250\n",
      "Epoch 71/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.8600 - accuracy: 0.6429\n",
      "Epoch 72/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 0.9070 - accuracy: 0.5893\n",
      "Epoch 73/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.8364 - accuracy: 0.6964\n",
      "Epoch 74/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.8724 - accuracy: 0.6429\n",
      "Epoch 75/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 0.8530 - accuracy: 0.5893\n",
      "Epoch 76/200\n",
      "56/56 [==============================] - 0s 117us/step - loss: 0.8655 - accuracy: 0.6250\n",
      "Epoch 77/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 0.8740 - accuracy: 0.5893\n",
      "Epoch 78/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.8345 - accuracy: 0.6964\n",
      "Epoch 79/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.8321 - accuracy: 0.6607\n",
      "Epoch 80/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.7999 - accuracy: 0.6964\n",
      "Epoch 81/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.8375 - accuracy: 0.6786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.7739 - accuracy: 0.6964\n",
      "Epoch 83/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.7656 - accuracy: 0.7679\n",
      "Epoch 84/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.7972 - accuracy: 0.6250\n",
      "Epoch 85/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.7784 - accuracy: 0.6607\n",
      "Epoch 86/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 0.7673 - accuracy: 0.7143\n",
      "Epoch 87/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 0.7466 - accuracy: 0.7679\n",
      "Epoch 88/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 0.7406 - accuracy: 0.6786\n",
      "Epoch 89/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.7457 - accuracy: 0.7321\n",
      "Epoch 90/200\n",
      "56/56 [==============================] - 0s 121us/step - loss: 0.7410 - accuracy: 0.6429\n",
      "Epoch 91/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.7590 - accuracy: 0.7321\n",
      "Epoch 92/200\n",
      "56/56 [==============================] - 0s 124us/step - loss: 0.7040 - accuracy: 0.8393\n",
      "Epoch 93/200\n",
      "56/56 [==============================] - 0s 122us/step - loss: 0.7308 - accuracy: 0.7857\n",
      "Epoch 94/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.7538 - accuracy: 0.7143\n",
      "Epoch 95/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 0.6952 - accuracy: 0.8036\n",
      "Epoch 96/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.7504 - accuracy: 0.7321\n",
      "Epoch 97/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.7606 - accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 0.6927 - accuracy: 0.6607\n",
      "Epoch 99/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 0.7153 - accuracy: 0.6071\n",
      "Epoch 100/200\n",
      "56/56 [==============================] - 0s 119us/step - loss: 0.6779 - accuracy: 0.7857\n",
      "Epoch 101/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.7217 - accuracy: 0.7143\n",
      "Epoch 102/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.6657 - accuracy: 0.7321\n",
      "Epoch 103/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.6124 - accuracy: 0.8036\n",
      "Epoch 104/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 0.6875 - accuracy: 0.7857\n",
      "Epoch 105/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.6971 - accuracy: 0.7321\n",
      "Epoch 106/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.6589 - accuracy: 0.8036\n",
      "Epoch 107/200\n",
      "56/56 [==============================] - 0s 121us/step - loss: 0.6148 - accuracy: 0.8036\n",
      "Epoch 108/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.6490 - accuracy: 0.8036\n",
      "Epoch 109/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.6809 - accuracy: 0.8036\n",
      "Epoch 110/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.6232 - accuracy: 0.7500\n",
      "Epoch 111/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.6440 - accuracy: 0.7857\n",
      "Epoch 112/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.6345 - accuracy: 0.7321\n",
      "Epoch 113/200\n",
      "56/56 [==============================] - 0s 117us/step - loss: 0.5798 - accuracy: 0.7500\n",
      "Epoch 114/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.6076 - accuracy: 0.7857\n",
      "Epoch 115/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.5828 - accuracy: 0.7679\n",
      "Epoch 116/200\n",
      "56/56 [==============================] - 0s 117us/step - loss: 0.5398 - accuracy: 0.8750\n",
      "Epoch 117/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 0.5547 - accuracy: 0.8393\n",
      "Epoch 118/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 0.5232 - accuracy: 0.8393\n",
      "Epoch 119/200\n",
      "56/56 [==============================] - 0s 121us/step - loss: 0.5675 - accuracy: 0.7857\n",
      "Epoch 120/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 0.5355 - accuracy: 0.7321\n",
      "Epoch 121/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 0.6037 - accuracy: 0.7500\n",
      "Epoch 122/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 0.5144 - accuracy: 0.8214\n",
      "Epoch 123/200\n",
      "56/56 [==============================] - 0s 122us/step - loss: 0.5564 - accuracy: 0.7143\n",
      "Epoch 124/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 0.5548 - accuracy: 0.7857\n",
      "Epoch 125/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 0.5586 - accuracy: 0.7857\n",
      "Epoch 126/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.5498 - accuracy: 0.7857\n",
      "Epoch 127/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.4921 - accuracy: 0.8571\n",
      "Epoch 128/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.5391 - accuracy: 0.7500\n",
      "Epoch 129/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.5114 - accuracy: 0.8214\n",
      "Epoch 130/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.4993 - accuracy: 0.7500\n",
      "Epoch 131/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.4516 - accuracy: 0.8036\n",
      "Epoch 132/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.4911 - accuracy: 0.8214\n",
      "Epoch 133/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 0.5101 - accuracy: 0.8393\n",
      "Epoch 134/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.4938 - accuracy: 0.8214\n",
      "Epoch 135/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.4872 - accuracy: 0.8214\n",
      "Epoch 136/200\n",
      "56/56 [==============================] - 0s 116us/step - loss: 0.5158 - accuracy: 0.7857\n",
      "Epoch 137/200\n",
      "56/56 [==============================] - 0s 117us/step - loss: 0.5366 - accuracy: 0.7500\n",
      "Epoch 138/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.5180 - accuracy: 0.8036\n",
      "Epoch 139/200\n",
      "56/56 [==============================] - 0s 118us/step - loss: 0.4463 - accuracy: 0.8036\n",
      "Epoch 140/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 0.4582 - accuracy: 0.8750\n",
      "Epoch 141/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.4292 - accuracy: 0.8393\n",
      "Epoch 142/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.4631 - accuracy: 0.8214\n",
      "Epoch 143/200\n",
      "56/56 [==============================] - 0s 122us/step - loss: 0.4667 - accuracy: 0.8214\n",
      "Epoch 144/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.4734 - accuracy: 0.7857\n",
      "Epoch 145/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.4018 - accuracy: 0.8393\n",
      "Epoch 146/200\n",
      "56/56 [==============================] - 0s 119us/step - loss: 0.4622 - accuracy: 0.8214\n",
      "Epoch 147/200\n",
      "56/56 [==============================] - 0s 120us/step - loss: 0.4094 - accuracy: 0.7679\n",
      "Epoch 148/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.5345 - accuracy: 0.7679\n",
      "Epoch 149/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 0.4848 - accuracy: 0.8036\n",
      "Epoch 150/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.3884 - accuracy: 0.8750\n",
      "Epoch 151/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.4671 - accuracy: 0.7321\n",
      "Epoch 152/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.4056 - accuracy: 0.8571\n",
      "Epoch 153/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.4091 - accuracy: 0.8036\n",
      "Epoch 154/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 0.3934 - accuracy: 0.8393\n",
      "Epoch 155/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.3672 - accuracy: 0.8393\n",
      "Epoch 156/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.4262 - accuracy: 0.8214\n",
      "Epoch 157/200\n",
      "56/56 [==============================] - 0s 113us/step - loss: 0.4212 - accuracy: 0.8393\n",
      "Epoch 158/200\n",
      "56/56 [==============================] - 0s 123us/step - loss: 0.3566 - accuracy: 0.8750\n",
      "Epoch 159/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.4010 - accuracy: 0.8750\n",
      "Epoch 160/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.3534 - accuracy: 0.8393\n",
      "Epoch 161/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.4293 - accuracy: 0.8393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 162/200\n",
      "56/56 [==============================] - 0s 124us/step - loss: 0.3762 - accuracy: 0.8571\n",
      "Epoch 163/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.3944 - accuracy: 0.8571\n",
      "Epoch 164/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.3970 - accuracy: 0.8393\n",
      "Epoch 165/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.4052 - accuracy: 0.8214\n",
      "Epoch 166/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.3657 - accuracy: 0.8393\n",
      "Epoch 167/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.3638 - accuracy: 0.8393\n",
      "Epoch 168/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 0.3729 - accuracy: 0.8214\n",
      "Epoch 169/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.3762 - accuracy: 0.8036\n",
      "Epoch 170/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 0.3813 - accuracy: 0.8036\n",
      "Epoch 171/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 0.3767 - accuracy: 0.8571\n",
      "Epoch 172/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.4393 - accuracy: 0.8214\n",
      "Epoch 173/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.3835 - accuracy: 0.8214\n",
      "Epoch 174/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.2839 - accuracy: 0.9107\n",
      "Epoch 175/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.3353 - accuracy: 0.8571\n",
      "Epoch 176/200\n",
      "56/56 [==============================] - 0s 111us/step - loss: 0.2882 - accuracy: 0.8571\n",
      "Epoch 177/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 0.3643 - accuracy: 0.8393\n",
      "Epoch 178/200\n",
      "56/56 [==============================] - 0s 112us/step - loss: 0.3681 - accuracy: 0.8214\n",
      "Epoch 179/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.3141 - accuracy: 0.9107\n",
      "Epoch 180/200\n",
      "56/56 [==============================] - 0s 107us/step - loss: 0.3443 - accuracy: 0.8393\n",
      "Epoch 181/200\n",
      "56/56 [==============================] - 0s 115us/step - loss: 0.3479 - accuracy: 0.8214\n",
      "Epoch 182/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.3167 - accuracy: 0.8750\n",
      "Epoch 183/200\n",
      "56/56 [==============================] - 0s 110us/step - loss: 0.3618 - accuracy: 0.8571\n",
      "Epoch 184/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 0.3416 - accuracy: 0.8750\n",
      "Epoch 185/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 0.3869 - accuracy: 0.8571\n",
      "Epoch 186/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 0.2995 - accuracy: 0.8571\n",
      "Epoch 187/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 0.2952 - accuracy: 0.8929\n",
      "Epoch 188/200\n",
      "56/56 [==============================] - 0s 104us/step - loss: 0.3728 - accuracy: 0.8036\n",
      "Epoch 189/200\n",
      "56/56 [==============================] - 0s 109us/step - loss: 0.3214 - accuracy: 0.8750\n",
      "Epoch 190/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 0.2920 - accuracy: 0.8571\n",
      "Epoch 191/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 0.3434 - accuracy: 0.8393\n",
      "Epoch 192/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 0.2983 - accuracy: 0.8393\n",
      "Epoch 193/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.2988 - accuracy: 0.9286\n",
      "Epoch 194/200\n",
      "56/56 [==============================] - 0s 105us/step - loss: 0.3165 - accuracy: 0.8750\n",
      "Epoch 195/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 0.3128 - accuracy: 0.8393\n",
      "Epoch 196/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.3432 - accuracy: 0.8393\n",
      "Epoch 197/200\n",
      "56/56 [==============================] - 0s 108us/step - loss: 0.3321 - accuracy: 0.8929\n",
      "Epoch 198/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 0.3397 - accuracy: 0.8750\n",
      "Epoch 199/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 0.3370 - accuracy: 0.8571\n",
      "Epoch 200/200\n",
      "56/56 [==============================] - 0s 106us/step - loss: 0.3761 - accuracy: 0.8214\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f8a0bd51978>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(50,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding More Data and Beginning Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2.]\n",
      "171 total new samples\n"
     ]
    }
   ],
   "source": [
    "dabDataset = np.load('data/more-dabs.npy')\n",
    "tposeDataset = np.load('data/more-tposes.npy')\n",
    "otherDataset = np.load('data/more-other.npy')\n",
    "labels1 = np.zeros(len(otherDataset))\n",
    "labels1 = np.append(labels1, np.full((len(dabDataset)), 1))\n",
    "labels1 = np.append(labels1, np.full((len(tposeDataset)), 2))\n",
    "print(labels1)\n",
    "print(\"%i total new samples\" % len(labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 25, 3)\n",
      "(171, 25, 2)\n",
      "(171, 50)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = np.append(otherDataset, dabDataset, axis=0)\n",
    "dataset1 = np.append(dataset1, tposeDataset, axis=0)\n",
    "X1, y1 = shuffle(dataset1, labels1)\n",
    "y1 = to_categorical(y1, 3)\n",
    "print(X1.shape)\n",
    "X1[:,:,0] = X1[:,:,0] / 720\n",
    "X1[:,:,1] = X1[:,:,1] / 1280\n",
    "X1 = X1[:,:,:2]\n",
    "print(X1.shape)\n",
    "X1 = X1.reshape(len(X1), 50)    \n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 114 samples, validate on 57 samples\n",
      "Epoch 1/1000\n",
      "114/114 [==============================] - 1s 9ms/step - loss: 1.3154 - accuracy: 0.3158 - val_loss: 1.1753 - val_accuracy: 0.2807\n",
      "Epoch 2/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 1.2615 - accuracy: 0.3246 - val_loss: 1.1142 - val_accuracy: 0.4561\n",
      "Epoch 3/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 1.1290 - accuracy: 0.3860 - val_loss: 1.0927 - val_accuracy: 0.3684\n",
      "Epoch 4/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 1.0584 - accuracy: 0.4561 - val_loss: 1.0895 - val_accuracy: 0.3684\n",
      "Epoch 5/1000\n",
      "114/114 [==============================] - 0s 167us/step - loss: 1.0801 - accuracy: 0.4211 - val_loss: 1.0848 - val_accuracy: 0.3684\n",
      "Epoch 6/1000\n",
      "114/114 [==============================] - 0s 156us/step - loss: 1.0314 - accuracy: 0.4912 - val_loss: 1.0770 - val_accuracy: 0.3684\n",
      "Epoch 7/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 1.0639 - accuracy: 0.5088 - val_loss: 1.0655 - val_accuracy: 0.3684\n",
      "Epoch 8/1000\n",
      "114/114 [==============================] - 0s 150us/step - loss: 1.0532 - accuracy: 0.4211 - val_loss: 1.0495 - val_accuracy: 0.3684\n",
      "Epoch 9/1000\n",
      "114/114 [==============================] - 0s 150us/step - loss: 1.0908 - accuracy: 0.4649 - val_loss: 1.0349 - val_accuracy: 0.3684\n",
      "Epoch 10/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 1.0384 - accuracy: 0.5175 - val_loss: 1.0198 - val_accuracy: 0.4211\n",
      "Epoch 11/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 1.0789 - accuracy: 0.4474 - val_loss: 1.0087 - val_accuracy: 0.4386\n",
      "Epoch 12/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.9624 - accuracy: 0.5877 - val_loss: 1.0008 - val_accuracy: 0.4561\n",
      "Epoch 13/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.9629 - accuracy: 0.5439 - val_loss: 0.9942 - val_accuracy: 0.4912\n",
      "Epoch 14/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.9836 - accuracy: 0.5088 - val_loss: 0.9892 - val_accuracy: 0.4912\n",
      "Epoch 15/1000\n",
      "114/114 [==============================] - 0s 149us/step - loss: 0.9735 - accuracy: 0.4825 - val_loss: 0.9841 - val_accuracy: 0.5088\n",
      "Epoch 16/1000\n",
      "114/114 [==============================] - 0s 153us/step - loss: 1.0018 - accuracy: 0.5263 - val_loss: 0.9779 - val_accuracy: 0.5263\n",
      "Epoch 17/1000\n",
      "114/114 [==============================] - 0s 153us/step - loss: 0.9745 - accuracy: 0.5351 - val_loss: 0.9713 - val_accuracy: 0.5263\n",
      "Epoch 18/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.9477 - accuracy: 0.5351 - val_loss: 0.9647 - val_accuracy: 0.5614\n",
      "Epoch 19/1000\n",
      "114/114 [==============================] - 0s 154us/step - loss: 0.9277 - accuracy: 0.6053 - val_loss: 0.9592 - val_accuracy: 0.5439\n",
      "Epoch 20/1000\n",
      "114/114 [==============================] - 0s 157us/step - loss: 0.9464 - accuracy: 0.6053 - val_loss: 0.9530 - val_accuracy: 0.5789\n",
      "Epoch 21/1000\n",
      "114/114 [==============================] - 0s 167us/step - loss: 0.9103 - accuracy: 0.5702 - val_loss: 0.9468 - val_accuracy: 0.6140\n",
      "Epoch 22/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.9030 - accuracy: 0.5702 - val_loss: 0.9407 - val_accuracy: 0.6491\n",
      "Epoch 23/1000\n",
      "114/114 [==============================] - 0s 152us/step - loss: 0.8562 - accuracy: 0.6491 - val_loss: 0.9336 - val_accuracy: 0.6491\n",
      "Epoch 24/1000\n",
      "114/114 [==============================] - 0s 160us/step - loss: 0.8326 - accuracy: 0.6491 - val_loss: 0.9252 - val_accuracy: 0.6491\n",
      "Epoch 25/1000\n",
      "114/114 [==============================] - 0s 184us/step - loss: 0.8847 - accuracy: 0.6053 - val_loss: 0.9167 - val_accuracy: 0.6842\n",
      "Epoch 26/1000\n",
      "114/114 [==============================] - 0s 163us/step - loss: 0.9041 - accuracy: 0.5965 - val_loss: 0.9087 - val_accuracy: 0.6667\n",
      "Epoch 27/1000\n",
      "114/114 [==============================] - 0s 156us/step - loss: 0.8560 - accuracy: 0.6228 - val_loss: 0.9001 - val_accuracy: 0.6842\n",
      "Epoch 28/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.8702 - accuracy: 0.5702 - val_loss: 0.8931 - val_accuracy: 0.6842\n",
      "Epoch 29/1000\n",
      "114/114 [==============================] - 0s 153us/step - loss: 0.8059 - accuracy: 0.7281 - val_loss: 0.8857 - val_accuracy: 0.6842\n",
      "Epoch 30/1000\n",
      "114/114 [==============================] - 0s 158us/step - loss: 0.8372 - accuracy: 0.6754 - val_loss: 0.8776 - val_accuracy: 0.7018\n",
      "Epoch 31/1000\n",
      "114/114 [==============================] - 0s 156us/step - loss: 0.8215 - accuracy: 0.6579 - val_loss: 0.8707 - val_accuracy: 0.7018\n",
      "Epoch 32/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.8617 - accuracy: 0.6754 - val_loss: 0.8653 - val_accuracy: 0.7018\n",
      "Epoch 33/1000\n",
      "114/114 [==============================] - 0s 159us/step - loss: 0.7859 - accuracy: 0.6579 - val_loss: 0.8607 - val_accuracy: 0.7018\n",
      "Epoch 34/1000\n",
      "114/114 [==============================] - 0s 162us/step - loss: 0.8248 - accuracy: 0.6667 - val_loss: 0.8533 - val_accuracy: 0.7018\n",
      "Epoch 35/1000\n",
      "114/114 [==============================] - 0s 166us/step - loss: 0.8011 - accuracy: 0.6579 - val_loss: 0.8473 - val_accuracy: 0.7018\n",
      "Epoch 36/1000\n",
      "114/114 [==============================] - 0s 152us/step - loss: 0.7522 - accuracy: 0.7018 - val_loss: 0.8377 - val_accuracy: 0.7018\n",
      "Epoch 37/1000\n",
      "114/114 [==============================] - 0s 159us/step - loss: 0.7908 - accuracy: 0.6491 - val_loss: 0.8249 - val_accuracy: 0.7018\n",
      "Epoch 38/1000\n",
      "114/114 [==============================] - 0s 153us/step - loss: 0.8056 - accuracy: 0.6754 - val_loss: 0.8109 - val_accuracy: 0.7193\n",
      "Epoch 39/1000\n",
      "114/114 [==============================] - 0s 155us/step - loss: 0.7533 - accuracy: 0.6842 - val_loss: 0.7979 - val_accuracy: 0.7193\n",
      "Epoch 40/1000\n",
      "114/114 [==============================] - 0s 158us/step - loss: 0.7422 - accuracy: 0.7281 - val_loss: 0.7860 - val_accuracy: 0.7193\n",
      "Epoch 41/1000\n",
      "114/114 [==============================] - 0s 166us/step - loss: 0.7019 - accuracy: 0.7456 - val_loss: 0.7744 - val_accuracy: 0.7193\n",
      "Epoch 42/1000\n",
      "114/114 [==============================] - 0s 162us/step - loss: 0.7507 - accuracy: 0.7544 - val_loss: 0.7650 - val_accuracy: 0.7193\n",
      "Epoch 43/1000\n",
      "114/114 [==============================] - 0s 157us/step - loss: 0.7162 - accuracy: 0.7281 - val_loss: 0.7584 - val_accuracy: 0.7193\n",
      "Epoch 44/1000\n",
      "114/114 [==============================] - 0s 171us/step - loss: 0.6956 - accuracy: 0.7368 - val_loss: 0.7539 - val_accuracy: 0.7193\n",
      "Epoch 45/1000\n",
      "114/114 [==============================] - 0s 159us/step - loss: 0.6978 - accuracy: 0.7719 - val_loss: 0.7453 - val_accuracy: 0.7193\n",
      "Epoch 46/1000\n",
      "114/114 [==============================] - 0s 173us/step - loss: 0.6482 - accuracy: 0.7456 - val_loss: 0.7304 - val_accuracy: 0.7193\n",
      "Epoch 47/1000\n",
      "114/114 [==============================] - 0s 174us/step - loss: 0.6537 - accuracy: 0.7632 - val_loss: 0.7112 - val_accuracy: 0.7193\n",
      "Epoch 48/1000\n",
      "114/114 [==============================] - 0s 170us/step - loss: 0.6427 - accuracy: 0.7544 - val_loss: 0.6982 - val_accuracy: 0.7193\n",
      "Epoch 49/1000\n",
      "114/114 [==============================] - 0s 157us/step - loss: 0.6556 - accuracy: 0.7456 - val_loss: 0.6861 - val_accuracy: 0.7368\n",
      "Epoch 50/1000\n",
      "114/114 [==============================] - 0s 152us/step - loss: 0.6327 - accuracy: 0.7632 - val_loss: 0.6739 - val_accuracy: 0.7368\n",
      "Epoch 51/1000\n",
      "114/114 [==============================] - 0s 169us/step - loss: 0.6183 - accuracy: 0.7632 - val_loss: 0.6658 - val_accuracy: 0.7368\n",
      "Epoch 52/1000\n",
      "114/114 [==============================] - 0s 150us/step - loss: 0.5730 - accuracy: 0.7895 - val_loss: 0.6578 - val_accuracy: 0.7193\n",
      "Epoch 53/1000\n",
      "114/114 [==============================] - 0s 153us/step - loss: 0.6203 - accuracy: 0.7456 - val_loss: 0.6497 - val_accuracy: 0.7193\n",
      "Epoch 54/1000\n",
      "114/114 [==============================] - 0s 151us/step - loss: 0.5029 - accuracy: 0.8421 - val_loss: 0.6363 - val_accuracy: 0.7193\n",
      "Epoch 55/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.6035 - accuracy: 0.7719 - val_loss: 0.6256 - val_accuracy: 0.7193\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 152us/step - loss: 0.5631 - accuracy: 0.7281 - val_loss: 0.6191 - val_accuracy: 0.7193\n",
      "Epoch 57/1000\n",
      "114/114 [==============================] - 0s 167us/step - loss: 0.5229 - accuracy: 0.8158 - val_loss: 0.6049 - val_accuracy: 0.7193\n",
      "Epoch 58/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.5529 - accuracy: 0.8158 - val_loss: 0.5843 - val_accuracy: 0.7368\n",
      "Epoch 59/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.4700 - accuracy: 0.8070 - val_loss: 0.5670 - val_accuracy: 0.7193\n",
      "Epoch 60/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.4736 - accuracy: 0.8158 - val_loss: 0.5535 - val_accuracy: 0.7719\n",
      "Epoch 61/1000\n",
      "114/114 [==============================] - 0s 149us/step - loss: 0.5041 - accuracy: 0.8333 - val_loss: 0.5395 - val_accuracy: 0.7368\n",
      "Epoch 62/1000\n",
      "114/114 [==============================] - 0s 168us/step - loss: 0.4782 - accuracy: 0.8246 - val_loss: 0.5375 - val_accuracy: 0.7368\n",
      "Epoch 63/1000\n",
      "114/114 [==============================] - 0s 149us/step - loss: 0.4481 - accuracy: 0.8158 - val_loss: 0.5486 - val_accuracy: 0.7193\n",
      "Epoch 64/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.4687 - accuracy: 0.8158 - val_loss: 0.5345 - val_accuracy: 0.7193\n",
      "Epoch 65/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.4135 - accuracy: 0.8684 - val_loss: 0.5065 - val_accuracy: 0.7368\n",
      "Epoch 66/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.4184 - accuracy: 0.8772 - val_loss: 0.4899 - val_accuracy: 0.7719\n",
      "Epoch 67/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.4123 - accuracy: 0.8772 - val_loss: 0.4764 - val_accuracy: 0.7895\n",
      "Epoch 68/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.3990 - accuracy: 0.8860 - val_loss: 0.4645 - val_accuracy: 0.8070\n",
      "Epoch 69/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.4397 - accuracy: 0.8772 - val_loss: 0.4560 - val_accuracy: 0.8246\n",
      "Epoch 70/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.3810 - accuracy: 0.8947 - val_loss: 0.4574 - val_accuracy: 0.7895\n",
      "Epoch 71/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.3898 - accuracy: 0.8772 - val_loss: 0.4541 - val_accuracy: 0.7895\n",
      "Epoch 72/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.3530 - accuracy: 0.8860 - val_loss: 0.4449 - val_accuracy: 0.8070\n",
      "Epoch 73/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.4105 - accuracy: 0.8246 - val_loss: 0.4386 - val_accuracy: 0.8070\n",
      "Epoch 74/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.3692 - accuracy: 0.8860 - val_loss: 0.4302 - val_accuracy: 0.8246\n",
      "Epoch 75/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.3717 - accuracy: 0.8684 - val_loss: 0.4227 - val_accuracy: 0.8246\n",
      "Epoch 76/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.3317 - accuracy: 0.8596 - val_loss: 0.4181 - val_accuracy: 0.8421\n",
      "Epoch 77/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.3519 - accuracy: 0.8772 - val_loss: 0.4152 - val_accuracy: 0.8421\n",
      "Epoch 78/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.3095 - accuracy: 0.9298 - val_loss: 0.4113 - val_accuracy: 0.8421\n",
      "Epoch 79/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.3318 - accuracy: 0.9123 - val_loss: 0.3986 - val_accuracy: 0.8421\n",
      "Epoch 80/1000\n",
      "114/114 [==============================] - 0s 150us/step - loss: 0.3653 - accuracy: 0.8684 - val_loss: 0.3881 - val_accuracy: 0.8421\n",
      "Epoch 81/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.2869 - accuracy: 0.9123 - val_loss: 0.3818 - val_accuracy: 0.8596\n",
      "Epoch 82/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.2616 - accuracy: 0.9386 - val_loss: 0.3778 - val_accuracy: 0.8596\n",
      "Epoch 83/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.2767 - accuracy: 0.9211 - val_loss: 0.3733 - val_accuracy: 0.8421\n",
      "Epoch 84/1000\n",
      "114/114 [==============================] - 0s 155us/step - loss: 0.2634 - accuracy: 0.9035 - val_loss: 0.3804 - val_accuracy: 0.8421\n",
      "Epoch 85/1000\n",
      "114/114 [==============================] - 0s 152us/step - loss: 0.2731 - accuracy: 0.9035 - val_loss: 0.3859 - val_accuracy: 0.8421\n",
      "Epoch 86/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.2752 - accuracy: 0.9123 - val_loss: 0.3729 - val_accuracy: 0.8421\n",
      "Epoch 87/1000\n",
      "114/114 [==============================] - 0s 151us/step - loss: 0.3108 - accuracy: 0.8684 - val_loss: 0.3517 - val_accuracy: 0.8421\n",
      "Epoch 88/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.2741 - accuracy: 0.9123 - val_loss: 0.3481 - val_accuracy: 0.8596\n",
      "Epoch 89/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.2579 - accuracy: 0.9123 - val_loss: 0.3432 - val_accuracy: 0.8421\n",
      "Epoch 90/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.2786 - accuracy: 0.9035 - val_loss: 0.3451 - val_accuracy: 0.8421\n",
      "Epoch 91/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.2954 - accuracy: 0.8860 - val_loss: 0.3617 - val_accuracy: 0.8246\n",
      "Epoch 92/1000\n",
      "114/114 [==============================] - 0s 153us/step - loss: 0.2711 - accuracy: 0.8947 - val_loss: 0.3693 - val_accuracy: 0.8246\n",
      "Epoch 93/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.2229 - accuracy: 0.9211 - val_loss: 0.3486 - val_accuracy: 0.8246\n",
      "Epoch 94/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.2418 - accuracy: 0.8947 - val_loss: 0.3282 - val_accuracy: 0.8421\n",
      "Epoch 95/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.2894 - accuracy: 0.9298 - val_loss: 0.3269 - val_accuracy: 0.8772\n",
      "Epoch 96/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.2297 - accuracy: 0.9211 - val_loss: 0.3200 - val_accuracy: 0.8947\n",
      "Epoch 97/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.2253 - accuracy: 0.9474 - val_loss: 0.3074 - val_accuracy: 0.8596\n",
      "Epoch 98/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.2469 - accuracy: 0.8947 - val_loss: 0.3025 - val_accuracy: 0.8421\n",
      "Epoch 99/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.1854 - accuracy: 0.9474 - val_loss: 0.3018 - val_accuracy: 0.8596\n",
      "Epoch 100/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.1977 - accuracy: 0.9474 - val_loss: 0.2974 - val_accuracy: 0.8596\n",
      "Epoch 101/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.2175 - accuracy: 0.9474 - val_loss: 0.2882 - val_accuracy: 0.8596\n",
      "Epoch 102/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.2425 - accuracy: 0.9211 - val_loss: 0.2828 - val_accuracy: 0.8772\n",
      "Epoch 103/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.1946 - accuracy: 0.9298 - val_loss: 0.2839 - val_accuracy: 0.8596\n",
      "Epoch 104/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.2502 - accuracy: 0.9211 - val_loss: 0.2844 - val_accuracy: 0.8772\n",
      "Epoch 105/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.1859 - accuracy: 0.9211 - val_loss: 0.2794 - val_accuracy: 0.8596\n",
      "Epoch 106/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.2084 - accuracy: 0.9474 - val_loss: 0.2743 - val_accuracy: 0.8596\n",
      "Epoch 107/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.1529 - accuracy: 0.9649 - val_loss: 0.2783 - val_accuracy: 0.8596\n",
      "Epoch 108/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.2276 - accuracy: 0.9298 - val_loss: 0.2845 - val_accuracy: 0.8596\n",
      "Epoch 109/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.2694 - accuracy: 0.8947 - val_loss: 0.2807 - val_accuracy: 0.8596\n",
      "Epoch 110/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.1764 - accuracy: 0.9474 - val_loss: 0.2761 - val_accuracy: 0.8596\n",
      "Epoch 111/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.1675 - accuracy: 0.9649 - val_loss: 0.2670 - val_accuracy: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.2360 - accuracy: 0.9386 - val_loss: 0.2685 - val_accuracy: 0.8421\n",
      "Epoch 113/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.1690 - accuracy: 0.9649 - val_loss: 0.2785 - val_accuracy: 0.8421\n",
      "Epoch 114/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.1521 - accuracy: 0.9649 - val_loss: 0.2721 - val_accuracy: 0.8421\n",
      "Epoch 115/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.1537 - accuracy: 0.9649 - val_loss: 0.2612 - val_accuracy: 0.8421\n",
      "Epoch 116/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.1568 - accuracy: 0.9561 - val_loss: 0.2566 - val_accuracy: 0.8596\n",
      "Epoch 117/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.1573 - accuracy: 0.9561 - val_loss: 0.2558 - val_accuracy: 0.8596\n",
      "Epoch 118/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.1702 - accuracy: 0.9649 - val_loss: 0.2583 - val_accuracy: 0.8596\n",
      "Epoch 119/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.1320 - accuracy: 0.9737 - val_loss: 0.2592 - val_accuracy: 0.8421\n",
      "Epoch 120/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.1652 - accuracy: 0.9649 - val_loss: 0.2656 - val_accuracy: 0.8246\n",
      "Epoch 121/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.1642 - accuracy: 0.9298 - val_loss: 0.2556 - val_accuracy: 0.8421\n",
      "Epoch 122/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.1748 - accuracy: 0.9386 - val_loss: 0.2397 - val_accuracy: 0.8596\n",
      "Epoch 123/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.1611 - accuracy: 0.9474 - val_loss: 0.2278 - val_accuracy: 0.8772\n",
      "Epoch 124/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.1747 - accuracy: 0.9386 - val_loss: 0.2211 - val_accuracy: 0.8947\n",
      "Epoch 125/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.1290 - accuracy: 0.9649 - val_loss: 0.2183 - val_accuracy: 0.8772\n",
      "Epoch 126/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.1708 - accuracy: 0.9474 - val_loss: 0.2183 - val_accuracy: 0.8772\n",
      "Epoch 127/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.1243 - accuracy: 0.9737 - val_loss: 0.2218 - val_accuracy: 0.8772\n",
      "Epoch 128/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.1506 - accuracy: 0.9474 - val_loss: 0.2370 - val_accuracy: 0.8596\n",
      "Epoch 129/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.2393 - accuracy: 0.9123 - val_loss: 0.2473 - val_accuracy: 0.8772\n",
      "Epoch 130/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.1233 - accuracy: 0.9825 - val_loss: 0.2452 - val_accuracy: 0.8596\n",
      "Epoch 131/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.1642 - accuracy: 0.9649 - val_loss: 0.2225 - val_accuracy: 0.8596\n",
      "Epoch 132/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.1639 - accuracy: 0.9474 - val_loss: 0.2086 - val_accuracy: 0.9123\n",
      "Epoch 133/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.1197 - accuracy: 0.9737 - val_loss: 0.2032 - val_accuracy: 0.8947\n",
      "Epoch 134/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.1728 - accuracy: 0.9298 - val_loss: 0.1976 - val_accuracy: 0.9123\n",
      "Epoch 135/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.1654 - accuracy: 0.9474 - val_loss: 0.2010 - val_accuracy: 0.9123\n",
      "Epoch 136/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0991 - accuracy: 0.9912 - val_loss: 0.2077 - val_accuracy: 0.8947\n",
      "Epoch 137/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.1571 - accuracy: 0.9561 - val_loss: 0.2116 - val_accuracy: 0.8947\n",
      "Epoch 138/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.1214 - accuracy: 0.9737 - val_loss: 0.2117 - val_accuracy: 0.8421\n",
      "Epoch 139/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0907 - accuracy: 0.9912 - val_loss: 0.2105 - val_accuracy: 0.8596\n",
      "Epoch 140/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.1115 - accuracy: 0.9649 - val_loss: 0.2076 - val_accuracy: 0.8772\n",
      "Epoch 141/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.1094 - accuracy: 0.9649 - val_loss: 0.2021 - val_accuracy: 0.8772\n",
      "Epoch 142/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.1551 - accuracy: 0.9649 - val_loss: 0.1978 - val_accuracy: 0.8947\n",
      "Epoch 143/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.1172 - accuracy: 0.9737 - val_loss: 0.1955 - val_accuracy: 0.8947\n",
      "Epoch 144/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.1540 - accuracy: 0.9561 - val_loss: 0.1959 - val_accuracy: 0.8772\n",
      "Epoch 145/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.1187 - accuracy: 0.9737 - val_loss: 0.1982 - val_accuracy: 0.8772\n",
      "Epoch 146/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.1361 - accuracy: 0.9474 - val_loss: 0.2005 - val_accuracy: 0.8772\n",
      "Epoch 147/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0822 - accuracy: 0.9737 - val_loss: 0.1940 - val_accuracy: 0.8772\n",
      "Epoch 148/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.1070 - accuracy: 0.9825 - val_loss: 0.1914 - val_accuracy: 0.9123\n",
      "Epoch 149/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.1313 - accuracy: 0.9561 - val_loss: 0.1905 - val_accuracy: 0.9123\n",
      "Epoch 150/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.1112 - accuracy: 0.9825 - val_loss: 0.1902 - val_accuracy: 0.8947\n",
      "Epoch 151/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0858 - accuracy: 0.9825 - val_loss: 0.1921 - val_accuracy: 0.8772\n",
      "Epoch 152/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.1438 - accuracy: 0.9649 - val_loss: 0.2042 - val_accuracy: 0.8772\n",
      "Epoch 153/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.1317 - accuracy: 0.9474 - val_loss: 0.2152 - val_accuracy: 0.8596\n",
      "Epoch 154/1000\n",
      "114/114 [==============================] - 0s 149us/step - loss: 0.0931 - accuracy: 0.9737 - val_loss: 0.2210 - val_accuracy: 0.8596\n",
      "Epoch 155/1000\n",
      "114/114 [==============================] - 0s 163us/step - loss: 0.1431 - accuracy: 0.9474 - val_loss: 0.2063 - val_accuracy: 0.8772\n",
      "Epoch 156/1000\n",
      "114/114 [==============================] - 0s 184us/step - loss: 0.0994 - accuracy: 0.9825 - val_loss: 0.1877 - val_accuracy: 0.8947\n",
      "Epoch 157/1000\n",
      "114/114 [==============================] - 0s 181us/step - loss: 0.0891 - accuracy: 0.9649 - val_loss: 0.1750 - val_accuracy: 0.9123\n",
      "Epoch 158/1000\n",
      "114/114 [==============================] - 0s 176us/step - loss: 0.1272 - accuracy: 0.9737 - val_loss: 0.1656 - val_accuracy: 0.9123\n",
      "Epoch 159/1000\n",
      "114/114 [==============================] - 0s 169us/step - loss: 0.0791 - accuracy: 0.9737 - val_loss: 0.1604 - val_accuracy: 0.9123\n",
      "Epoch 160/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0906 - accuracy: 0.9912 - val_loss: 0.1614 - val_accuracy: 0.8947\n",
      "Epoch 161/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.0806 - accuracy: 0.9737 - val_loss: 0.1610 - val_accuracy: 0.8947\n",
      "Epoch 162/1000\n",
      "114/114 [==============================] - 0s 151us/step - loss: 0.0793 - accuracy: 0.9825 - val_loss: 0.1606 - val_accuracy: 0.8947\n",
      "Epoch 163/1000\n",
      "114/114 [==============================] - 0s 151us/step - loss: 0.0927 - accuracy: 0.9737 - val_loss: 0.1599 - val_accuracy: 0.9123\n",
      "Epoch 164/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.1062 - accuracy: 0.9649 - val_loss: 0.1655 - val_accuracy: 0.9123\n",
      "Epoch 165/1000\n",
      "114/114 [==============================] - 0s 157us/step - loss: 0.0998 - accuracy: 0.9649 - val_loss: 0.1643 - val_accuracy: 0.9123\n",
      "Epoch 166/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.1036 - accuracy: 0.9649 - val_loss: 0.1624 - val_accuracy: 0.9123\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 147us/step - loss: 0.0604 - accuracy: 1.0000 - val_loss: 0.1614 - val_accuracy: 0.9123\n",
      "Epoch 168/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.1025 - accuracy: 0.9649 - val_loss: 0.1568 - val_accuracy: 0.8947\n",
      "Epoch 169/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0703 - accuracy: 0.9912 - val_loss: 0.1514 - val_accuracy: 0.9123\n",
      "Epoch 170/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0802 - accuracy: 0.9737 - val_loss: 0.1506 - val_accuracy: 0.9123\n",
      "Epoch 171/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.1056 - accuracy: 0.9649 - val_loss: 0.1500 - val_accuracy: 0.9123\n",
      "Epoch 172/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.1068 - accuracy: 0.9649 - val_loss: 0.1512 - val_accuracy: 0.9123\n",
      "Epoch 173/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.1038 - accuracy: 0.9737 - val_loss: 0.1651 - val_accuracy: 0.9123\n",
      "Epoch 174/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.1088 - accuracy: 0.9737 - val_loss: 0.1588 - val_accuracy: 0.9123\n",
      "Epoch 175/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0677 - accuracy: 0.9912 - val_loss: 0.1501 - val_accuracy: 0.9123\n",
      "Epoch 176/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9298\n",
      "Epoch 177/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0933 - accuracy: 0.9649 - val_loss: 0.1368 - val_accuracy: 0.9298\n",
      "Epoch 178/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0743 - accuracy: 0.9825 - val_loss: 0.1362 - val_accuracy: 0.9123\n",
      "Epoch 179/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.1166 - accuracy: 0.9474 - val_loss: 0.1421 - val_accuracy: 0.9298\n",
      "Epoch 180/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0855 - accuracy: 0.9649 - val_loss: 0.1488 - val_accuracy: 0.9298\n",
      "Epoch 181/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0825 - accuracy: 0.9825 - val_loss: 0.1603 - val_accuracy: 0.9298\n",
      "Epoch 182/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0645 - accuracy: 0.9737 - val_loss: 0.1625 - val_accuracy: 0.9298\n",
      "Epoch 183/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.1047 - accuracy: 0.9561 - val_loss: 0.1617 - val_accuracy: 0.9298\n",
      "Epoch 184/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0791 - accuracy: 0.9737 - val_loss: 0.1633 - val_accuracy: 0.9123\n",
      "Epoch 185/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0954 - accuracy: 0.9649 - val_loss: 0.1677 - val_accuracy: 0.8947\n",
      "Epoch 186/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0942 - accuracy: 0.9737 - val_loss: 0.1583 - val_accuracy: 0.9123\n",
      "Epoch 187/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0593 - accuracy: 0.9912 - val_loss: 0.1492 - val_accuracy: 0.9298\n",
      "Epoch 188/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0685 - accuracy: 0.9825 - val_loss: 0.1447 - val_accuracy: 0.9298\n",
      "Epoch 189/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0836 - accuracy: 0.9737 - val_loss: 0.1434 - val_accuracy: 0.9298\n",
      "Epoch 190/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0862 - accuracy: 0.9737 - val_loss: 0.1521 - val_accuracy: 0.9123\n",
      "Epoch 191/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0881 - accuracy: 0.9825 - val_loss: 0.1571 - val_accuracy: 0.9123\n",
      "Epoch 192/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0817 - accuracy: 0.9825 - val_loss: 0.1558 - val_accuracy: 0.9123\n",
      "Epoch 193/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0827 - accuracy: 0.9737 - val_loss: 0.1361 - val_accuracy: 0.9474\n",
      "Epoch 194/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.1014 - accuracy: 0.9474 - val_loss: 0.1261 - val_accuracy: 0.9474\n",
      "Epoch 195/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0549 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9474\n",
      "Epoch 196/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0666 - accuracy: 0.9912 - val_loss: 0.1224 - val_accuracy: 0.9474\n",
      "Epoch 197/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0585 - accuracy: 0.9912 - val_loss: 0.1251 - val_accuracy: 0.9298\n",
      "Epoch 198/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0878 - accuracy: 0.9561 - val_loss: 0.1399 - val_accuracy: 0.9298\n",
      "Epoch 199/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0664 - accuracy: 0.9737 - val_loss: 0.1564 - val_accuracy: 0.8947\n",
      "Epoch 200/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0850 - accuracy: 0.9737 - val_loss: 0.1565 - val_accuracy: 0.8772\n",
      "Epoch 201/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0548 - accuracy: 0.9912 - val_loss: 0.1386 - val_accuracy: 0.9298\n",
      "Epoch 202/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0817 - accuracy: 0.9737 - val_loss: 0.1416 - val_accuracy: 0.9298\n",
      "Epoch 203/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0772 - accuracy: 0.9825 - val_loss: 0.1425 - val_accuracy: 0.9298\n",
      "Epoch 204/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0817 - accuracy: 0.9649 - val_loss: 0.1425 - val_accuracy: 0.8947\n",
      "Epoch 205/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0449 - accuracy: 0.9912 - val_loss: 0.1529 - val_accuracy: 0.9123\n",
      "Epoch 206/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0865 - accuracy: 0.9649 - val_loss: 0.1581 - val_accuracy: 0.9123\n",
      "Epoch 207/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 0.1578 - val_accuracy: 0.9123\n",
      "Epoch 208/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0577 - accuracy: 0.9825 - val_loss: 0.1521 - val_accuracy: 0.9123\n",
      "Epoch 209/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0783 - accuracy: 0.9825 - val_loss: 0.1432 - val_accuracy: 0.8947\n",
      "Epoch 210/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0541 - accuracy: 0.9912 - val_loss: 0.1293 - val_accuracy: 0.9298\n",
      "Epoch 211/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0434 - accuracy: 1.0000 - val_loss: 0.1238 - val_accuracy: 0.9474\n",
      "Epoch 212/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0637 - accuracy: 0.9912 - val_loss: 0.1217 - val_accuracy: 0.9474\n",
      "Epoch 213/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0592 - accuracy: 0.9649 - val_loss: 0.1214 - val_accuracy: 0.9474\n",
      "Epoch 214/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0446 - accuracy: 0.9912 - val_loss: 0.1234 - val_accuracy: 0.9298\n",
      "Epoch 215/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0527 - accuracy: 0.9912 - val_loss: 0.1321 - val_accuracy: 0.9298\n",
      "Epoch 216/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0742 - accuracy: 0.9825 - val_loss: 0.1436 - val_accuracy: 0.9123\n",
      "Epoch 217/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0311 - accuracy: 0.9912 - val_loss: 0.1375 - val_accuracy: 0.9298\n",
      "Epoch 218/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.1282 - val_accuracy: 0.9474\n",
      "Epoch 219/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0613 - accuracy: 0.9825 - val_loss: 0.1112 - val_accuracy: 0.9474\n",
      "Epoch 220/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0524 - accuracy: 0.9825 - val_loss: 0.1072 - val_accuracy: 0.9474\n",
      "Epoch 221/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0556 - accuracy: 0.9912 - val_loss: 0.1066 - val_accuracy: 0.9474\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 133us/step - loss: 0.1072 - accuracy: 0.9474 - val_loss: 0.1052 - val_accuracy: 0.9474\n",
      "Epoch 223/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.1116 - val_accuracy: 0.9474\n",
      "Epoch 224/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0452 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9298\n",
      "Epoch 225/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0544 - accuracy: 0.9912 - val_loss: 0.1326 - val_accuracy: 0.9298\n",
      "Epoch 226/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0606 - accuracy: 0.9825 - val_loss: 0.1320 - val_accuracy: 0.9298\n",
      "Epoch 227/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0603 - accuracy: 0.9825 - val_loss: 0.1380 - val_accuracy: 0.9298\n",
      "Epoch 228/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 0.1420 - val_accuracy: 0.9123\n",
      "Epoch 229/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0969 - accuracy: 0.9737 - val_loss: 0.1338 - val_accuracy: 0.9298\n",
      "Epoch 230/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0668 - accuracy: 0.9737 - val_loss: 0.1202 - val_accuracy: 0.9474\n",
      "Epoch 231/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0561 - accuracy: 0.9825 - val_loss: 0.1192 - val_accuracy: 0.9474\n",
      "Epoch 232/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0904 - accuracy: 0.9649 - val_loss: 0.1307 - val_accuracy: 0.9298\n",
      "Epoch 233/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0649 - accuracy: 0.9825 - val_loss: 0.1457 - val_accuracy: 0.9298\n",
      "Epoch 234/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0589 - accuracy: 0.9825 - val_loss: 0.1498 - val_accuracy: 0.9298\n",
      "Epoch 235/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0594 - accuracy: 0.9737 - val_loss: 0.1444 - val_accuracy: 0.9298\n",
      "Epoch 236/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.1420 - val_accuracy: 0.9298\n",
      "Epoch 237/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0593 - accuracy: 0.9825 - val_loss: 0.1307 - val_accuracy: 0.9298\n",
      "Epoch 238/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0877 - accuracy: 0.9474 - val_loss: 0.1149 - val_accuracy: 0.9298\n",
      "Epoch 239/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9298\n",
      "Epoch 240/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9298\n",
      "Epoch 241/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0447 - accuracy: 0.9825 - val_loss: 0.1013 - val_accuracy: 0.9474\n",
      "Epoch 242/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0412 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9474\n",
      "Epoch 243/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0532 - accuracy: 0.9825 - val_loss: 0.1134 - val_accuracy: 0.9474\n",
      "Epoch 244/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0390 - accuracy: 1.0000 - val_loss: 0.1289 - val_accuracy: 0.9298\n",
      "Epoch 245/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0488 - accuracy: 0.9825 - val_loss: 0.1418 - val_accuracy: 0.9123\n",
      "Epoch 246/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9298\n",
      "Epoch 247/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0511 - accuracy: 0.9912 - val_loss: 0.1127 - val_accuracy: 0.9649\n",
      "Epoch 248/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0566 - accuracy: 0.9825 - val_loss: 0.0910 - val_accuracy: 0.9649\n",
      "Epoch 249/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0768 - accuracy: 0.9737 - val_loss: 0.0899 - val_accuracy: 0.9474\n",
      "Epoch 250/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 0.0957 - val_accuracy: 0.9474\n",
      "Epoch 251/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0306 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9298\n",
      "Epoch 252/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0622 - accuracy: 0.9912 - val_loss: 0.1237 - val_accuracy: 0.9298\n",
      "Epoch 253/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0733 - accuracy: 0.9825 - val_loss: 0.1282 - val_accuracy: 0.9298\n",
      "Epoch 254/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0517 - accuracy: 0.9825 - val_loss: 0.1090 - val_accuracy: 0.9474\n",
      "Epoch 255/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9474\n",
      "Epoch 256/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0495 - accuracy: 0.9912 - val_loss: 0.0949 - val_accuracy: 0.9474\n",
      "Epoch 257/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0347 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9474\n",
      "Epoch 258/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0374 - accuracy: 0.9912 - val_loss: 0.1078 - val_accuracy: 0.9474\n",
      "Epoch 259/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0321 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9649\n",
      "Epoch 260/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0527 - accuracy: 0.9825 - val_loss: 0.1260 - val_accuracy: 0.9298\n",
      "Epoch 261/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0466 - accuracy: 0.9912 - val_loss: 0.1290 - val_accuracy: 0.9123\n",
      "Epoch 262/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0334 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9474\n",
      "Epoch 263/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0550 - accuracy: 0.9825 - val_loss: 0.1116 - val_accuracy: 0.9298\n",
      "Epoch 264/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0549 - accuracy: 0.9737 - val_loss: 0.1037 - val_accuracy: 0.9298\n",
      "Epoch 265/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9298\n",
      "Epoch 266/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0429 - accuracy: 0.9912 - val_loss: 0.0946 - val_accuracy: 0.9298\n",
      "Epoch 267/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0962 - val_accuracy: 0.9474\n",
      "Epoch 268/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0347 - accuracy: 0.9912 - val_loss: 0.1032 - val_accuracy: 0.9474\n",
      "Epoch 269/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0418 - accuracy: 0.9912 - val_loss: 0.1135 - val_accuracy: 0.9474\n",
      "Epoch 270/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0586 - accuracy: 0.9825 - val_loss: 0.1180 - val_accuracy: 0.9474\n",
      "Epoch 271/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0499 - accuracy: 0.9825 - val_loss: 0.1308 - val_accuracy: 0.9474\n",
      "Epoch 272/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 0.1322 - val_accuracy: 0.9298\n",
      "Epoch 273/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 0.1231 - val_accuracy: 0.9474\n",
      "Epoch 274/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0412 - accuracy: 0.9912 - val_loss: 0.1127 - val_accuracy: 0.9474\n",
      "Epoch 275/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9474\n",
      "Epoch 276/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0416 - accuracy: 0.9912 - val_loss: 0.0953 - val_accuracy: 0.9474\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 131us/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.0917 - val_accuracy: 0.9474\n",
      "Epoch 278/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9298\n",
      "Epoch 279/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0407 - accuracy: 0.9912 - val_loss: 0.0922 - val_accuracy: 0.9298\n",
      "Epoch 280/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9474\n",
      "Epoch 281/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0363 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9474\n",
      "Epoch 282/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0338 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9474\n",
      "Epoch 283/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0404 - accuracy: 0.9825 - val_loss: 0.1080 - val_accuracy: 0.9474\n",
      "Epoch 284/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0448 - accuracy: 0.9825 - val_loss: 0.0964 - val_accuracy: 0.9474\n",
      "Epoch 285/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0284 - accuracy: 0.9912 - val_loss: 0.0931 - val_accuracy: 0.9474\n",
      "Epoch 286/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0285 - accuracy: 0.9912 - val_loss: 0.0964 - val_accuracy: 0.9474\n",
      "Epoch 287/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0366 - accuracy: 0.9912 - val_loss: 0.0994 - val_accuracy: 0.9649\n",
      "Epoch 288/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.0967 - val_accuracy: 0.9649\n",
      "Epoch 289/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0511 - accuracy: 0.9825 - val_loss: 0.0974 - val_accuracy: 0.9649\n",
      "Epoch 290/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0459 - accuracy: 0.9825 - val_loss: 0.0928 - val_accuracy: 0.9474\n",
      "Epoch 291/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0233 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9474\n",
      "Epoch 292/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0346 - accuracy: 0.9825 - val_loss: 0.1013 - val_accuracy: 0.9474\n",
      "Epoch 293/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9474\n",
      "Epoch 294/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0617 - accuracy: 0.9825 - val_loss: 0.1359 - val_accuracy: 0.9298\n",
      "Epoch 295/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0357 - accuracy: 0.9825 - val_loss: 0.1338 - val_accuracy: 0.9298\n",
      "Epoch 296/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0297 - accuracy: 0.9912 - val_loss: 0.1178 - val_accuracy: 0.9298\n",
      "Epoch 297/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0456 - accuracy: 0.9912 - val_loss: 0.1119 - val_accuracy: 0.9474\n",
      "Epoch 298/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9649\n",
      "Epoch 299/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9649\n",
      "Epoch 300/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 0.1011 - val_accuracy: 0.9649\n",
      "Epoch 301/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0932 - val_accuracy: 0.9649\n",
      "Epoch 302/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0396 - accuracy: 0.9825 - val_loss: 0.0916 - val_accuracy: 0.9649\n",
      "Epoch 303/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9649\n",
      "Epoch 304/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0379 - accuracy: 0.9825 - val_loss: 0.0904 - val_accuracy: 0.9649\n",
      "Epoch 305/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9649\n",
      "Epoch 306/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0272 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9649\n",
      "Epoch 307/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9474\n",
      "Epoch 308/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9474\n",
      "Epoch 309/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0223 - accuracy: 0.9912 - val_loss: 0.1070 - val_accuracy: 0.9474\n",
      "Epoch 310/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0356 - accuracy: 0.9912 - val_loss: 0.1012 - val_accuracy: 0.9474\n",
      "Epoch 311/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0280 - accuracy: 0.9912 - val_loss: 0.1033 - val_accuracy: 0.9649\n",
      "Epoch 312/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0402 - accuracy: 0.9912 - val_loss: 0.1128 - val_accuracy: 0.9474\n",
      "Epoch 313/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9474\n",
      "Epoch 314/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0513 - accuracy: 0.9649 - val_loss: 0.1067 - val_accuracy: 0.9649\n",
      "Epoch 315/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0243 - accuracy: 0.9912 - val_loss: 0.0947 - val_accuracy: 0.9649\n",
      "Epoch 316/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0394 - accuracy: 0.9912 - val_loss: 0.0937 - val_accuracy: 0.9649\n",
      "Epoch 317/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 0.1080 - val_accuracy: 0.9474\n",
      "Epoch 318/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0361 - accuracy: 0.9912 - val_loss: 0.1149 - val_accuracy: 0.9474\n",
      "Epoch 319/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9474\n",
      "Epoch 320/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.1044 - val_accuracy: 0.9649\n",
      "Epoch 321/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0261 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9649\n",
      "Epoch 322/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9649\n",
      "Epoch 323/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0349 - accuracy: 0.9825 - val_loss: 0.0781 - val_accuracy: 0.9649\n",
      "Epoch 324/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9649\n",
      "Epoch 325/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.0765 - val_accuracy: 0.9649\n",
      "Epoch 326/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9474\n",
      "Epoch 327/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9474\n",
      "Epoch 328/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0273 - accuracy: 0.9912 - val_loss: 0.0944 - val_accuracy: 0.9474\n",
      "Epoch 329/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.0871 - val_accuracy: 0.9474\n",
      "Epoch 330/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9649\n",
      "Epoch 331/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9649\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 135us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 0.0779 - val_accuracy: 0.9649\n",
      "Epoch 333/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0804 - val_accuracy: 0.9649\n",
      "Epoch 334/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0182 - accuracy: 0.9912 - val_loss: 0.0885 - val_accuracy: 0.9649\n",
      "Epoch 335/1000\n",
      "114/114 [==============================] - 0s 155us/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9649\n",
      "Epoch 336/1000\n",
      "114/114 [==============================] - 0s 173us/step - loss: 0.0188 - accuracy: 0.9912 - val_loss: 0.1084 - val_accuracy: 0.9474\n",
      "Epoch 337/1000\n",
      "114/114 [==============================] - 0s 164us/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9474\n",
      "Epoch 338/1000\n",
      "114/114 [==============================] - 0s 171us/step - loss: 0.0298 - accuracy: 0.9912 - val_loss: 0.1093 - val_accuracy: 0.9474\n",
      "Epoch 339/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0367 - accuracy: 0.9912 - val_loss: 0.0991 - val_accuracy: 0.9649\n",
      "Epoch 340/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0216 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9649\n",
      "Epoch 341/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9649\n",
      "Epoch 342/1000\n",
      "114/114 [==============================] - 0s 157us/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9649\n",
      "Epoch 343/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9649\n",
      "Epoch 344/1000\n",
      "114/114 [==============================] - 0s 156us/step - loss: 0.0282 - accuracy: 0.9912 - val_loss: 0.1088 - val_accuracy: 0.9474\n",
      "Epoch 345/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0245 - accuracy: 0.9912 - val_loss: 0.1045 - val_accuracy: 0.9649\n",
      "Epoch 346/1000\n",
      "114/114 [==============================] - 0s 160us/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9649\n",
      "Epoch 347/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.0208 - accuracy: 0.9912 - val_loss: 0.0786 - val_accuracy: 0.9649\n",
      "Epoch 348/1000\n",
      "114/114 [==============================] - 0s 174us/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9649\n",
      "Epoch 349/1000\n",
      "114/114 [==============================] - 0s 164us/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.0743 - val_accuracy: 0.9474\n",
      "Epoch 350/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9474\n",
      "Epoch 351/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9474\n",
      "Epoch 352/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9474\n",
      "Epoch 353/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9649\n",
      "Epoch 354/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0381 - accuracy: 0.9912 - val_loss: 0.0987 - val_accuracy: 0.9649\n",
      "Epoch 355/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0159 - accuracy: 0.9912 - val_loss: 0.0953 - val_accuracy: 0.9649\n",
      "Epoch 356/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9649\n",
      "Epoch 357/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9649\n",
      "Epoch 358/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0890 - val_accuracy: 0.9649\n",
      "Epoch 359/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9649\n",
      "Epoch 360/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9649\n",
      "Epoch 361/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9649\n",
      "Epoch 362/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9649\n",
      "Epoch 363/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0202 - accuracy: 0.9912 - val_loss: 0.0901 - val_accuracy: 0.9474\n",
      "Epoch 364/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0220 - accuracy: 0.9912 - val_loss: 0.0834 - val_accuracy: 0.9474\n",
      "Epoch 365/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0796 - val_accuracy: 0.9649\n",
      "Epoch 366/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0353 - accuracy: 0.9912 - val_loss: 0.0831 - val_accuracy: 0.9649\n",
      "Epoch 367/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0245 - accuracy: 0.9825 - val_loss: 0.0884 - val_accuracy: 0.9474\n",
      "Epoch 368/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0196 - accuracy: 1.0000 - val_loss: 0.0929 - val_accuracy: 0.9649\n",
      "Epoch 369/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0956 - val_accuracy: 0.9649\n",
      "Epoch 370/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9649\n",
      "Epoch 371/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9649\n",
      "Epoch 372/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0273 - accuracy: 0.9825 - val_loss: 0.0850 - val_accuracy: 0.9649\n",
      "Epoch 373/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9649\n",
      "Epoch 374/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0204 - accuracy: 0.9912 - val_loss: 0.0775 - val_accuracy: 0.9649\n",
      "Epoch 375/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 0.0868 - val_accuracy: 0.9649\n",
      "Epoch 376/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0301 - accuracy: 0.9912 - val_loss: 0.1098 - val_accuracy: 0.9649\n",
      "Epoch 377/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 0.1344 - val_accuracy: 0.9474\n",
      "Epoch 378/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 0.1315 - val_accuracy: 0.9474\n",
      "Epoch 379/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0275 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9649\n",
      "Epoch 380/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0202 - accuracy: 0.9912 - val_loss: 0.0925 - val_accuracy: 0.9649\n",
      "Epoch 381/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9649\n",
      "Epoch 382/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9649\n",
      "Epoch 383/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 0.0703 - val_accuracy: 0.9649\n",
      "Epoch 384/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0489 - accuracy: 0.9737 - val_loss: 0.0848 - val_accuracy: 0.9649\n",
      "Epoch 385/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.1029 - val_accuracy: 0.9649\n",
      "Epoch 386/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9649\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 135us/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9649\n",
      "Epoch 388/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9649\n",
      "Epoch 389/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9649\n",
      "Epoch 390/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9649\n",
      "Epoch 391/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9649\n",
      "Epoch 392/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 0.0924 - val_accuracy: 0.9649\n",
      "Epoch 393/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0433 - accuracy: 0.9825 - val_loss: 0.1005 - val_accuracy: 0.9649\n",
      "Epoch 394/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9649\n",
      "Epoch 395/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0235 - accuracy: 0.9912 - val_loss: 0.1008 - val_accuracy: 0.9474\n",
      "Epoch 396/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0400 - accuracy: 0.9825 - val_loss: 0.0973 - val_accuracy: 0.9474\n",
      "Epoch 397/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9649\n",
      "Epoch 398/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0184 - accuracy: 0.9912 - val_loss: 0.0863 - val_accuracy: 0.9649\n",
      "Epoch 399/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0851 - val_accuracy: 0.9649\n",
      "Epoch 400/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9649\n",
      "Epoch 401/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9649\n",
      "Epoch 402/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9649\n",
      "Epoch 403/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9649\n",
      "Epoch 404/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9649\n",
      "Epoch 405/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.0790 - val_accuracy: 0.9474\n",
      "Epoch 406/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0330 - accuracy: 0.9912 - val_loss: 0.0879 - val_accuracy: 0.9649\n",
      "Epoch 407/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9649\n",
      "Epoch 408/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.1346 - val_accuracy: 0.9298\n",
      "Epoch 409/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.1378 - val_accuracy: 0.9298\n",
      "Epoch 410/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0187 - accuracy: 0.9912 - val_loss: 0.1176 - val_accuracy: 0.9649\n",
      "Epoch 411/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0242 - accuracy: 0.9825 - val_loss: 0.0845 - val_accuracy: 0.9649\n",
      "Epoch 412/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9649\n",
      "Epoch 413/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9825\n",
      "Epoch 414/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0220 - accuracy: 0.9912 - val_loss: 0.0604 - val_accuracy: 0.9649\n",
      "Epoch 415/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0204 - accuracy: 0.9912 - val_loss: 0.0667 - val_accuracy: 0.9474\n",
      "Epoch 416/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0201 - accuracy: 0.9912 - val_loss: 0.0854 - val_accuracy: 0.9474\n",
      "Epoch 417/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 0.1171 - val_accuracy: 0.9474\n",
      "Epoch 418/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0462 - accuracy: 0.9825 - val_loss: 0.1087 - val_accuracy: 0.9474\n",
      "Epoch 419/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0225 - accuracy: 0.9912 - val_loss: 0.0988 - val_accuracy: 0.9474\n",
      "Epoch 420/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9474\n",
      "Epoch 421/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9474\n",
      "Epoch 422/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0875 - val_accuracy: 0.9474\n",
      "Epoch 423/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0286 - accuracy: 0.9912 - val_loss: 0.0802 - val_accuracy: 0.9474\n",
      "Epoch 424/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0321 - accuracy: 0.9912 - val_loss: 0.0793 - val_accuracy: 0.9649\n",
      "Epoch 425/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9649\n",
      "Epoch 426/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0291 - accuracy: 0.9825 - val_loss: 0.0825 - val_accuracy: 0.9649\n",
      "Epoch 427/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9649\n",
      "Epoch 428/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0179 - accuracy: 0.9912 - val_loss: 0.0973 - val_accuracy: 0.9649\n",
      "Epoch 429/1000\n",
      "114/114 [==============================] - 0s 238us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9649\n",
      "Epoch 430/1000\n",
      "114/114 [==============================] - 0s 162us/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9649\n",
      "Epoch 431/1000\n",
      "114/114 [==============================] - 0s 158us/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9649\n",
      "Epoch 432/1000\n",
      "114/114 [==============================] - 0s 217us/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9649\n",
      "Epoch 433/1000\n",
      "114/114 [==============================] - 0s 187us/step - loss: 0.0268 - accuracy: 0.9912 - val_loss: 0.0714 - val_accuracy: 0.9649\n",
      "Epoch 434/1000\n",
      "114/114 [==============================] - 0s 164us/step - loss: 0.0220 - accuracy: 0.9912 - val_loss: 0.0702 - val_accuracy: 0.9649\n",
      "Epoch 435/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0705 - val_accuracy: 0.9649\n",
      "Epoch 436/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0181 - accuracy: 0.9912 - val_loss: 0.0738 - val_accuracy: 0.9649\n",
      "Epoch 437/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0218 - accuracy: 0.9912 - val_loss: 0.0968 - val_accuracy: 0.9649\n",
      "Epoch 438/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9474\n",
      "Epoch 439/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9474\n",
      "Epoch 440/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9474\n",
      "Epoch 441/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.1046 - val_accuracy: 0.9474\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 134us/step - loss: 0.0224 - accuracy: 0.9912 - val_loss: 0.0966 - val_accuracy: 0.9649\n",
      "Epoch 443/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9649\n",
      "Epoch 444/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9649\n",
      "Epoch 445/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9649\n",
      "Epoch 446/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0884 - val_accuracy: 0.9649\n",
      "Epoch 447/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9649\n",
      "Epoch 448/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0217 - accuracy: 0.9825 - val_loss: 0.0769 - val_accuracy: 0.9649\n",
      "Epoch 449/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0228 - accuracy: 0.9912 - val_loss: 0.0763 - val_accuracy: 0.9649\n",
      "Epoch 450/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 0.0821 - val_accuracy: 0.9474\n",
      "Epoch 451/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9474\n",
      "Epoch 452/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9474\n",
      "Epoch 453/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 0.0708 - val_accuracy: 0.9474\n",
      "Epoch 454/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9474\n",
      "Epoch 455/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9474\n",
      "Epoch 456/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9474\n",
      "Epoch 457/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.1385 - val_accuracy: 0.9298\n",
      "Epoch 458/1000\n",
      "114/114 [==============================] - 0s 191us/step - loss: 0.0299 - accuracy: 0.9825 - val_loss: 0.1239 - val_accuracy: 0.9298\n",
      "Epoch 459/1000\n",
      "114/114 [==============================] - 0s 157us/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9649\n",
      "Epoch 460/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0578 - val_accuracy: 0.9649\n",
      "Epoch 461/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0472 - val_accuracy: 0.9825\n",
      "Epoch 462/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 0.0434 - val_accuracy: 0.9825\n",
      "Epoch 463/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0326 - accuracy: 0.9825 - val_loss: 0.0450 - val_accuracy: 0.9825\n",
      "Epoch 464/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.0537 - val_accuracy: 0.9649\n",
      "Epoch 465/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9649\n",
      "Epoch 466/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.0679 - val_accuracy: 0.9649\n",
      "Epoch 467/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0171 - accuracy: 0.9912 - val_loss: 0.0783 - val_accuracy: 0.9649\n",
      "Epoch 468/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0892 - val_accuracy: 0.9649\n",
      "Epoch 469/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0287 - accuracy: 0.9825 - val_loss: 0.0978 - val_accuracy: 0.9649\n",
      "Epoch 470/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0117 - accuracy: 0.9912 - val_loss: 0.0963 - val_accuracy: 0.9649\n",
      "Epoch 471/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9649\n",
      "Epoch 472/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9649\n",
      "Epoch 473/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9474\n",
      "Epoch 474/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0223 - accuracy: 0.9912 - val_loss: 0.1019 - val_accuracy: 0.9474\n",
      "Epoch 475/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9474\n",
      "Epoch 476/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9474\n",
      "Epoch 477/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0156 - accuracy: 0.9912 - val_loss: 0.0761 - val_accuracy: 0.9649\n",
      "Epoch 478/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9649\n",
      "Epoch 479/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9649\n",
      "Epoch 480/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0784 - val_accuracy: 0.9649\n",
      "Epoch 481/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9649\n",
      "Epoch 482/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9649\n",
      "Epoch 483/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9649\n",
      "Epoch 484/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0138 - accuracy: 0.9912 - val_loss: 0.0878 - val_accuracy: 0.9474\n",
      "Epoch 485/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0808 - val_accuracy: 0.9474\n",
      "Epoch 486/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9474\n",
      "Epoch 487/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0165 - accuracy: 0.9912 - val_loss: 0.0804 - val_accuracy: 0.9474\n",
      "Epoch 488/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0885 - val_accuracy: 0.9474\n",
      "Epoch 489/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9649\n",
      "Epoch 490/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0179 - accuracy: 0.9912 - val_loss: 0.0981 - val_accuracy: 0.9649\n",
      "Epoch 491/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9649\n",
      "Epoch 492/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0125 - accuracy: 0.9912 - val_loss: 0.1007 - val_accuracy: 0.9649\n",
      "Epoch 493/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9649\n",
      "Epoch 494/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9649\n",
      "Epoch 495/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0763 - val_accuracy: 0.9649\n",
      "Epoch 496/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0721 - val_accuracy: 0.9649\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 130us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0719 - val_accuracy: 0.9649\n",
      "Epoch 498/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9649\n",
      "Epoch 499/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9649\n",
      "Epoch 500/1000\n",
      "114/114 [==============================] - 0s 125us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9649\n",
      "Epoch 501/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0176 - accuracy: 0.9912 - val_loss: 0.0823 - val_accuracy: 0.9649\n",
      "Epoch 502/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0359 - accuracy: 0.9825 - val_loss: 0.1177 - val_accuracy: 0.9474\n",
      "Epoch 503/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0239 - accuracy: 0.9912 - val_loss: 0.1403 - val_accuracy: 0.9474\n",
      "Epoch 504/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9474\n",
      "Epoch 505/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1352 - val_accuracy: 0.9474\n",
      "Epoch 506/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9474\n",
      "Epoch 507/1000\n",
      "114/114 [==============================] - 0s 125us/step - loss: 0.0122 - accuracy: 0.9912 - val_loss: 0.1101 - val_accuracy: 0.9474\n",
      "Epoch 508/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9649\n",
      "Epoch 509/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9649\n",
      "Epoch 510/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0215 - accuracy: 0.9912 - val_loss: 0.1054 - val_accuracy: 0.9474\n",
      "Epoch 511/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0238 - accuracy: 0.9825 - val_loss: 0.1203 - val_accuracy: 0.9474\n",
      "Epoch 512/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.1294 - val_accuracy: 0.9474\n",
      "Epoch 513/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0331 - accuracy: 0.9912 - val_loss: 0.1470 - val_accuracy: 0.9474\n",
      "Epoch 514/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0198 - accuracy: 0.9912 - val_loss: 0.1306 - val_accuracy: 0.9474\n",
      "Epoch 515/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0156 - accuracy: 0.9912 - val_loss: 0.0999 - val_accuracy: 0.9474\n",
      "Epoch 516/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9649\n",
      "Epoch 517/1000\n",
      "114/114 [==============================] - 0s 153us/step - loss: 0.0130 - accuracy: 0.9912 - val_loss: 0.0641 - val_accuracy: 0.9649\n",
      "Epoch 518/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9649\n",
      "Epoch 519/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0210 - accuracy: 0.9912 - val_loss: 0.0791 - val_accuracy: 0.9649\n",
      "Epoch 520/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9649\n",
      "Epoch 521/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9649\n",
      "Epoch 522/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9649\n",
      "Epoch 523/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9649\n",
      "Epoch 524/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9649\n",
      "Epoch 525/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9649\n",
      "Epoch 526/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0127 - accuracy: 0.9912 - val_loss: 0.0672 - val_accuracy: 0.9649\n",
      "Epoch 527/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0338 - accuracy: 0.9825 - val_loss: 0.0847 - val_accuracy: 0.9649\n",
      "Epoch 528/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9649\n",
      "Epoch 529/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9474\n",
      "Epoch 530/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0194 - accuracy: 0.9912 - val_loss: 0.0919 - val_accuracy: 0.9649\n",
      "Epoch 531/1000\n",
      "114/114 [==============================] - 0s 124us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0778 - val_accuracy: 0.9649\n",
      "Epoch 532/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9649\n",
      "Epoch 533/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0612 - val_accuracy: 0.9649\n",
      "Epoch 534/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0587 - val_accuracy: 0.9649\n",
      "Epoch 535/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 0.9649\n",
      "Epoch 536/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0565 - val_accuracy: 0.9649\n",
      "Epoch 537/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0566 - val_accuracy: 0.9649\n",
      "Epoch 538/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9649\n",
      "Epoch 539/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9649\n",
      "Epoch 540/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9649\n",
      "Epoch 541/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9649\n",
      "Epoch 542/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0939 - val_accuracy: 0.9649\n",
      "Epoch 543/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0933 - val_accuracy: 0.9649\n",
      "Epoch 544/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9649\n",
      "Epoch 545/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9649\n",
      "Epoch 546/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9649\n",
      "Epoch 547/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0947 - val_accuracy: 0.9649\n",
      "Epoch 548/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0905 - val_accuracy: 0.9649\n",
      "Epoch 549/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9649\n",
      "Epoch 550/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0858 - val_accuracy: 0.9649\n",
      "Epoch 551/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0273 - accuracy: 0.9825 - val_loss: 0.0844 - val_accuracy: 0.9474\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 133us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9474\n",
      "Epoch 553/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9474\n",
      "Epoch 554/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0724 - val_accuracy: 0.9474\n",
      "Epoch 555/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0878 - val_accuracy: 0.9649\n",
      "Epoch 556/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9649\n",
      "Epoch 557/1000\n",
      "114/114 [==============================] - 0s 125us/step - loss: 0.0105 - accuracy: 0.9912 - val_loss: 0.0908 - val_accuracy: 0.9649\n",
      "Epoch 558/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9649\n",
      "Epoch 559/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9649\n",
      "Epoch 560/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1148 - val_accuracy: 0.9649\n",
      "Epoch 561/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9649\n",
      "Epoch 562/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9474\n",
      "Epoch 563/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9474\n",
      "Epoch 564/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9649\n",
      "Epoch 565/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0886 - val_accuracy: 0.9649\n",
      "Epoch 566/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9649\n",
      "Epoch 567/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9649\n",
      "Epoch 568/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0740 - val_accuracy: 0.9649\n",
      "Epoch 569/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0774 - val_accuracy: 0.9649\n",
      "Epoch 570/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9649\n",
      "Epoch 571/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0133 - accuracy: 0.9912 - val_loss: 0.0853 - val_accuracy: 0.9649\n",
      "Epoch 572/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9649\n",
      "Epoch 573/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9649\n",
      "Epoch 574/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9649\n",
      "Epoch 575/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9649\n",
      "Epoch 576/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9649\n",
      "Epoch 577/1000\n",
      "114/114 [==============================] - 0s 149us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9649\n",
      "Epoch 578/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9649\n",
      "Epoch 579/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0942 - val_accuracy: 0.9649\n",
      "Epoch 580/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9474\n",
      "Epoch 581/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9474\n",
      "Epoch 582/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9474\n",
      "Epoch 583/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0198 - accuracy: 0.9912 - val_loss: 0.0988 - val_accuracy: 0.9474\n",
      "Epoch 584/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0951 - val_accuracy: 0.9474\n",
      "Epoch 585/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9474\n",
      "Epoch 586/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0845 - val_accuracy: 0.9649\n",
      "Epoch 587/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0816 - val_accuracy: 0.9649\n",
      "Epoch 588/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0765 - val_accuracy: 0.9649\n",
      "Epoch 589/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9649\n",
      "Epoch 590/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0666 - val_accuracy: 0.9649\n",
      "Epoch 591/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9649\n",
      "Epoch 592/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0576 - val_accuracy: 0.9649\n",
      "Epoch 593/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0546 - val_accuracy: 0.9649\n",
      "Epoch 594/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9474\n",
      "Epoch 595/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.0652 - val_accuracy: 0.9649\n",
      "Epoch 596/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0806 - val_accuracy: 0.9649\n",
      "Epoch 597/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9649\n",
      "Epoch 598/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0217 - accuracy: 0.9912 - val_loss: 0.1080 - val_accuracy: 0.9649\n",
      "Epoch 599/1000\n",
      "114/114 [==============================] - 0s 125us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9649\n",
      "Epoch 600/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0171 - accuracy: 0.9912 - val_loss: 0.1131 - val_accuracy: 0.9649\n",
      "Epoch 601/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9474\n",
      "Epoch 602/1000\n",
      "114/114 [==============================] - 0s 160us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9474\n",
      "Epoch 603/1000\n",
      "114/114 [==============================] - 0s 156us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9474\n",
      "Epoch 604/1000\n",
      "114/114 [==============================] - 0s 156us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9649\n",
      "Epoch 605/1000\n",
      "114/114 [==============================] - 0s 154us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9649\n",
      "Epoch 606/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0165 - accuracy: 0.9912 - val_loss: 0.0803 - val_accuracy: 0.9649\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 145us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 0.9649\n",
      "Epoch 608/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0687 - val_accuracy: 0.9649\n",
      "Epoch 609/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0269 - accuracy: 0.9912 - val_loss: 0.0810 - val_accuracy: 0.9649\n",
      "Epoch 610/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9649\n",
      "Epoch 611/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0106 - accuracy: 0.9912 - val_loss: 0.0993 - val_accuracy: 0.9649\n",
      "Epoch 612/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9649\n",
      "Epoch 613/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9649\n",
      "Epoch 614/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9649\n",
      "Epoch 615/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9649\n",
      "Epoch 616/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9649\n",
      "Epoch 617/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9474\n",
      "Epoch 618/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9474\n",
      "Epoch 619/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9474\n",
      "Epoch 620/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0227 - accuracy: 0.9912 - val_loss: 0.1035 - val_accuracy: 0.9474\n",
      "Epoch 621/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9474\n",
      "Epoch 622/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9649\n",
      "Epoch 623/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9649\n",
      "Epoch 624/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9649\n",
      "Epoch 625/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9649\n",
      "Epoch 626/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9649\n",
      "Epoch 627/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9649\n",
      "Epoch 628/1000\n",
      "114/114 [==============================] - 0s 125us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9649\n",
      "Epoch 629/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9649\n",
      "Epoch 630/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9649\n",
      "Epoch 631/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9474\n",
      "Epoch 632/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9474\n",
      "Epoch 633/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 0.9474\n",
      "Epoch 634/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9474\n",
      "Epoch 635/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0645 - val_accuracy: 0.9649\n",
      "Epoch 636/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0628 - val_accuracy: 0.9649\n",
      "Epoch 637/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9649\n",
      "Epoch 638/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9649\n",
      "Epoch 639/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9649\n",
      "Epoch 640/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 8.7103e-04 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9649\n",
      "Epoch 641/1000\n",
      "114/114 [==============================] - 0s 150us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0826 - val_accuracy: 0.9649\n",
      "Epoch 642/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0802 - val_accuracy: 0.9649\n",
      "Epoch 643/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0790 - val_accuracy: 0.9649\n",
      "Epoch 644/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9649\n",
      "Epoch 645/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9649\n",
      "Epoch 646/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0727 - val_accuracy: 0.9649\n",
      "Epoch 647/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0709 - val_accuracy: 0.9474\n",
      "Epoch 648/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 0.9474\n",
      "Epoch 649/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0741 - val_accuracy: 0.9474\n",
      "Epoch 650/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0139 - accuracy: 0.9912 - val_loss: 0.0783 - val_accuracy: 0.9474\n",
      "Epoch 651/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9649\n",
      "Epoch 652/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1006 - val_accuracy: 0.9649\n",
      "Epoch 653/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9649\n",
      "Epoch 654/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9649\n",
      "Epoch 655/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 0.9649\n",
      "Epoch 656/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9649\n",
      "Epoch 657/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9649\n",
      "Epoch 658/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0100 - accuracy: 0.9912 - val_loss: 0.0611 - val_accuracy: 0.9649\n",
      "Epoch 659/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0579 - val_accuracy: 0.9649\n",
      "Epoch 660/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0555 - val_accuracy: 0.9649\n",
      "Epoch 661/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9649\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 129us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9649\n",
      "Epoch 663/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0160 - accuracy: 0.9912 - val_loss: 0.0667 - val_accuracy: 0.9649\n",
      "Epoch 664/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0795 - val_accuracy: 0.9649\n",
      "Epoch 665/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9649\n",
      "Epoch 666/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0289 - accuracy: 0.9912 - val_loss: 0.1204 - val_accuracy: 0.9474\n",
      "Epoch 667/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.1455 - val_accuracy: 0.9298\n",
      "Epoch 668/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9474\n",
      "Epoch 669/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9474\n",
      "Epoch 670/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9649\n",
      "Epoch 671/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.0638 - val_accuracy: 0.9649\n",
      "Epoch 672/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0150 - accuracy: 0.9912 - val_loss: 0.0633 - val_accuracy: 0.9649\n",
      "Epoch 673/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9649\n",
      "Epoch 674/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9649\n",
      "Epoch 675/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9649\n",
      "Epoch 676/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9649\n",
      "Epoch 677/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0166 - accuracy: 0.9912 - val_loss: 0.0960 - val_accuracy: 0.9649\n",
      "Epoch 678/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9649\n",
      "Epoch 679/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9649\n",
      "Epoch 680/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9649\n",
      "Epoch 681/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9649\n",
      "Epoch 682/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9649\n",
      "Epoch 683/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9649\n",
      "Epoch 684/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9649\n",
      "Epoch 685/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9649\n",
      "Epoch 686/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0697 - val_accuracy: 0.9649\n",
      "Epoch 687/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0165 - accuracy: 0.9912 - val_loss: 0.0674 - val_accuracy: 0.9649\n",
      "Epoch 688/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0661 - val_accuracy: 0.9649\n",
      "Epoch 689/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0215 - accuracy: 0.9912 - val_loss: 0.0900 - val_accuracy: 0.9649\n",
      "Epoch 690/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9474\n",
      "Epoch 691/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1273 - val_accuracy: 0.9474\n",
      "Epoch 692/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9474\n",
      "Epoch 693/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0978 - val_accuracy: 0.9649\n",
      "Epoch 694/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9649\n",
      "Epoch 695/1000\n",
      "114/114 [==============================] - 0s 151us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9649\n",
      "Epoch 696/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0189 - accuracy: 0.9912 - val_loss: 0.0515 - val_accuracy: 0.9649\n",
      "Epoch 697/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9649\n",
      "Epoch 698/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0556 - val_accuracy: 0.9649\n",
      "Epoch 699/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0119 - accuracy: 0.9912 - val_loss: 0.0733 - val_accuracy: 0.9649\n",
      "Epoch 700/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0411 - accuracy: 0.9825 - val_loss: 0.0895 - val_accuracy: 0.9649\n",
      "Epoch 701/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9649\n",
      "Epoch 702/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9474\n",
      "Epoch 703/1000\n",
      "114/114 [==============================] - 0s 155us/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9474\n",
      "Epoch 704/1000\n",
      "114/114 [==============================] - 0s 154us/step - loss: 0.0162 - accuracy: 0.9912 - val_loss: 0.0970 - val_accuracy: 0.9649\n",
      "Epoch 705/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9649\n",
      "Epoch 706/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0156 - accuracy: 0.9912 - val_loss: 0.0682 - val_accuracy: 0.9649\n",
      "Epoch 707/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9474\n",
      "Epoch 708/1000\n",
      "114/114 [==============================] - 0s 235us/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0749 - val_accuracy: 0.9474\n",
      "Epoch 709/1000\n",
      "114/114 [==============================] - 0s 154us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0827 - val_accuracy: 0.9474\n",
      "Epoch 710/1000\n",
      "114/114 [==============================] - 0s 150us/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 0.0832 - val_accuracy: 0.9474\n",
      "Epoch 711/1000\n",
      "114/114 [==============================] - 0s 201us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9298\n",
      "Epoch 712/1000\n",
      "114/114 [==============================] - 0s 260us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9474\n",
      "Epoch 713/1000\n",
      "114/114 [==============================] - 0s 280us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9474\n",
      "Epoch 714/1000\n",
      "114/114 [==============================] - 0s 235us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9649\n",
      "Epoch 715/1000\n",
      "114/114 [==============================] - 0s 192us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0934 - val_accuracy: 0.9649\n",
      "Epoch 716/1000\n",
      "114/114 [==============================] - 0s 180us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9649\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 153us/step - loss: 0.0342 - accuracy: 0.9912 - val_loss: 0.0836 - val_accuracy: 0.9649\n",
      "Epoch 718/1000\n",
      "114/114 [==============================] - 0s 151us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9474\n",
      "Epoch 719/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9474\n",
      "Epoch 720/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9474\n",
      "Epoch 721/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9474\n",
      "Epoch 722/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0879 - val_accuracy: 0.9474\n",
      "Epoch 723/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0149 - accuracy: 0.9912 - val_loss: 0.0876 - val_accuracy: 0.9649\n",
      "Epoch 724/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9649\n",
      "Epoch 725/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0212 - accuracy: 0.9912 - val_loss: 0.1032 - val_accuracy: 0.9649\n",
      "Epoch 726/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1023 - val_accuracy: 0.9649\n",
      "Epoch 727/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1004 - val_accuracy: 0.9649\n",
      "Epoch 728/1000\n",
      "114/114 [==============================] - 0s 233us/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9649\n",
      "Epoch 729/1000\n",
      "114/114 [==============================] - 0s 172us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9649\n",
      "Epoch 730/1000\n",
      "114/114 [==============================] - 0s 157us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0715 - val_accuracy: 0.9649\n",
      "Epoch 731/1000\n",
      "114/114 [==============================] - 0s 205us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0617 - val_accuracy: 0.9649\n",
      "Epoch 732/1000\n",
      "114/114 [==============================] - 0s 171us/step - loss: 0.0122 - accuracy: 0.9912 - val_loss: 0.0600 - val_accuracy: 0.9649\n",
      "Epoch 733/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0571 - val_accuracy: 0.9649\n",
      "Epoch 734/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9649\n",
      "Epoch 735/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0552 - val_accuracy: 0.9649\n",
      "Epoch 736/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0563 - val_accuracy: 0.9649\n",
      "Epoch 737/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0605 - val_accuracy: 0.9649\n",
      "Epoch 738/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9649\n",
      "Epoch 739/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0242 - accuracy: 0.9912 - val_loss: 0.0590 - val_accuracy: 0.9649\n",
      "Epoch 740/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0567 - val_accuracy: 0.9649\n",
      "Epoch 741/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0181 - accuracy: 0.9912 - val_loss: 0.0598 - val_accuracy: 0.9825\n",
      "Epoch 742/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0657 - val_accuracy: 0.9825\n",
      "Epoch 743/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0092 - accuracy: 0.9912 - val_loss: 0.0726 - val_accuracy: 0.9825\n",
      "Epoch 744/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9649\n",
      "Epoch 745/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0109 - accuracy: 0.9912 - val_loss: 0.0935 - val_accuracy: 0.9649\n",
      "Epoch 746/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9649\n",
      "Epoch 747/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9649\n",
      "Epoch 748/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9649\n",
      "Epoch 749/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9649\n",
      "Epoch 750/1000\n",
      "114/114 [==============================] - 0s 151us/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9649\n",
      "Epoch 751/1000\n",
      "114/114 [==============================] - 0s 151us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0664 - val_accuracy: 0.9649\n",
      "Epoch 752/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0620 - val_accuracy: 0.9649\n",
      "Epoch 753/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0609 - val_accuracy: 0.9649\n",
      "Epoch 754/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0695 - val_accuracy: 0.9474\n",
      "Epoch 755/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9474\n",
      "Epoch 756/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0205 - accuracy: 0.9912 - val_loss: 0.1427 - val_accuracy: 0.9474\n",
      "Epoch 757/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0140 - accuracy: 0.9912 - val_loss: 0.1426 - val_accuracy: 0.9474\n",
      "Epoch 758/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9474\n",
      "Epoch 759/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0161 - accuracy: 0.9912 - val_loss: 0.0929 - val_accuracy: 0.9649\n",
      "Epoch 760/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9649\n",
      "Epoch 761/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0521 - val_accuracy: 0.9649\n",
      "Epoch 762/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0458 - val_accuracy: 0.9825\n",
      "Epoch 763/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0206 - accuracy: 0.9912 - val_loss: 0.0475 - val_accuracy: 0.9649\n",
      "Epoch 764/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0161 - accuracy: 0.9912 - val_loss: 0.0677 - val_accuracy: 0.9649\n",
      "Epoch 765/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9649\n",
      "Epoch 766/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.1499 - val_accuracy: 0.9298\n",
      "Epoch 767/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.1336 - val_accuracy: 0.9474\n",
      "Epoch 768/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9649\n",
      "Epoch 769/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0704 - val_accuracy: 0.9649\n",
      "Epoch 770/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0523 - val_accuracy: 0.9649\n",
      "Epoch 771/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0147 - accuracy: 0.9912 - val_loss: 0.0467 - val_accuracy: 0.9649\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 132us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0477 - val_accuracy: 0.9649\n",
      "Epoch 773/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.0496 - val_accuracy: 0.9649\n",
      "Epoch 774/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0575 - val_accuracy: 0.9649\n",
      "Epoch 775/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9649\n",
      "Epoch 776/1000\n",
      "114/114 [==============================] - 0s 150us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9649\n",
      "Epoch 777/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0835 - val_accuracy: 0.9649\n",
      "Epoch 778/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0869 - val_accuracy: 0.9649\n",
      "Epoch 779/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9649\n",
      "Epoch 780/1000\n",
      "114/114 [==============================] - 0s 150us/step - loss: 0.0171 - accuracy: 0.9912 - val_loss: 0.0741 - val_accuracy: 0.9649\n",
      "Epoch 781/1000\n",
      "114/114 [==============================] - 0s 152us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0545 - val_accuracy: 0.9649\n",
      "Epoch 782/1000\n",
      "114/114 [==============================] - 0s 172us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0443 - val_accuracy: 0.9649\n",
      "Epoch 783/1000\n",
      "114/114 [==============================] - 0s 161us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0445 - val_accuracy: 0.9649\n",
      "Epoch 784/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9649\n",
      "Epoch 785/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0214 - accuracy: 0.9912 - val_loss: 0.0587 - val_accuracy: 0.9649\n",
      "Epoch 786/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9649\n",
      "Epoch 787/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9649\n",
      "Epoch 788/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9649\n",
      "Epoch 789/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0115 - accuracy: 0.9912 - val_loss: 0.0846 - val_accuracy: 0.9649\n",
      "Epoch 790/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9649\n",
      "Epoch 791/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0312 - accuracy: 0.9825 - val_loss: 0.0808 - val_accuracy: 0.9649\n",
      "Epoch 792/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9649\n",
      "Epoch 793/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9649\n",
      "Epoch 794/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9649\n",
      "Epoch 795/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0564 - val_accuracy: 0.9649\n",
      "Epoch 796/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9649\n",
      "Epoch 797/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0489 - val_accuracy: 0.9649\n",
      "Epoch 798/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0159 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9649\n",
      "Epoch 799/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0602 - val_accuracy: 0.9649\n",
      "Epoch 800/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9649\n",
      "Epoch 801/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.0871 - val_accuracy: 0.9649\n",
      "Epoch 802/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0988 - val_accuracy: 0.9649\n",
      "Epoch 803/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9649\n",
      "Epoch 804/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9649\n",
      "Epoch 805/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0831 - val_accuracy: 0.9649\n",
      "Epoch 806/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9649\n",
      "Epoch 807/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.0677 - val_accuracy: 0.9649\n",
      "Epoch 808/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0624 - val_accuracy: 0.9649\n",
      "Epoch 809/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9649\n",
      "Epoch 810/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0547 - val_accuracy: 0.9649\n",
      "Epoch 811/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 5.4488e-04 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9649\n",
      "Epoch 812/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0536 - val_accuracy: 0.9649\n",
      "Epoch 813/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0085 - accuracy: 0.9912 - val_loss: 0.0624 - val_accuracy: 0.9649\n",
      "Epoch 814/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9649\n",
      "Epoch 815/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 9.8465e-04 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9649\n",
      "Epoch 816/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1001 - val_accuracy: 0.9649\n",
      "Epoch 817/1000\n",
      "114/114 [==============================] - 0s 126us/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9649\n",
      "Epoch 818/1000\n",
      "114/114 [==============================] - 0s 125us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9649\n",
      "Epoch 819/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0105 - accuracy: 0.9912 - val_loss: 0.0703 - val_accuracy: 0.9649\n",
      "Epoch 820/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9649\n",
      "Epoch 821/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0551 - val_accuracy: 0.9649\n",
      "Epoch 822/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0529 - val_accuracy: 0.9649\n",
      "Epoch 823/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 0.9649\n",
      "Epoch 824/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0559 - val_accuracy: 0.9649\n",
      "Epoch 825/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0599 - val_accuracy: 0.9649\n",
      "Epoch 826/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 6.7799e-04 - accuracy: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9649\n",
      "Epoch 827/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 138us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0671 - val_accuracy: 0.9649\n",
      "Epoch 828/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0145 - accuracy: 0.9912 - val_loss: 0.0760 - val_accuracy: 0.9649\n",
      "Epoch 829/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9649\n",
      "Epoch 830/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0821 - val_accuracy: 0.9649\n",
      "Epoch 831/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9649\n",
      "Epoch 832/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9649\n",
      "Epoch 833/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0225 - accuracy: 0.9912 - val_loss: 0.0863 - val_accuracy: 0.9649\n",
      "Epoch 834/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 0.9649\n",
      "Epoch 835/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0264 - accuracy: 0.9912 - val_loss: 0.1115 - val_accuracy: 0.9649\n",
      "Epoch 836/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9649\n",
      "Epoch 837/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9649\n",
      "Epoch 838/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.1081 - val_accuracy: 0.9649\n",
      "Epoch 839/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9649\n",
      "Epoch 840/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0203 - accuracy: 0.9912 - val_loss: 0.0699 - val_accuracy: 0.9649\n",
      "Epoch 841/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0549 - val_accuracy: 0.9649\n",
      "Epoch 842/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0438 - val_accuracy: 0.9825\n",
      "Epoch 843/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0371 - val_accuracy: 0.9825\n",
      "Epoch 844/1000\n",
      "114/114 [==============================] - 0s 183us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9825\n",
      "Epoch 845/1000\n",
      "114/114 [==============================] - 0s 187us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9825\n",
      "Epoch 846/1000\n",
      "114/114 [==============================] - 0s 311us/step - loss: 0.0177 - accuracy: 0.9912 - val_loss: 0.0444 - val_accuracy: 0.9649\n",
      "Epoch 847/1000\n",
      "114/114 [==============================] - 0s 174us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0613 - val_accuracy: 0.9649\n",
      "Epoch 848/1000\n",
      "114/114 [==============================] - 0s 161us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0793 - val_accuracy: 0.9649\n",
      "Epoch 849/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9649\n",
      "Epoch 850/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0975 - val_accuracy: 0.9649\n",
      "Epoch 851/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9649\n",
      "Epoch 852/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0615 - val_accuracy: 0.9649\n",
      "Epoch 853/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0467 - val_accuracy: 0.9649\n",
      "Epoch 854/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9825\n",
      "Epoch 855/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0087 - accuracy: 0.9912 - val_loss: 0.0389 - val_accuracy: 0.9825\n",
      "Epoch 856/1000\n",
      "114/114 [==============================] - 0s 170us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0388 - val_accuracy: 0.9825\n",
      "Epoch 857/1000\n",
      "114/114 [==============================] - 0s 168us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9649\n",
      "Epoch 858/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9649\n",
      "Epoch 859/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0572 - val_accuracy: 0.9474\n",
      "Epoch 860/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0733 - val_accuracy: 0.9474\n",
      "Epoch 861/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0126 - accuracy: 0.9912 - val_loss: 0.0947 - val_accuracy: 0.9474\n",
      "Epoch 862/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0299 - accuracy: 0.9912 - val_loss: 0.0906 - val_accuracy: 0.9649\n",
      "Epoch 863/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9649\n",
      "Epoch 864/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0088 - accuracy: 0.9912 - val_loss: 0.0693 - val_accuracy: 0.9649\n",
      "Epoch 865/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0776 - val_accuracy: 0.9649\n",
      "Epoch 866/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9649\n",
      "Epoch 867/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9649\n",
      "Epoch 868/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9649\n",
      "Epoch 869/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9649\n",
      "Epoch 870/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9649\n",
      "Epoch 871/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0125 - accuracy: 0.9912 - val_loss: 0.1152 - val_accuracy: 0.9649\n",
      "Epoch 872/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0927 - val_accuracy: 0.9649\n",
      "Epoch 873/1000\n",
      "114/114 [==============================] - 0s 168us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0803 - val_accuracy: 0.9649\n",
      "Epoch 874/1000\n",
      "114/114 [==============================] - 0s 158us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0725 - val_accuracy: 0.9649\n",
      "Epoch 875/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9649\n",
      "Epoch 876/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0658 - val_accuracy: 0.9649\n",
      "Epoch 877/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9649\n",
      "Epoch 878/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0797 - val_accuracy: 0.9649\n",
      "Epoch 879/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9649\n",
      "Epoch 880/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9649\n",
      "Epoch 881/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0925 - val_accuracy: 0.9649\n",
      "Epoch 882/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 136us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0974 - val_accuracy: 0.9649\n",
      "Epoch 883/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9649\n",
      "Epoch 884/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0234 - accuracy: 0.9912 - val_loss: 0.0904 - val_accuracy: 0.9649\n",
      "Epoch 885/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0091 - accuracy: 0.9912 - val_loss: 0.0718 - val_accuracy: 0.9649\n",
      "Epoch 886/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9649\n",
      "Epoch 887/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0553 - val_accuracy: 0.9649\n",
      "Epoch 888/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0163 - accuracy: 0.9912 - val_loss: 0.0576 - val_accuracy: 0.9649\n",
      "Epoch 889/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0135 - accuracy: 0.9912 - val_loss: 0.0707 - val_accuracy: 0.9649\n",
      "Epoch 890/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0841 - val_accuracy: 0.9649\n",
      "Epoch 891/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9649\n",
      "Epoch 892/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9649\n",
      "Epoch 893/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9649\n",
      "Epoch 894/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0137 - accuracy: 0.9912 - val_loss: 0.0863 - val_accuracy: 0.9649\n",
      "Epoch 895/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0230 - accuracy: 0.9912 - val_loss: 0.0804 - val_accuracy: 0.9649\n",
      "Epoch 896/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9649\n",
      "Epoch 897/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9649\n",
      "Epoch 898/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0717 - val_accuracy: 0.9825\n",
      "Epoch 899/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0126 - accuracy: 0.9912 - val_loss: 0.0557 - val_accuracy: 0.9649\n",
      "Epoch 900/1000\n",
      "114/114 [==============================] - 0s 132us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.0535 - val_accuracy: 0.9649\n",
      "Epoch 901/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0591 - val_accuracy: 0.9649\n",
      "Epoch 902/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9649\n",
      "Epoch 903/1000\n",
      "114/114 [==============================] - 0s 127us/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0655 - val_accuracy: 0.9649\n",
      "Epoch 904/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0174 - accuracy: 0.9912 - val_loss: 0.0707 - val_accuracy: 0.9649\n",
      "Epoch 905/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9649\n",
      "Epoch 906/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9649\n",
      "Epoch 907/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.1201 - val_accuracy: 0.9649\n",
      "Epoch 908/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9649\n",
      "Epoch 909/1000\n",
      "114/114 [==============================] - 0s 131us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9649\n",
      "Epoch 910/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9649\n",
      "Epoch 911/1000\n",
      "114/114 [==============================] - 0s 128us/step - loss: 0.0126 - accuracy: 0.9912 - val_loss: 0.1002 - val_accuracy: 0.9474\n",
      "Epoch 912/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0899 - val_accuracy: 0.9298\n",
      "Epoch 913/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9298\n",
      "Epoch 914/1000\n",
      "114/114 [==============================] - 0s 129us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0754 - val_accuracy: 0.9298\n",
      "Epoch 915/1000\n",
      "114/114 [==============================] - 0s 130us/step - loss: 0.0205 - accuracy: 0.9912 - val_loss: 0.0815 - val_accuracy: 0.9298\n",
      "Epoch 916/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0115 - accuracy: 0.9912 - val_loss: 0.0969 - val_accuracy: 0.9298\n",
      "Epoch 917/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9474\n",
      "Epoch 918/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9474\n",
      "Epoch 919/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.1113 - val_accuracy: 0.9649\n",
      "Epoch 920/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0164 - accuracy: 0.9912 - val_loss: 0.0963 - val_accuracy: 0.9649\n",
      "Epoch 921/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0846 - val_accuracy: 0.9649\n",
      "Epoch 922/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9649\n",
      "Epoch 923/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9649\n",
      "Epoch 924/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0770 - val_accuracy: 0.9649\n",
      "Epoch 925/1000\n",
      "114/114 [==============================] - 0s 147us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0768 - val_accuracy: 0.9649\n",
      "Epoch 926/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0769 - val_accuracy: 0.9649\n",
      "Epoch 927/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0775 - val_accuracy: 0.9649\n",
      "Epoch 928/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0102 - accuracy: 0.9912 - val_loss: 0.0787 - val_accuracy: 0.9649\n",
      "Epoch 929/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0791 - val_accuracy: 0.9649\n",
      "Epoch 930/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0792 - val_accuracy: 0.9649\n",
      "Epoch 931/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0786 - val_accuracy: 0.9649\n",
      "Epoch 932/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9649\n",
      "Epoch 933/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9649\n",
      "Epoch 934/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9649\n",
      "Epoch 935/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9649\n",
      "Epoch 936/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9649\n",
      "Epoch 937/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 148us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0810 - val_accuracy: 0.9649\n",
      "Epoch 938/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9649\n",
      "Epoch 939/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9649\n",
      "Epoch 940/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 9.1356e-04 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9649\n",
      "Epoch 941/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0711 - val_accuracy: 0.9649\n",
      "Epoch 942/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0122 - accuracy: 0.9912 - val_loss: 0.0762 - val_accuracy: 0.9649\n",
      "Epoch 943/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0923 - val_accuracy: 0.9649\n",
      "Epoch 944/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9649\n",
      "Epoch 945/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0092 - accuracy: 0.9912 - val_loss: 0.1238 - val_accuracy: 0.9649\n",
      "Epoch 946/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9649\n",
      "Epoch 947/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9649\n",
      "Epoch 948/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0075 - accuracy: 0.9912 - val_loss: 0.0896 - val_accuracy: 0.9649\n",
      "Epoch 949/1000\n",
      "114/114 [==============================] - 0s 144us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.0837 - val_accuracy: 0.9649\n",
      "Epoch 950/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0815 - val_accuracy: 0.9649\n",
      "Epoch 951/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9649\n",
      "Epoch 952/1000\n",
      "114/114 [==============================] - 0s 135us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0833 - val_accuracy: 0.9649\n",
      "Epoch 953/1000\n",
      "114/114 [==============================] - 0s 133us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0887 - val_accuracy: 0.9649\n",
      "Epoch 954/1000\n",
      "114/114 [==============================] - 0s 136us/step - loss: 0.0207 - accuracy: 0.9912 - val_loss: 0.1015 - val_accuracy: 0.9649\n",
      "Epoch 955/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9649\n",
      "Epoch 956/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.1190 - val_accuracy: 0.9649\n",
      "Epoch 957/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0174 - accuracy: 0.9912 - val_loss: 0.1193 - val_accuracy: 0.9649\n",
      "Epoch 958/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1138 - val_accuracy: 0.9649\n",
      "Epoch 959/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.1034 - val_accuracy: 0.9474\n",
      "Epoch 960/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0950 - val_accuracy: 0.9649\n",
      "Epoch 961/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0904 - val_accuracy: 0.9649\n",
      "Epoch 962/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0844 - val_accuracy: 0.9649\n",
      "Epoch 963/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0747 - val_accuracy: 0.9649\n",
      "Epoch 964/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0681 - val_accuracy: 0.9474\n",
      "Epoch 965/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0632 - val_accuracy: 0.9649\n",
      "Epoch 966/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0590 - val_accuracy: 0.9649\n",
      "Epoch 967/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9649\n",
      "Epoch 968/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0748 - val_accuracy: 0.9649\n",
      "Epoch 969/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0824 - val_accuracy: 0.9649\n",
      "Epoch 970/1000\n",
      "114/114 [==============================] - 0s 145us/step - loss: 6.6853e-04 - accuracy: 1.0000 - val_loss: 0.0888 - val_accuracy: 0.9649\n",
      "Epoch 971/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0902 - val_accuracy: 0.9649\n",
      "Epoch 972/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0913 - val_accuracy: 0.9649\n",
      "Epoch 973/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0175 - accuracy: 0.9912 - val_loss: 0.0912 - val_accuracy: 0.9649\n",
      "Epoch 974/1000\n",
      "114/114 [==============================] - 0s 134us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9649\n",
      "Epoch 975/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 0.9825\n",
      "Epoch 976/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9649\n",
      "Epoch 977/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9649\n",
      "Epoch 978/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0083 - accuracy: 0.9912 - val_loss: 0.0909 - val_accuracy: 0.9649\n",
      "Epoch 979/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0746 - val_accuracy: 0.9649\n",
      "Epoch 980/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 9.9003e-04 - accuracy: 1.0000 - val_loss: 0.0634 - val_accuracy: 0.9825\n",
      "Epoch 981/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0557 - val_accuracy: 0.9649\n",
      "Epoch 982/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9649\n",
      "Epoch 983/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0462 - val_accuracy: 0.9649\n",
      "Epoch 984/1000\n",
      "114/114 [==============================] - 0s 146us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 0.0454 - val_accuracy: 0.9649\n",
      "Epoch 985/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0517 - val_accuracy: 0.9649\n",
      "Epoch 986/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0592 - val_accuracy: 0.9649\n",
      "Epoch 987/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0662 - val_accuracy: 0.9649\n",
      "Epoch 988/1000\n",
      "114/114 [==============================] - 0s 137us/step - loss: 0.0117 - accuracy: 0.9912 - val_loss: 0.0781 - val_accuracy: 0.9649\n",
      "Epoch 989/1000\n",
      "114/114 [==============================] - 0s 141us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0882 - val_accuracy: 0.9649\n",
      "Epoch 990/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9649\n",
      "Epoch 991/1000\n",
      "114/114 [==============================] - 0s 142us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9474\n",
      "Epoch 992/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 143us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1135 - val_accuracy: 0.9474\n",
      "Epoch 993/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9474\n",
      "Epoch 994/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1157 - val_accuracy: 0.9474\n",
      "Epoch 995/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9474\n",
      "Epoch 996/1000\n",
      "114/114 [==============================] - 0s 140us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9649\n",
      "Epoch 997/1000\n",
      "114/114 [==============================] - 0s 143us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9649\n",
      "Epoch 998/1000\n",
      "114/114 [==============================] - 0s 148us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9649\n",
      "Epoch 999/1000\n",
      "114/114 [==============================] - 0s 138us/step - loss: 7.1476e-04 - accuracy: 1.0000 - val_loss: 0.0914 - val_accuracy: 0.9649\n",
      "Epoch 1000/1000\n",
      "114/114 [==============================] - 0s 139us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0872 - val_accuracy: 0.9649\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_shape = (50,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "model.compile(optimizer = 'Adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "history = model.fit(X1, y1, validation_split=0.33, epochs = 1000,batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    }
   ],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.783125, 0.7256637]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_on_batch(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('data/dab-tpose-other.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "modello = keras.models.load_model('data/dab-tpose-other.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset = np.load('data/test-dabs.npy')\n",
    "dabDataset[:,:,0] = dabDataset[:,:,0] / 720\n",
    "dabDataset[:,:,1] = dabDataset[:,:,1] / 1280\n",
    "dabDataset = dabDataset[:,:,:2]\n",
    "dabDataset = dabDataset.reshape(len(dabDataset), 50)\n",
    "modello.predict_classes(dabDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型是做好了，但卻無法使用，由於導入pyopenpose的不成功，無法在python裡呼叫openpose來作業，沒辦法實際應用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
