{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目標：利用openpose和神經網路辨識T-POSE和DAB姿勢。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 組員：\n",
    "# 應數一 108701011 游能澤\n",
    "# 應數一 108701034 柯里橫\n",
    "# 應數一 108701018 池欣霓\n",
    "# 應數一 108701019 許辰宇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分工：\n",
    "# 構想與建設環境：游能澤、柯里橫\n",
    "# 程式建構：柯里橫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 由於一直無法使用pyopenpose函式，無法透過\n",
    "# openpose取得樣本，只好找別人做好的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 到https://github.com/burningion/dab-and-tpose-controlled-lights/tree/master/data\n",
    "# 載下作者生成好的數據，開個data資料夾放進去\n",
    "# dabs.npy tposes.npy other.npy\n",
    "# more-dabs.npy more-tposes.npy more-other.npy\n",
    "# test-dabs.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 這幾個檔案是以numpy儲存的二進制文件\n",
    "# 裡頭有我們需要的特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dabDataset = np.load('data/dabs.npy')\n",
    "tposeDataset = np.load('data/tposes.npy')\n",
    "otherDataset = np.load('data/other.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.8832416e+02, 2.9433704e+02, 7.2265184e-01],\n",
       "       [5.8239331e+02, 3.5126093e+02, 8.0205584e-01],\n",
       "       [5.0984329e+02, 3.4919385e+02, 7.5316119e-01],\n",
       "       [4.1784265e+02, 3.1985785e+02, 8.1164622e-01],\n",
       "       [3.6101605e+02, 2.9243521e+02, 8.0296052e-01],\n",
       "       [6.5091376e+02, 3.6097537e+02, 6.4161348e-01],\n",
       "       [6.3724268e+02, 2.7274924e+02, 7.8188539e-01],\n",
       "       [4.9614203e+02, 2.4154723e+02, 8.3243752e-01],\n",
       "       [5.4315808e+02, 6.4114813e+02, 4.4807938e-01],\n",
       "       [4.8636816e+02, 6.2938318e+02, 3.6906898e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [6.0191382e+02, 6.4702966e+02, 3.8946095e-01],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [5.7648334e+02, 2.7475522e+02, 6.1822432e-01],\n",
       "       [6.0389270e+02, 2.8454663e+02, 4.1854110e-01],\n",
       "       [5.5686536e+02, 2.6891223e+02, 2.7014270e-01],\n",
       "       [6.1959991e+02, 2.9243130e+02, 7.0310913e-02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 25, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding our Labels\n",
    "# Our labels come from the [BODY_25 Pose Output format](https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/doc/output.md#pose-output-format-body_25) available at the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Nose\", \"Neck\", \"RShoulder\", \"RElbow\", \"RWrist\", \"LShoulder\", \"LElbow\",\n",
    " \"LWrist\", \"MidHip\", \"RHip\", \"RKnee\", \"RAnkle\", \"LHip\", \"LKnee\", \"LAnkle\",\n",
    " \"REye\", \"LEye\", \"REar\", \"LEar\", \"LBigToe\", \"LSmallToe\", \"LHeel\", \"RBigToe\",\n",
    " \"RSmallToe\", \"RHeel\", \"Background\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 看數據有三個維度分別是X、Ｙ、Confidence，不需要用到Confidence。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "properLabels = []\n",
    "for label in labels:\n",
    "    properLabels.append(label + 'X')\n",
    "    properLabels.append(label + 'Y')\n",
    "    properLabels.append(label + 'Confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('data/dabs.csv', 'w+') as dabcsv:\n",
    "    dabwriter = csv.writer(dabcsv, delimiter=',')\n",
    "    dabwriter.writerow(properLabels)\n",
    "    for cell in dabDataset:\n",
    "        dabwriter.writerow(cell.flatten())\n",
    "        \n",
    "with open('data/tposes.csv', 'w+') as tposecsv:\n",
    "    tposewriter = csv.writer(tposecsv, delimiter=',')\n",
    "    tposewriter.writerow(properLabels)\n",
    "    for cell in tposeDataset:\n",
    "        tposewriter.writerow(cell.flatten())\n",
    "        \n",
    "with open('data/other.csv', 'w+') as othercsv:\n",
    "    otherwriter = csv.writer(othercsv, delimiter=',')\n",
    "    otherwriter.writerow(properLabels)\n",
    "    for cell in otherDataset:\n",
    "        otherwriter.writerow(cell.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用CSV檔看訓練資料略少，但還是試著訓練看看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Labeled Dataset for Training and Testing\n",
    "# We'll use 0 for other poses, 1 for dabs, and 2 for tposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2.]\n",
      "56 total examples for training.\n"
     ]
    }
   ],
   "source": [
    "labels = np.zeros(len(otherDataset))\n",
    "labels = np.append(labels, np.full((len(dabDataset)), 1))\n",
    "labels = np.append(labels, np.full((len(tposeDataset)), 2))\n",
    "print(labels)\n",
    "print(\"%i total examples for training.\" % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[488.3213     147.51425      0.83340967]\n",
      "  [494.22372    284.5734       0.8012297 ]\n",
      "  [386.4863     270.83716      0.66853976]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[515.7737     112.18818      0.83487195]\n",
      "  [478.48004    274.7029       0.8005627 ]\n",
      "  [368.77948    257.2105       0.6782713 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[547.1316     112.15151      0.79948723]\n",
      "  [464.79065    268.88403      0.73338044]\n",
      "  [360.98135    243.43745      0.62600124]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[509.97504    257.06958      0.892523  ]\n",
      "  [460.9663     351.17117      0.7867987 ]\n",
      "  [372.75305    333.54434      0.6111988 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[554.90063    286.50854      0.88104486]\n",
      "  [496.1236     374.6841       0.7804795 ]\n",
      "  [415.7811     353.13678      0.74092144]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]\n",
      "\n",
      " [[570.5084     268.88422      0.855286  ]\n",
      "  [509.95016    370.85114      0.7977039 ]\n",
      "  [431.50925    353.08978      0.7552353 ]\n",
      "  ...\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]\n",
      "  [  0.           0.           0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "dataset = np.append(otherDataset, dabDataset, axis=0)\n",
    "dataset = np.append(dataset, tposeDataset, axis=0)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 25, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讓數值變成0~1之間"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11524551, 0.22232297, 0.21159153, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.08764701, 0.21461165, 0.2009457 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.08761837, 0.21006565, 0.19018552, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.20083562, 0.2743525 , 0.26058152, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.2238348 , 0.29272196, 0.27588812, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.2100658 , 0.28972745, 0.2758514 , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:,:,1] / 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(dataset, labels)\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y = to_categorical(y, 3)\n",
    "print(y.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 架設神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.88321289e+02, 1.47514252e+02, 8.33409667e-01],\n",
       "       [4.94223724e+02, 2.84573395e+02, 8.01229715e-01],\n",
       "       [3.86486298e+02, 2.70837158e+02, 6.68539762e-01],\n",
       "       [3.37498718e+02, 4.31440033e+02, 8.06459844e-01],\n",
       "       [2.76727325e+02, 5.92155334e+02, 6.95721209e-01],\n",
       "       [6.01926575e+02, 2.96297577e+02, 6.77372575e-01],\n",
       "       [6.17621460e+02, 4.47154175e+02, 8.15527081e-01],\n",
       "       [6.33207092e+02, 6.13721497e+02, 7.50288665e-01],\n",
       "       [4.49166534e+02, 6.23515259e+02, 3.33123893e-01],\n",
       "       [3.68768433e+02, 6.15664124e+02, 2.96909660e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [5.29464417e+02, 6.35266663e+02, 3.00662249e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [4.72626495e+02, 1.25848732e+02, 7.93599010e-01],\n",
       "       [5.09897217e+02, 1.25915306e+02, 8.75047982e-01],\n",
       "       [4.47158661e+02, 1.31820786e+02, 9.30340886e-01],\n",
       "       [5.51045410e+02, 1.35715973e+02, 8.41542602e-01],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.reshape(len(X), 75)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 349.1770 - accuracy: 0.3571\n",
      "Epoch 2/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 10615.8975 - accuracy: 0.2500\n",
      "Epoch 3/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 40285.3789 - accuracy: 0.4643\n",
      "Epoch 4/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 39818.2070 - accuracy: 0.2857\n",
      "Epoch 5/200\n",
      "56/56 [==============================] - 0s 66us/step - loss: 6458.7578 - accuracy: 0.4643\n",
      "Epoch 6/200\n",
      "56/56 [==============================] - 0s 85us/step - loss: 1.0930 - accuracy: 0.3393\n",
      "Epoch 7/200\n",
      "56/56 [==============================] - 0s 67us/step - loss: 1.0814 - accuracy: 0.4643\n",
      "Epoch 8/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 1.1014 - accuracy: 0.4643\n",
      "Epoch 9/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0853 - accuracy: 0.4643\n",
      "Epoch 10/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0844 - accuracy: 0.4643\n",
      "Epoch 11/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0920 - accuracy: 0.4643\n",
      "Epoch 12/200\n",
      "56/56 [==============================] - 0s 34us/step - loss: 1.1036 - accuracy: 0.4643\n",
      "Epoch 13/200\n",
      "56/56 [==============================] - 0s 71us/step - loss: 1.0882 - accuracy: 0.4643\n",
      "Epoch 14/200\n",
      "56/56 [==============================] - 0s 71us/step - loss: 1.0975 - accuracy: 0.4643\n",
      "Epoch 15/200\n",
      "56/56 [==============================] - 0s 69us/step - loss: 1.0845 - accuracy: 0.4643\n",
      "Epoch 16/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0877 - accuracy: 0.4643\n",
      "Epoch 17/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 1.0809 - accuracy: 0.4643\n",
      "Epoch 18/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0869 - accuracy: 0.4643\n",
      "Epoch 19/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0983 - accuracy: 0.4643\n",
      "Epoch 20/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0788 - accuracy: 0.4643\n",
      "Epoch 21/200\n",
      "56/56 [==============================] - 0s 62us/step - loss: 1.0950 - accuracy: 0.4643\n",
      "Epoch 22/200\n",
      "56/56 [==============================] - 0s 66us/step - loss: 1.0877 - accuracy: 0.4643\n",
      "Epoch 23/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 1.0841 - accuracy: 0.4643\n",
      "Epoch 24/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0747 - accuracy: 0.4643\n",
      "Epoch 25/200\n",
      "56/56 [==============================] - 0s 48us/step - loss: 1.0943 - accuracy: 0.4643\n",
      "Epoch 26/200\n",
      "56/56 [==============================] - 0s 81us/step - loss: 1.0724 - accuracy: 0.4643\n",
      "Epoch 27/200\n",
      "56/56 [==============================] - 0s 64us/step - loss: 1.0853 - accuracy: 0.4643\n",
      "Epoch 28/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0973 - accuracy: 0.4643\n",
      "Epoch 29/200\n",
      "56/56 [==============================] - 0s 60us/step - loss: 1.0826 - accuracy: 0.4643\n",
      "Epoch 30/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0759 - accuracy: 0.4643\n",
      "Epoch 31/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 1.0886 - accuracy: 0.4643\n",
      "Epoch 32/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0937 - accuracy: 0.4643\n",
      "Epoch 33/200\n",
      "56/56 [==============================] - 0s 59us/step - loss: 1.0934 - accuracy: 0.4643\n",
      "Epoch 34/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0710 - accuracy: 0.4643\n",
      "Epoch 35/200\n",
      "56/56 [==============================] - 0s 33us/step - loss: 1.0782 - accuracy: 0.4643\n",
      "Epoch 36/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0830 - accuracy: 0.4643\n",
      "Epoch 37/200\n",
      "56/56 [==============================] - 0s 64us/step - loss: 1.0779 - accuracy: 0.4643\n",
      "Epoch 38/200\n",
      "56/56 [==============================] - 0s 61us/step - loss: 1.0944 - accuracy: 0.4643\n",
      "Epoch 39/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0917 - accuracy: 0.4643\n",
      "Epoch 40/200\n",
      "56/56 [==============================] - 0s 63us/step - loss: 1.0916 - accuracy: 0.4643\n",
      "Epoch 41/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0827 - accuracy: 0.4643\n",
      "Epoch 42/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 1.0747 - accuracy: 0.4643\n",
      "Epoch 43/200\n",
      "56/56 [==============================] - 0s 84us/step - loss: 1.0671 - accuracy: 0.4643\n",
      "Epoch 44/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 1.0827 - accuracy: 0.4643\n",
      "Epoch 45/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 1.0939 - accuracy: 0.4643\n",
      "Epoch 46/200\n",
      "56/56 [==============================] - 0s 114us/step - loss: 1.0915 - accuracy: 0.4643\n",
      "Epoch 47/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 1.0804 - accuracy: 0.4643\n",
      "Epoch 48/200\n",
      "56/56 [==============================] - 0s 95us/step - loss: 1.0774 - accuracy: 0.4643\n",
      "Epoch 49/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.1006 - accuracy: 0.4643\n",
      "Epoch 50/200\n",
      "56/56 [==============================] - 0s 34us/step - loss: 1.0789 - accuracy: 0.4643\n",
      "Epoch 51/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 1.0823 - accuracy: 0.4643\n",
      "Epoch 52/200\n",
      "56/56 [==============================] - 0s 67us/step - loss: 1.0895 - accuracy: 0.4643\n",
      "Epoch 53/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0844 - accuracy: 0.4643\n",
      "Epoch 54/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 1.0918 - accuracy: 0.4643\n",
      "Epoch 55/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0826 - accuracy: 0.4643\n",
      "Epoch 56/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0893 - accuracy: 0.4643\n",
      "Epoch 57/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 1.0884 - accuracy: 0.4643\n",
      "Epoch 58/200\n",
      "56/56 [==============================] - 0s 33us/step - loss: 1.0941 - accuracy: 0.4643\n",
      "Epoch 59/200\n",
      "56/56 [==============================] - 0s 50us/step - loss: 1.0852 - accuracy: 0.4643\n",
      "Epoch 60/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 1.0921 - accuracy: 0.4643\n",
      "Epoch 61/200\n",
      "56/56 [==============================] - 0s 51us/step - loss: 1.0724 - accuracy: 0.4643\n",
      "Epoch 62/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 1.0787 - accuracy: 0.4643\n",
      "Epoch 63/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0809 - accuracy: 0.4643\n",
      "Epoch 64/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 1.0701 - accuracy: 0.4643\n",
      "Epoch 65/200\n",
      "56/56 [==============================] - 0s 59us/step - loss: 1.0770 - accuracy: 0.4643\n",
      "Epoch 66/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0892 - accuracy: 0.4643\n",
      "Epoch 67/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 1.0868 - accuracy: 0.4643\n",
      "Epoch 68/200\n",
      "56/56 [==============================] - 0s 46us/step - loss: 1.0700 - accuracy: 0.4643\n",
      "Epoch 69/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0705 - accuracy: 0.4643\n",
      "Epoch 70/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0801 - accuracy: 0.4643\n",
      "Epoch 71/200\n",
      "56/56 [==============================] - 0s 48us/step - loss: 1.0841 - accuracy: 0.4643\n",
      "Epoch 72/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0663 - accuracy: 0.4643\n",
      "Epoch 73/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0660 - accuracy: 0.4643\n",
      "Epoch 74/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0947 - accuracy: 0.4643\n",
      "Epoch 75/200\n",
      "56/56 [==============================] - 0s 59us/step - loss: 1.0669 - accuracy: 0.4643\n",
      "Epoch 76/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0807 - accuracy: 0.4643\n",
      "Epoch 77/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 1.0718 - accuracy: 0.4643\n",
      "Epoch 78/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 1.0821 - accuracy: 0.4643\n",
      "Epoch 79/200\n",
      "56/56 [==============================] - 0s 72us/step - loss: 1.0778 - accuracy: 0.4643\n",
      "Epoch 80/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0854 - accuracy: 0.4643\n",
      "Epoch 81/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0859 - accuracy: 0.4643\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 43us/step - loss: 1.1028 - accuracy: 0.4643\n",
      "Epoch 83/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0535 - accuracy: 0.4643\n",
      "Epoch 84/200\n",
      "56/56 [==============================] - 0s 50us/step - loss: 1.0909 - accuracy: 0.4643\n",
      "Epoch 85/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0707 - accuracy: 0.4643\n",
      "Epoch 86/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0798 - accuracy: 0.4643\n",
      "Epoch 87/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0680 - accuracy: 0.4643\n",
      "Epoch 88/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0735 - accuracy: 0.4643\n",
      "Epoch 89/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 1.1026 - accuracy: 0.4643\n",
      "Epoch 90/200\n",
      "56/56 [==============================] - 0s 46us/step - loss: 1.0710 - accuracy: 0.4643\n",
      "Epoch 91/200\n",
      "56/56 [==============================] - 0s 34us/step - loss: 1.0706 - accuracy: 0.4643\n",
      "Epoch 92/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0793 - accuracy: 0.4643\n",
      "Epoch 93/200\n",
      "56/56 [==============================] - 0s 64us/step - loss: 1.0606 - accuracy: 0.4643\n",
      "Epoch 94/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0862 - accuracy: 0.4643\n",
      "Epoch 95/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 1.0796 - accuracy: 0.4643\n",
      "Epoch 96/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.1069 - accuracy: 0.4643\n",
      "Epoch 97/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0666 - accuracy: 0.4643\n",
      "Epoch 98/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0725 - accuracy: 0.4643\n",
      "Epoch 99/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0878 - accuracy: 0.4643\n",
      "Epoch 100/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 1.0831 - accuracy: 0.4643\n",
      "Epoch 101/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0760 - accuracy: 0.4643\n",
      "Epoch 102/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0909 - accuracy: 0.4643\n",
      "Epoch 103/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0790 - accuracy: 0.4643\n",
      "Epoch 104/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 1.0781 - accuracy: 0.4643\n",
      "Epoch 105/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 1.0868 - accuracy: 0.4643\n",
      "Epoch 106/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0807 - accuracy: 0.4643\n",
      "Epoch 107/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0716 - accuracy: 0.4643\n",
      "Epoch 108/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0748 - accuracy: 0.4643\n",
      "Epoch 109/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 1.0764 - accuracy: 0.4643\n",
      "Epoch 110/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0594 - accuracy: 0.4643\n",
      "Epoch 111/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 1.0688 - accuracy: 0.4643\n",
      "Epoch 112/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0667 - accuracy: 0.4643\n",
      "Epoch 113/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0779 - accuracy: 0.4643\n",
      "Epoch 114/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0815 - accuracy: 0.4643\n",
      "Epoch 115/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0882 - accuracy: 0.4643\n",
      "Epoch 116/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0891 - accuracy: 0.4643\n",
      "Epoch 117/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0669 - accuracy: 0.4643\n",
      "Epoch 118/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 1.0794 - accuracy: 0.4643\n",
      "Epoch 119/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 1.0698 - accuracy: 0.4643\n",
      "Epoch 120/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0826 - accuracy: 0.4643\n",
      "Epoch 121/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 1.0851 - accuracy: 0.4643\n",
      "Epoch 122/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0696 - accuracy: 0.4643\n",
      "Epoch 123/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0774 - accuracy: 0.4643\n",
      "Epoch 124/200\n",
      "56/56 [==============================] - 0s 30us/step - loss: 1.0794 - accuracy: 0.4643\n",
      "Epoch 125/200\n",
      "56/56 [==============================] - 0s 33us/step - loss: 1.0885 - accuracy: 0.4643\n",
      "Epoch 126/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 1.0746 - accuracy: 0.4643\n",
      "Epoch 127/200\n",
      "56/56 [==============================] - 0s 28us/step - loss: 1.0699 - accuracy: 0.4643\n",
      "Epoch 128/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 1.0737 - accuracy: 0.4643\n",
      "Epoch 129/200\n",
      "56/56 [==============================] - 0s 34us/step - loss: 1.0826 - accuracy: 0.4643\n",
      "Epoch 130/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 1.0691 - accuracy: 0.4643\n",
      "Epoch 131/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0737 - accuracy: 0.4643\n",
      "Epoch 132/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0885 - accuracy: 0.4643\n",
      "Epoch 133/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0734 - accuracy: 0.4643\n",
      "Epoch 134/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0854 - accuracy: 0.4643\n",
      "Epoch 135/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0805 - accuracy: 0.4643\n",
      "Epoch 136/200\n",
      "56/56 [==============================] - 0s 34us/step - loss: 1.0727 - accuracy: 0.4643\n",
      "Epoch 137/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0664 - accuracy: 0.4643\n",
      "Epoch 138/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0793 - accuracy: 0.4643\n",
      "Epoch 139/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0869 - accuracy: 0.4643\n",
      "Epoch 140/200\n",
      "56/56 [==============================] - 0s 30us/step - loss: 1.0744 - accuracy: 0.4643\n",
      "Epoch 141/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0727 - accuracy: 0.4643\n",
      "Epoch 142/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 1.0827 - accuracy: 0.4643\n",
      "Epoch 143/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 1.0606 - accuracy: 0.4643\n",
      "Epoch 144/200\n",
      "56/56 [==============================] - 0s 34us/step - loss: 1.0837 - accuracy: 0.4643\n",
      "Epoch 145/200\n",
      "56/56 [==============================] - 0s 33us/step - loss: 1.0787 - accuracy: 0.4643\n",
      "Epoch 146/200\n",
      "56/56 [==============================] - 0s 30us/step - loss: 1.0799 - accuracy: 0.4643\n",
      "Epoch 147/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0727 - accuracy: 0.4643\n",
      "Epoch 148/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0667 - accuracy: 0.4643\n",
      "Epoch 149/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0843 - accuracy: 0.4643\n",
      "Epoch 150/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0801 - accuracy: 0.4643\n",
      "Epoch 151/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0796 - accuracy: 0.4643\n",
      "Epoch 152/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0683 - accuracy: 0.4643\n",
      "Epoch 153/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0741 - accuracy: 0.4643\n",
      "Epoch 154/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0810 - accuracy: 0.4643\n",
      "Epoch 155/200\n",
      "56/56 [==============================] - 0s 50us/step - loss: 1.0759 - accuracy: 0.4643\n",
      "Epoch 156/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 1.0797 - accuracy: 0.4643\n",
      "Epoch 157/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 1.0844 - accuracy: 0.4643\n",
      "Epoch 158/200\n",
      "56/56 [==============================] - 0s 63us/step - loss: 1.0762 - accuracy: 0.4643\n",
      "Epoch 159/200\n",
      "56/56 [==============================] - 0s 56us/step - loss: 1.0613 - accuracy: 0.4643\n",
      "Epoch 160/200\n",
      "56/56 [==============================] - 0s 46us/step - loss: 1.0660 - accuracy: 0.4643\n",
      "Epoch 161/200\n",
      "56/56 [==============================] - 0s 56us/step - loss: 1.0838 - accuracy: 0.4643\n",
      "Epoch 162/200\n",
      "56/56 [==============================] - 0s 70us/step - loss: 1.0720 - accuracy: 0.4643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "56/56 [==============================] - 0s 51us/step - loss: 1.0867 - accuracy: 0.4643\n",
      "Epoch 164/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0703 - accuracy: 0.4643\n",
      "Epoch 165/200\n",
      "56/56 [==============================] - 0s 56us/step - loss: 1.0695 - accuracy: 0.4643\n",
      "Epoch 166/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0898 - accuracy: 0.4643\n",
      "Epoch 167/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 1.0861 - accuracy: 0.4643\n",
      "Epoch 168/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 1.0661 - accuracy: 0.4643\n",
      "Epoch 169/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0770 - accuracy: 0.4643\n",
      "Epoch 170/200\n",
      "56/56 [==============================] - 0s 50us/step - loss: 1.0834 - accuracy: 0.4643\n",
      "Epoch 171/200\n",
      "56/56 [==============================] - 0s 63us/step - loss: 1.0667 - accuracy: 0.4643\n",
      "Epoch 172/200\n",
      "56/56 [==============================] - 0s 65us/step - loss: 1.0761 - accuracy: 0.4643\n",
      "Epoch 173/200\n",
      "56/56 [==============================] - 0s 56us/step - loss: 1.0693 - accuracy: 0.4643\n",
      "Epoch 174/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 1.0711 - accuracy: 0.4643\n",
      "Epoch 175/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0739 - accuracy: 0.4643\n",
      "Epoch 176/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0665 - accuracy: 0.4643\n",
      "Epoch 177/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0768 - accuracy: 0.4643\n",
      "Epoch 178/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0748 - accuracy: 0.4643\n",
      "Epoch 179/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0723 - accuracy: 0.4643\n",
      "Epoch 180/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0542 - accuracy: 0.4643\n",
      "Epoch 181/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0824 - accuracy: 0.4643\n",
      "Epoch 182/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0700 - accuracy: 0.4643\n",
      "Epoch 183/200\n",
      "56/56 [==============================] - 0s 31us/step - loss: 1.0672 - accuracy: 0.4643\n",
      "Epoch 184/200\n",
      "56/56 [==============================] - 0s 32us/step - loss: 1.0756 - accuracy: 0.4643\n",
      "Epoch 185/200\n",
      "56/56 [==============================] - 0s 30us/step - loss: 1.0717 - accuracy: 0.4643\n",
      "Epoch 186/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 1.0624 - accuracy: 0.4643\n",
      "Epoch 187/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0826 - accuracy: 0.4643\n",
      "Epoch 188/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0712 - accuracy: 0.4643\n",
      "Epoch 189/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 1.0606 - accuracy: 0.4643\n",
      "Epoch 190/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0621 - accuracy: 0.4643\n",
      "Epoch 191/200\n",
      "56/56 [==============================] - 0s 48us/step - loss: 1.1013 - accuracy: 0.4643\n",
      "Epoch 192/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 1.0887 - accuracy: 0.4643\n",
      "Epoch 193/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0672 - accuracy: 0.4643\n",
      "Epoch 194/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 1.0625 - accuracy: 0.4643\n",
      "Epoch 195/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0724 - accuracy: 0.4643\n",
      "Epoch 196/200\n",
      "56/56 [==============================] - 0s 33us/step - loss: 1.0927 - accuracy: 0.4643\n",
      "Epoch 197/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0721 - accuracy: 0.4643\n",
      "Epoch 198/200\n",
      "56/56 [==============================] - 0s 67us/step - loss: 1.0687 - accuracy: 0.4643\n",
      "Epoch 199/200\n",
      "56/56 [==============================] - 0s 48us/step - loss: 1.0793 - accuracy: 0.4643\n",
      "Epoch 200/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0773 - accuracy: 0.4643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fbd123ea890>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_shape = (75,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "model.compile(optimizer = SGD(lr = 0.005),\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "model.fit(X, y, epochs = 200, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning up data further¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy too low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 25, 3)\n",
      "(56, 25, 2)\n",
      "(56, 50)\n"
     ]
    }
   ],
   "source": [
    "X, y = shuffle(dataset, labels)\n",
    "y = to_categorical(y, 3)\n",
    "print(X.shape)\n",
    "X[:,:,0] = X[:,:,0] / 720 \n",
    "X[:,:,1] = X[:,:,1] / 1280\n",
    "X = X[:,:,:2]\n",
    "print(X.shape)\n",
    "X = X.reshape(56, 50)     \n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "56/56 [==============================] - 0s 3ms/step - loss: 1.0406 - accuracy: 0.4821\n",
      "Epoch 2/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.1201 - accuracy: 0.4107\n",
      "Epoch 3/200\n",
      "56/56 [==============================] - 0s 59us/step - loss: 1.0904 - accuracy: 0.3750\n",
      "Epoch 4/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 1.1830 - accuracy: 0.3036\n",
      "Epoch 5/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.1125 - accuracy: 0.3214\n",
      "Epoch 6/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 1.0818 - accuracy: 0.5000\n",
      "Epoch 7/200\n",
      "56/56 [==============================] - 0s 72us/step - loss: 1.1210 - accuracy: 0.4643\n",
      "Epoch 8/200\n",
      "56/56 [==============================] - 0s 59us/step - loss: 1.1126 - accuracy: 0.4107\n",
      "Epoch 9/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 1.1226 - accuracy: 0.4464\n",
      "Epoch 10/200\n",
      "56/56 [==============================] - 0s 61us/step - loss: 1.0506 - accuracy: 0.5000\n",
      "Epoch 11/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 1.0489 - accuracy: 0.5179\n",
      "Epoch 12/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 1.0744 - accuracy: 0.4821\n",
      "Epoch 13/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 1.1476 - accuracy: 0.3750\n",
      "Epoch 14/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0980 - accuracy: 0.3571\n",
      "Epoch 15/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 1.0293 - accuracy: 0.5179\n",
      "Epoch 16/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 1.0451 - accuracy: 0.4464\n",
      "Epoch 17/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 1.0533 - accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "56/56 [==============================] - 0s 56us/step - loss: 1.0400 - accuracy: 0.4464\n",
      "Epoch 19/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 1.0453 - accuracy: 0.5000\n",
      "Epoch 20/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 1.0191 - accuracy: 0.5179\n",
      "Epoch 21/200\n",
      "56/56 [==============================] - 0s 57us/step - loss: 0.9748 - accuracy: 0.5714\n",
      "Epoch 22/200\n",
      "56/56 [==============================] - 0s 48us/step - loss: 1.0180 - accuracy: 0.5536\n",
      "Epoch 23/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 1.0769 - accuracy: 0.4107\n",
      "Epoch 24/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0039 - accuracy: 0.4643\n",
      "Epoch 25/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 1.0341 - accuracy: 0.4286\n",
      "Epoch 26/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 1.0186 - accuracy: 0.4464\n",
      "Epoch 27/200\n",
      "56/56 [==============================] - 0s 62us/step - loss: 0.9989 - accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "56/56 [==============================] - 0s 46us/step - loss: 0.9547 - accuracy: 0.6250\n",
      "Epoch 29/200\n",
      "56/56 [==============================] - 0s 48us/step - loss: 0.9977 - accuracy: 0.4643\n",
      "Epoch 30/200\n",
      "56/56 [==============================] - 0s 57us/step - loss: 0.9668 - accuracy: 0.4821\n",
      "Epoch 31/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.9866 - accuracy: 0.5179\n",
      "Epoch 32/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 0.9320 - accuracy: 0.5714\n",
      "Epoch 33/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 0.9227 - accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.9132 - accuracy: 0.5893\n",
      "Epoch 35/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 0.9124 - accuracy: 0.6250\n",
      "Epoch 36/200\n",
      "56/56 [==============================] - 0s 66us/step - loss: 0.9734 - accuracy: 0.5714\n",
      "Epoch 37/200\n",
      "56/56 [==============================] - 0s 66us/step - loss: 0.9819 - accuracy: 0.5179\n",
      "Epoch 38/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 0.9442 - accuracy: 0.5536\n",
      "Epoch 39/200\n",
      "56/56 [==============================] - 0s 74us/step - loss: 0.9597 - accuracy: 0.5357\n",
      "Epoch 40/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 0.9376 - accuracy: 0.5536\n",
      "Epoch 41/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.9535 - accuracy: 0.5893\n",
      "Epoch 42/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 0.8973 - accuracy: 0.6964\n",
      "Epoch 43/200\n",
      "56/56 [==============================] - 0s 78us/step - loss: 0.9176 - accuracy: 0.6429\n",
      "Epoch 44/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.9357 - accuracy: 0.5357\n",
      "Epoch 45/200\n",
      "56/56 [==============================] - 0s 70us/step - loss: 0.9040 - accuracy: 0.5714\n",
      "Epoch 46/200\n",
      "56/56 [==============================] - 0s 85us/step - loss: 0.8752 - accuracy: 0.6429\n",
      "Epoch 47/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 0.8456 - accuracy: 0.6071\n",
      "Epoch 48/200\n",
      "56/56 [==============================] - 0s 64us/step - loss: 0.8921 - accuracy: 0.6429\n",
      "Epoch 49/200\n",
      "56/56 [==============================] - 0s 93us/step - loss: 0.8815 - accuracy: 0.6786\n",
      "Epoch 50/200\n",
      "56/56 [==============================] - 0s 57us/step - loss: 0.8611 - accuracy: 0.6250\n",
      "Epoch 51/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.8316 - accuracy: 0.6786\n",
      "Epoch 52/200\n",
      "56/56 [==============================] - 0s 59us/step - loss: 0.8723 - accuracy: 0.6607\n",
      "Epoch 53/200\n",
      "56/56 [==============================] - 0s 46us/step - loss: 0.8413 - accuracy: 0.6429\n",
      "Epoch 54/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.8631 - accuracy: 0.6786\n",
      "Epoch 55/200\n",
      "56/56 [==============================] - 0s 46us/step - loss: 0.8321 - accuracy: 0.6607\n",
      "Epoch 56/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.8484 - accuracy: 0.7143\n",
      "Epoch 57/200\n",
      "56/56 [==============================] - 0s 65us/step - loss: 0.8510 - accuracy: 0.6786\n",
      "Epoch 58/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 0.8072 - accuracy: 0.6786\n",
      "Epoch 59/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.7828 - accuracy: 0.7857\n",
      "Epoch 60/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 0.7619 - accuracy: 0.8036\n",
      "Epoch 61/200\n",
      "56/56 [==============================] - 0s 75us/step - loss: 0.8104 - accuracy: 0.7143\n",
      "Epoch 62/200\n",
      "56/56 [==============================] - 0s 66us/step - loss: 0.7332 - accuracy: 0.7143\n",
      "Epoch 63/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.7541 - accuracy: 0.6786\n",
      "Epoch 64/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 0.7779 - accuracy: 0.6786\n",
      "Epoch 65/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 0.7512 - accuracy: 0.6964\n",
      "Epoch 66/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 0.7310 - accuracy: 0.7679\n",
      "Epoch 67/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 0.7744 - accuracy: 0.6250\n",
      "Epoch 68/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 0.7224 - accuracy: 0.7679\n",
      "Epoch 69/200\n",
      "56/56 [==============================] - 0s 56us/step - loss: 0.7512 - accuracy: 0.7321\n",
      "Epoch 70/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 0.7768 - accuracy: 0.6964\n",
      "Epoch 71/200\n",
      "56/56 [==============================] - 0s 62us/step - loss: 0.7715 - accuracy: 0.7321\n",
      "Epoch 72/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 0.7261 - accuracy: 0.6964\n",
      "Epoch 73/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 0.7031 - accuracy: 0.7857\n",
      "Epoch 74/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.7318 - accuracy: 0.7500\n",
      "Epoch 75/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.7131 - accuracy: 0.6607\n",
      "Epoch 76/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.6899 - accuracy: 0.7679\n",
      "Epoch 77/200\n",
      "56/56 [==============================] - 0s 81us/step - loss: 0.6441 - accuracy: 0.8036\n",
      "Epoch 78/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 0.7058 - accuracy: 0.7321\n",
      "Epoch 79/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 0.6638 - accuracy: 0.7679\n",
      "Epoch 80/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 0.6369 - accuracy: 0.7679\n",
      "Epoch 81/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.6866 - accuracy: 0.7679\n",
      "Epoch 82/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.6356 - accuracy: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.6506 - accuracy: 0.8036\n",
      "Epoch 84/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.6389 - accuracy: 0.7143\n",
      "Epoch 85/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 0.5546 - accuracy: 0.8750\n",
      "Epoch 86/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 0.6370 - accuracy: 0.7321\n",
      "Epoch 87/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.6159 - accuracy: 0.8036\n",
      "Epoch 88/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 0.5777 - accuracy: 0.7679\n",
      "Epoch 89/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 0.6161 - accuracy: 0.7500\n",
      "Epoch 90/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 0.6721 - accuracy: 0.7321\n",
      "Epoch 91/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 0.6290 - accuracy: 0.6964\n",
      "Epoch 92/200\n",
      "56/56 [==============================] - 0s 46us/step - loss: 0.5752 - accuracy: 0.7679\n",
      "Epoch 93/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.5148 - accuracy: 0.8750\n",
      "Epoch 94/200\n",
      "56/56 [==============================] - 0s 68us/step - loss: 0.5393 - accuracy: 0.8393\n",
      "Epoch 95/200\n",
      "56/56 [==============================] - 0s 58us/step - loss: 0.5626 - accuracy: 0.7857\n",
      "Epoch 96/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.5872 - accuracy: 0.7321\n",
      "Epoch 97/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 0.5722 - accuracy: 0.7500\n",
      "Epoch 98/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.5943 - accuracy: 0.7321\n",
      "Epoch 99/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 0.5571 - accuracy: 0.7321\n",
      "Epoch 100/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.5411 - accuracy: 0.8393\n",
      "Epoch 101/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.4949 - accuracy: 0.7857\n",
      "Epoch 102/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.5472 - accuracy: 0.7321\n",
      "Epoch 103/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 0.5984 - accuracy: 0.6964\n",
      "Epoch 104/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.5555 - accuracy: 0.7857\n",
      "Epoch 105/200\n",
      "56/56 [==============================] - 0s 71us/step - loss: 0.4933 - accuracy: 0.8571\n",
      "Epoch 106/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.4755 - accuracy: 0.7857\n",
      "Epoch 107/200\n",
      "56/56 [==============================] - 0s 60us/step - loss: 0.5526 - accuracy: 0.7679\n",
      "Epoch 108/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 0.4988 - accuracy: 0.8214\n",
      "Epoch 109/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.5013 - accuracy: 0.8571\n",
      "Epoch 110/200\n",
      "56/56 [==============================] - 0s 57us/step - loss: 0.5117 - accuracy: 0.8214\n",
      "Epoch 111/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.4301 - accuracy: 0.8036\n",
      "Epoch 112/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.4354 - accuracy: 0.8571\n",
      "Epoch 113/200\n",
      "56/56 [==============================] - 0s 51us/step - loss: 0.5531 - accuracy: 0.7857\n",
      "Epoch 114/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.4640 - accuracy: 0.8036\n",
      "Epoch 115/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 0.4932 - accuracy: 0.7500\n",
      "Epoch 116/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.4581 - accuracy: 0.8393\n",
      "Epoch 117/200\n",
      "56/56 [==============================] - 0s 48us/step - loss: 0.4660 - accuracy: 0.8571\n",
      "Epoch 118/200\n",
      "56/56 [==============================] - 0s 56us/step - loss: 0.4605 - accuracy: 0.8036\n",
      "Epoch 119/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 0.4827 - accuracy: 0.7857\n",
      "Epoch 120/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.4008 - accuracy: 0.8929\n",
      "Epoch 121/200\n",
      "56/56 [==============================] - 0s 64us/step - loss: 0.4699 - accuracy: 0.7679\n",
      "Epoch 122/200\n",
      "56/56 [==============================] - 0s 57us/step - loss: 0.4621 - accuracy: 0.7857\n",
      "Epoch 123/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.4777 - accuracy: 0.7500\n",
      "Epoch 124/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 0.5033 - accuracy: 0.7321\n",
      "Epoch 125/200\n",
      "56/56 [==============================] - 0s 60us/step - loss: 0.4875 - accuracy: 0.7500\n",
      "Epoch 126/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.5173 - accuracy: 0.8036\n",
      "Epoch 127/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.4380 - accuracy: 0.7857\n",
      "Epoch 128/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 0.4074 - accuracy: 0.8750\n",
      "Epoch 129/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 0.4072 - accuracy: 0.8214\n",
      "Epoch 130/200\n",
      "56/56 [==============================] - 0s 83us/step - loss: 0.4696 - accuracy: 0.8036\n",
      "Epoch 131/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.4751 - accuracy: 0.8750\n",
      "Epoch 132/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.4252 - accuracy: 0.8036\n",
      "Epoch 133/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 0.4264 - accuracy: 0.9107\n",
      "Epoch 134/200\n",
      "56/56 [==============================] - 0s 58us/step - loss: 0.4381 - accuracy: 0.8571\n",
      "Epoch 135/200\n",
      "56/56 [==============================] - 0s 100us/step - loss: 0.4199 - accuracy: 0.8214\n",
      "Epoch 136/200\n",
      "56/56 [==============================] - 0s 54us/step - loss: 0.4029 - accuracy: 0.8571\n",
      "Epoch 137/200\n",
      "56/56 [==============================] - 0s 71us/step - loss: 0.4072 - accuracy: 0.8571\n",
      "Epoch 138/200\n",
      "56/56 [==============================] - 0s 71us/step - loss: 0.4698 - accuracy: 0.8036\n",
      "Epoch 139/200\n",
      "56/56 [==============================] - 0s 58us/step - loss: 0.3351 - accuracy: 0.9107\n",
      "Epoch 140/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 0.4019 - accuracy: 0.8750\n",
      "Epoch 141/200\n",
      "56/56 [==============================] - 0s 41us/step - loss: 0.3980 - accuracy: 0.7679\n",
      "Epoch 142/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 0.4163 - accuracy: 0.8036\n",
      "Epoch 143/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.4175 - accuracy: 0.8214\n",
      "Epoch 144/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 0.3765 - accuracy: 0.8571\n",
      "Epoch 145/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 0.3431 - accuracy: 0.8750\n",
      "Epoch 146/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 0.3617 - accuracy: 0.8393\n",
      "Epoch 147/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 0.3274 - accuracy: 0.8929\n",
      "Epoch 148/200\n",
      "56/56 [==============================] - 0s 50us/step - loss: 0.3624 - accuracy: 0.8214\n",
      "Epoch 149/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.3815 - accuracy: 0.8393\n",
      "Epoch 150/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 0.3423 - accuracy: 0.8393\n",
      "Epoch 151/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 0.3486 - accuracy: 0.8393\n",
      "Epoch 152/200\n",
      "56/56 [==============================] - 0s 37us/step - loss: 0.3241 - accuracy: 0.8929\n",
      "Epoch 153/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 0.3134 - accuracy: 0.9286\n",
      "Epoch 154/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.3780 - accuracy: 0.8214\n",
      "Epoch 155/200\n",
      "56/56 [==============================] - 0s 49us/step - loss: 0.4276 - accuracy: 0.8393\n",
      "Epoch 156/200\n",
      "56/56 [==============================] - 0s 42us/step - loss: 0.2930 - accuracy: 0.9107\n",
      "Epoch 157/200\n",
      "56/56 [==============================] - 0s 43us/step - loss: 0.3743 - accuracy: 0.8571\n",
      "Epoch 158/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 0.3012 - accuracy: 0.9107\n",
      "Epoch 159/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 0.3636 - accuracy: 0.8750\n",
      "Epoch 160/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.4039 - accuracy: 0.7857\n",
      "Epoch 161/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.3607 - accuracy: 0.8393\n",
      "Epoch 162/200\n",
      "56/56 [==============================] - 0s 39us/step - loss: 0.2870 - accuracy: 0.9107\n",
      "Epoch 163/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 0.2990 - accuracy: 0.8929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 164/200\n",
      "56/56 [==============================] - 0s 35us/step - loss: 0.4008 - accuracy: 0.8036\n",
      "Epoch 165/200\n",
      "56/56 [==============================] - 0s 40us/step - loss: 0.2823 - accuracy: 0.8929\n",
      "Epoch 166/200\n",
      "56/56 [==============================] - 0s 38us/step - loss: 0.3017 - accuracy: 0.8750\n",
      "Epoch 167/200\n",
      "56/56 [==============================] - 0s 34us/step - loss: 0.3650 - accuracy: 0.8571\n",
      "Epoch 168/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 0.3413 - accuracy: 0.8750\n",
      "Epoch 169/200\n",
      "56/56 [==============================] - 0s 45us/step - loss: 0.3408 - accuracy: 0.8571\n",
      "Epoch 170/200\n",
      "56/56 [==============================] - 0s 51us/step - loss: 0.2701 - accuracy: 0.8929\n",
      "Epoch 171/200\n",
      "56/56 [==============================] - 0s 55us/step - loss: 0.3290 - accuracy: 0.8393\n",
      "Epoch 172/200\n",
      "56/56 [==============================] - 0s 36us/step - loss: 0.3566 - accuracy: 0.8214\n",
      "Epoch 173/200\n",
      "56/56 [==============================] - 0s 50us/step - loss: 0.2628 - accuracy: 0.8929\n",
      "Epoch 174/200\n",
      "56/56 [==============================] - 0s 74us/step - loss: 0.3163 - accuracy: 0.9107\n",
      "Epoch 175/200\n",
      "56/56 [==============================] - 0s 60us/step - loss: 0.2940 - accuracy: 0.8571\n",
      "Epoch 176/200\n",
      "56/56 [==============================] - 0s 57us/step - loss: 0.2847 - accuracy: 0.8571\n",
      "Epoch 177/200\n",
      "56/56 [==============================] - 0s 63us/step - loss: 0.2794 - accuracy: 0.9286\n",
      "Epoch 178/200\n",
      "56/56 [==============================] - 0s 53us/step - loss: 0.2842 - accuracy: 0.8750\n",
      "Epoch 179/200\n",
      "56/56 [==============================] - 0s 64us/step - loss: 0.3086 - accuracy: 0.8750\n",
      "Epoch 180/200\n",
      "56/56 [==============================] - 0s 63us/step - loss: 0.2842 - accuracy: 0.8750\n",
      "Epoch 181/200\n",
      "56/56 [==============================] - 0s 50us/step - loss: 0.3472 - accuracy: 0.8393\n",
      "Epoch 182/200\n",
      "56/56 [==============================] - 0s 57us/step - loss: 0.3162 - accuracy: 0.8393\n",
      "Epoch 183/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.2743 - accuracy: 0.8750\n",
      "Epoch 184/200\n",
      "56/56 [==============================] - 0s 62us/step - loss: 0.3202 - accuracy: 0.8036\n",
      "Epoch 185/200\n",
      "56/56 [==============================] - 0s 83us/step - loss: 0.2714 - accuracy: 0.8929\n",
      "Epoch 186/200\n",
      "56/56 [==============================] - 0s 59us/step - loss: 0.3251 - accuracy: 0.8393\n",
      "Epoch 187/200\n",
      "56/56 [==============================] - 0s 50us/step - loss: 0.2354 - accuracy: 0.9286\n",
      "Epoch 188/200\n",
      "56/56 [==============================] - 0s 103us/step - loss: 0.3194 - accuracy: 0.8571\n",
      "Epoch 189/200\n",
      "56/56 [==============================] - 0s 71us/step - loss: 0.3000 - accuracy: 0.8750\n",
      "Epoch 190/200\n",
      "56/56 [==============================] - 0s 141us/step - loss: 0.2708 - accuracy: 0.9107\n",
      "Epoch 191/200\n",
      "56/56 [==============================] - 0s 89us/step - loss: 0.3346 - accuracy: 0.8929\n",
      "Epoch 192/200\n",
      "56/56 [==============================] - 0s 67us/step - loss: 0.2571 - accuracy: 0.9286\n",
      "Epoch 193/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.2526 - accuracy: 0.8750\n",
      "Epoch 194/200\n",
      "56/56 [==============================] - 0s 52us/step - loss: 0.2845 - accuracy: 0.8393\n",
      "Epoch 195/200\n",
      "56/56 [==============================] - 0s 64us/step - loss: 0.2873 - accuracy: 0.8571\n",
      "Epoch 196/200\n",
      "56/56 [==============================] - 0s 44us/step - loss: 0.2908 - accuracy: 0.8929\n",
      "Epoch 197/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.3028 - accuracy: 0.8571\n",
      "Epoch 198/200\n",
      "56/56 [==============================] - 0s 47us/step - loss: 0.2950 - accuracy: 0.8571\n",
      "Epoch 199/200\n",
      "56/56 [==============================] - 0s 57us/step - loss: 0.3319 - accuracy: 0.8750\n",
      "Epoch 200/200\n",
      "56/56 [==============================] - 0s 59us/step - loss: 0.2523 - accuracy: 0.9464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fbd129c3d90>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(50,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))\n",
    "model.compile(optimizer='Adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding More Data and Beginning Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2.]\n",
      "171 total new samples\n"
     ]
    }
   ],
   "source": [
    "dabDataset = np.load('data/more-dabs.npy')\n",
    "tposeDataset = np.load('data/more-tposes.npy')\n",
    "otherDataset = np.load('data/more-other.npy')\n",
    "labels1 = np.zeros(len(otherDataset))\n",
    "labels1 = np.append(labels1, np.full((len(dabDataset)), 1))\n",
    "labels1 = np.append(labels1, np.full((len(tposeDataset)), 2))\n",
    "print(labels1)\n",
    "print(\"%i total new samples\" % len(labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 25, 3)\n",
      "(171, 25, 2)\n",
      "(171, 50)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = np.append(otherDataset, dabDataset, axis=0)\n",
    "dataset1 = np.append(dataset1, tposeDataset, axis=0)\n",
    "X1, y1 = shuffle(dataset1, labels1)\n",
    "y1 = to_categorical(y1, 3)\n",
    "print(X1.shape)\n",
    "X1[:,:,0] = X1[:,:,0] / 720\n",
    "X1[:,:,1] = X1[:,:,1] / 1280\n",
    "X1 = X1[:,:,:2]\n",
    "print(X1.shape)\n",
    "X1 = X1.reshape(len(X1), 50)    \n",
    "print(X1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "171/171 [==============================] - 0s 817us/step - loss: 1.1506 - accuracy: 0.3977\n",
      "Epoch 2/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 1.1650 - accuracy: 0.3801\n",
      "Epoch 3/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 1.1043 - accuracy: 0.3918\n",
      "Epoch 4/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 1.1017 - accuracy: 0.3977\n",
      "Epoch 5/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 1.0634 - accuracy: 0.3801\n",
      "Epoch 6/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.9900 - accuracy: 0.5380\n",
      "Epoch 7/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.9947 - accuracy: 0.4912\n",
      "Epoch 8/200\n",
      "171/171 [==============================] - 0s 60us/step - loss: 1.0302 - accuracy: 0.4503\n",
      "Epoch 9/200\n",
      "171/171 [==============================] - 0s 50us/step - loss: 0.9533 - accuracy: 0.5906\n",
      "Epoch 10/200\n",
      "171/171 [==============================] - 0s 49us/step - loss: 0.9815 - accuracy: 0.5088\n",
      "Epoch 11/200\n",
      "171/171 [==============================] - 0s 54us/step - loss: 0.9358 - accuracy: 0.5731\n",
      "Epoch 12/200\n",
      "171/171 [==============================] - 0s 59us/step - loss: 0.9097 - accuracy: 0.5789\n",
      "Epoch 13/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.9493 - accuracy: 0.5146\n",
      "Epoch 14/200\n",
      "171/171 [==============================] - 0s 52us/step - loss: 0.8765 - accuracy: 0.6140\n",
      "Epoch 15/200\n",
      "171/171 [==============================] - 0s 66us/step - loss: 0.8655 - accuracy: 0.6140\n",
      "Epoch 16/200\n",
      "171/171 [==============================] - 0s 55us/step - loss: 0.8718 - accuracy: 0.6082\n",
      "Epoch 17/200\n",
      "171/171 [==============================] - 0s 60us/step - loss: 0.8780 - accuracy: 0.5965\n",
      "Epoch 18/200\n",
      "171/171 [==============================] - 0s 64us/step - loss: 0.8196 - accuracy: 0.6550\n",
      "Epoch 19/200\n",
      "171/171 [==============================] - 0s 68us/step - loss: 0.7922 - accuracy: 0.6316\n",
      "Epoch 20/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.7818 - accuracy: 0.6725\n",
      "Epoch 21/200\n",
      "171/171 [==============================] - 0s 50us/step - loss: 0.7933 - accuracy: 0.6433\n",
      "Epoch 22/200\n",
      "171/171 [==============================] - 0s 61us/step - loss: 0.7709 - accuracy: 0.6959\n",
      "Epoch 23/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.7785 - accuracy: 0.6784\n",
      "Epoch 24/200\n",
      "171/171 [==============================] - 0s 38us/step - loss: 0.7445 - accuracy: 0.7135\n",
      "Epoch 25/200\n",
      "171/171 [==============================] - 0s 61us/step - loss: 0.7130 - accuracy: 0.7485\n",
      "Epoch 26/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.7177 - accuracy: 0.7135\n",
      "Epoch 27/200\n",
      "171/171 [==============================] - 0s 49us/step - loss: 0.7596 - accuracy: 0.6784\n",
      "Epoch 28/200\n",
      "171/171 [==============================] - 0s 59us/step - loss: 0.7091 - accuracy: 0.7135\n",
      "Epoch 29/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.6479 - accuracy: 0.7719\n",
      "Epoch 30/200\n",
      "171/171 [==============================] - 0s 48us/step - loss: 0.6127 - accuracy: 0.8070\n",
      "Epoch 31/200\n",
      "171/171 [==============================] - 0s 47us/step - loss: 0.6317 - accuracy: 0.7368\n",
      "Epoch 32/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.6049 - accuracy: 0.7953\n",
      "Epoch 33/200\n",
      "171/171 [==============================] - 0s 54us/step - loss: 0.6023 - accuracy: 0.7895\n",
      "Epoch 34/200\n",
      "171/171 [==============================] - 0s 53us/step - loss: 0.5617 - accuracy: 0.7895\n",
      "Epoch 35/200\n",
      "171/171 [==============================] - 0s 90us/step - loss: 0.6283 - accuracy: 0.7310\n",
      "Epoch 36/200\n",
      "171/171 [==============================] - 0s 55us/step - loss: 0.5837 - accuracy: 0.7836\n",
      "Epoch 37/200\n",
      "171/171 [==============================] - 0s 71us/step - loss: 0.5429 - accuracy: 0.8012\n",
      "Epoch 38/200\n",
      "171/171 [==============================] - 0s 79us/step - loss: 0.5143 - accuracy: 0.8246\n",
      "Epoch 39/200\n",
      "171/171 [==============================] - 0s 67us/step - loss: 0.5448 - accuracy: 0.8363\n",
      "Epoch 40/200\n",
      "171/171 [==============================] - 0s 84us/step - loss: 0.4946 - accuracy: 0.8246\n",
      "Epoch 41/200\n",
      "171/171 [==============================] - 0s 55us/step - loss: 0.4395 - accuracy: 0.8772\n",
      "Epoch 42/200\n",
      "171/171 [==============================] - 0s 65us/step - loss: 0.4571 - accuracy: 0.8363\n",
      "Epoch 43/200\n",
      "171/171 [==============================] - 0s 74us/step - loss: 0.4033 - accuracy: 0.8596\n",
      "Epoch 44/200\n",
      "171/171 [==============================] - 0s 70us/step - loss: 0.4970 - accuracy: 0.8012\n",
      "Epoch 45/200\n",
      "171/171 [==============================] - 0s 66us/step - loss: 0.3911 - accuracy: 0.8538\n",
      "Epoch 46/200\n",
      "171/171 [==============================] - 0s 55us/step - loss: 0.4045 - accuracy: 0.8596\n",
      "Epoch 47/200\n",
      "171/171 [==============================] - 0s 60us/step - loss: 0.3606 - accuracy: 0.9064\n",
      "Epoch 48/200\n",
      "171/171 [==============================] - 0s 63us/step - loss: 0.4457 - accuracy: 0.8012\n",
      "Epoch 49/200\n",
      "171/171 [==============================] - 0s 71us/step - loss: 0.3713 - accuracy: 0.8830\n",
      "Epoch 50/200\n",
      "171/171 [==============================] - 0s 66us/step - loss: 0.4062 - accuracy: 0.8538\n",
      "Epoch 51/200\n",
      "171/171 [==============================] - 0s 50us/step - loss: 0.3907 - accuracy: 0.8713\n",
      "Epoch 52/200\n",
      "171/171 [==============================] - 0s 60us/step - loss: 0.3823 - accuracy: 0.8480\n",
      "Epoch 53/200\n",
      "171/171 [==============================] - 0s 51us/step - loss: 0.3507 - accuracy: 0.9006\n",
      "Epoch 54/200\n",
      "171/171 [==============================] - 0s 51us/step - loss: 0.3545 - accuracy: 0.8830\n",
      "Epoch 55/200\n",
      "171/171 [==============================] - 0s 52us/step - loss: 0.3434 - accuracy: 0.9064\n",
      "Epoch 56/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.3197 - accuracy: 0.9123\n",
      "Epoch 57/200\n",
      "171/171 [==============================] - 0s 53us/step - loss: 0.2924 - accuracy: 0.8830\n",
      "Epoch 58/200\n",
      "171/171 [==============================] - 0s 57us/step - loss: 0.3072 - accuracy: 0.9064\n",
      "Epoch 59/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.2644 - accuracy: 0.9298\n",
      "Epoch 60/200\n",
      "171/171 [==============================] - 0s 52us/step - loss: 0.2598 - accuracy: 0.9064\n",
      "Epoch 61/200\n",
      "171/171 [==============================] - 0s 60us/step - loss: 0.2782 - accuracy: 0.9064\n",
      "Epoch 62/200\n",
      "171/171 [==============================] - 0s 50us/step - loss: 0.2678 - accuracy: 0.9240\n",
      "Epoch 63/200\n",
      "171/171 [==============================] - 0s 54us/step - loss: 0.2839 - accuracy: 0.9064\n",
      "Epoch 64/200\n",
      "171/171 [==============================] - 0s 63us/step - loss: 0.3064 - accuracy: 0.8889\n",
      "Epoch 65/200\n",
      "171/171 [==============================] - 0s 82us/step - loss: 0.2564 - accuracy: 0.9240\n",
      "Epoch 66/200\n",
      "171/171 [==============================] - 0s 73us/step - loss: 0.2666 - accuracy: 0.8889\n",
      "Epoch 67/200\n",
      "171/171 [==============================] - 0s 58us/step - loss: 0.2616 - accuracy: 0.9181\n",
      "Epoch 68/200\n",
      "171/171 [==============================] - 0s 53us/step - loss: 0.2441 - accuracy: 0.9357\n",
      "Epoch 69/200\n",
      "171/171 [==============================] - 0s 59us/step - loss: 0.2297 - accuracy: 0.9357\n",
      "Epoch 70/200\n",
      "171/171 [==============================] - 0s 54us/step - loss: 0.2818 - accuracy: 0.9006\n",
      "Epoch 71/200\n",
      "171/171 [==============================] - 0s 54us/step - loss: 0.2296 - accuracy: 0.9181\n",
      "Epoch 72/200\n",
      "171/171 [==============================] - 0s 57us/step - loss: 0.1971 - accuracy: 0.9298\n",
      "Epoch 73/200\n",
      "171/171 [==============================] - 0s 53us/step - loss: 0.1906 - accuracy: 0.9649\n",
      "Epoch 74/200\n",
      "171/171 [==============================] - 0s 50us/step - loss: 0.2046 - accuracy: 0.9591\n",
      "Epoch 75/200\n",
      "171/171 [==============================] - 0s 54us/step - loss: 0.1654 - accuracy: 0.9649\n",
      "Epoch 76/200\n",
      "171/171 [==============================] - 0s 46us/step - loss: 0.2305 - accuracy: 0.9240\n",
      "Epoch 77/200\n",
      "171/171 [==============================] - 0s 51us/step - loss: 0.1695 - accuracy: 0.9591\n",
      "Epoch 78/200\n",
      "171/171 [==============================] - 0s 53us/step - loss: 0.1804 - accuracy: 0.9532\n",
      "Epoch 79/200\n",
      "171/171 [==============================] - 0s 49us/step - loss: 0.2005 - accuracy: 0.9474\n",
      "Epoch 80/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 51us/step - loss: 0.2204 - accuracy: 0.9181\n",
      "Epoch 81/200\n",
      "171/171 [==============================] - 0s 60us/step - loss: 0.2210 - accuracy: 0.9240\n",
      "Epoch 82/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.2416 - accuracy: 0.9123\n",
      "Epoch 83/200\n",
      "171/171 [==============================] - 0s 51us/step - loss: 0.2020 - accuracy: 0.9591\n",
      "Epoch 84/200\n",
      "171/171 [==============================] - 0s 50us/step - loss: 0.1638 - accuracy: 0.9532\n",
      "Epoch 85/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.1710 - accuracy: 0.9357\n",
      "Epoch 86/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.2051 - accuracy: 0.9532\n",
      "Epoch 87/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.1453 - accuracy: 0.9591\n",
      "Epoch 88/200\n",
      "171/171 [==============================] - 0s 49us/step - loss: 0.1965 - accuracy: 0.9415\n",
      "Epoch 89/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.1748 - accuracy: 0.9415\n",
      "Epoch 90/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.1649 - accuracy: 0.9532\n",
      "Epoch 91/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.1504 - accuracy: 0.9415\n",
      "Epoch 92/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.1463 - accuracy: 0.9532\n",
      "Epoch 93/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.1266 - accuracy: 0.9649\n",
      "Epoch 94/200\n",
      "171/171 [==============================] - 0s 54us/step - loss: 0.1403 - accuracy: 0.9591\n",
      "Epoch 95/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.1425 - accuracy: 0.9708\n",
      "Epoch 96/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.1421 - accuracy: 0.9532\n",
      "Epoch 97/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.1495 - accuracy: 0.9532\n",
      "Epoch 98/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.1343 - accuracy: 0.9532\n",
      "Epoch 99/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.1360 - accuracy: 0.9591\n",
      "Epoch 100/200\n",
      "171/171 [==============================] - 0s 50us/step - loss: 0.1303 - accuracy: 0.9532\n",
      "Epoch 101/200\n",
      "171/171 [==============================] - 0s 47us/step - loss: 0.1334 - accuracy: 0.9474\n",
      "Epoch 102/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.1263 - accuracy: 0.9532\n",
      "Epoch 103/200\n",
      "171/171 [==============================] - 0s 47us/step - loss: 0.1357 - accuracy: 0.9415\n",
      "Epoch 104/200\n",
      "171/171 [==============================] - 0s 46us/step - loss: 0.1082 - accuracy: 0.9708\n",
      "Epoch 105/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.1179 - accuracy: 0.9708\n",
      "Epoch 106/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.1011 - accuracy: 0.9942\n",
      "Epoch 107/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.1022 - accuracy: 0.9708\n",
      "Epoch 108/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0956 - accuracy: 0.9766\n",
      "Epoch 109/200\n",
      "171/171 [==============================] - 0s 38us/step - loss: 0.1286 - accuracy: 0.9591\n",
      "Epoch 110/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.0940 - accuracy: 0.9708\n",
      "Epoch 111/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.0951 - accuracy: 0.9883\n",
      "Epoch 112/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.1087 - accuracy: 0.9825\n",
      "Epoch 113/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.1372 - accuracy: 0.9591\n",
      "Epoch 114/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0925 - accuracy: 0.9708\n",
      "Epoch 115/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.1032 - accuracy: 0.9649\n",
      "Epoch 116/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.0916 - accuracy: 0.9825\n",
      "Epoch 117/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.0891 - accuracy: 0.9766\n",
      "Epoch 118/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.1089 - accuracy: 0.9591\n",
      "Epoch 119/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.0848 - accuracy: 0.9649\n",
      "Epoch 120/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.1143 - accuracy: 0.9825\n",
      "Epoch 121/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.0732 - accuracy: 0.9825\n",
      "Epoch 122/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.1535 - accuracy: 0.9298\n",
      "Epoch 123/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.0808 - accuracy: 0.9825\n",
      "Epoch 124/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0884 - accuracy: 0.9649\n",
      "Epoch 125/200\n",
      "171/171 [==============================] - 0s 49us/step - loss: 0.0802 - accuracy: 0.9883\n",
      "Epoch 126/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.0834 - accuracy: 0.9766\n",
      "Epoch 127/200\n",
      "171/171 [==============================] - 0s 47us/step - loss: 0.0633 - accuracy: 0.9883\n",
      "Epoch 128/200\n",
      "171/171 [==============================] - 0s 47us/step - loss: 0.0790 - accuracy: 0.9766\n",
      "Epoch 129/200\n",
      "171/171 [==============================] - 0s 52us/step - loss: 0.0671 - accuracy: 0.9883\n",
      "Epoch 130/200\n",
      "171/171 [==============================] - 0s 48us/step - loss: 0.0831 - accuracy: 0.9766\n",
      "Epoch 131/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.0774 - accuracy: 0.9825\n",
      "Epoch 132/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.0680 - accuracy: 0.9708\n",
      "Epoch 133/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.0800 - accuracy: 0.9883\n",
      "Epoch 134/200\n",
      "171/171 [==============================] - 0s 51us/step - loss: 0.0792 - accuracy: 0.9708\n",
      "Epoch 135/200\n",
      "171/171 [==============================] - 0s 46us/step - loss: 0.0574 - accuracy: 0.9883\n",
      "Epoch 136/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.0693 - accuracy: 0.9825\n",
      "Epoch 137/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.0850 - accuracy: 0.9649\n",
      "Epoch 138/200\n",
      "171/171 [==============================] - 0s 46us/step - loss: 0.0702 - accuracy: 0.9883\n",
      "Epoch 139/200\n",
      "171/171 [==============================] - 0s 47us/step - loss: 0.0669 - accuracy: 0.9883\n",
      "Epoch 140/200\n",
      "171/171 [==============================] - 0s 46us/step - loss: 0.0576 - accuracy: 0.9766\n",
      "Epoch 141/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.0598 - accuracy: 0.9883\n",
      "Epoch 142/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0703 - accuracy: 0.9825\n",
      "Epoch 143/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0618 - accuracy: 0.9825\n",
      "Epoch 144/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.0479 - accuracy: 0.9942\n",
      "Epoch 145/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0506 - accuracy: 0.9942\n",
      "Epoch 146/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.0768 - accuracy: 0.9708\n",
      "Epoch 147/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0762 - accuracy: 0.9825\n",
      "Epoch 148/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0442 - accuracy: 0.9883\n",
      "Epoch 149/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.0971 - accuracy: 0.9649\n",
      "Epoch 150/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0692 - accuracy: 0.9825\n",
      "Epoch 151/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0669 - accuracy: 0.9825\n",
      "Epoch 152/200\n",
      "171/171 [==============================] - 0s 38us/step - loss: 0.0592 - accuracy: 0.9766\n",
      "Epoch 153/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.0460 - accuracy: 0.9883\n",
      "Epoch 154/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.0949 - accuracy: 0.9708\n",
      "Epoch 155/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0602 - accuracy: 0.9825\n",
      "Epoch 156/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.0513 - accuracy: 0.9883\n",
      "Epoch 157/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0717 - accuracy: 0.9766\n",
      "Epoch 158/200\n",
      "171/171 [==============================] - 0s 35us/step - loss: 0.0430 - accuracy: 0.9883\n",
      "Epoch 159/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - 0s 39us/step - loss: 0.0680 - accuracy: 0.9825\n",
      "Epoch 160/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0566 - accuracy: 0.9825\n",
      "Epoch 161/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0416 - accuracy: 0.9942\n",
      "Epoch 162/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0758 - accuracy: 0.9766\n",
      "Epoch 163/200\n",
      "171/171 [==============================] - 0s 36us/step - loss: 0.0589 - accuracy: 0.9766\n",
      "Epoch 164/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0625 - accuracy: 0.9649\n",
      "Epoch 165/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0549 - accuracy: 0.9766\n",
      "Epoch 166/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "171/171 [==============================] - 0s 36us/step - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "171/171 [==============================] - 0s 37us/step - loss: 0.0517 - accuracy: 0.9883\n",
      "Epoch 169/200\n",
      "171/171 [==============================] - 0s 38us/step - loss: 0.0588 - accuracy: 0.9883\n",
      "Epoch 170/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0332 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0926 - accuracy: 0.9708\n",
      "Epoch 172/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0515 - accuracy: 0.9883\n",
      "Epoch 173/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0302 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "171/171 [==============================] - 0s 37us/step - loss: 0.0334 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "171/171 [==============================] - 0s 40us/step - loss: 0.0518 - accuracy: 0.9825\n",
      "Epoch 176/200\n",
      "171/171 [==============================] - 0s 37us/step - loss: 0.0525 - accuracy: 0.9825\n",
      "Epoch 177/200\n",
      "171/171 [==============================] - 0s 38us/step - loss: 0.0441 - accuracy: 0.9883\n",
      "Epoch 178/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.0520 - accuracy: 0.9825\n",
      "Epoch 179/200\n",
      "171/171 [==============================] - 0s 46us/step - loss: 0.0487 - accuracy: 0.9883\n",
      "Epoch 180/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0288 - accuracy: 0.9942\n",
      "Epoch 181/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.0475 - accuracy: 0.9825\n",
      "Epoch 182/200\n",
      "171/171 [==============================] - 0s 39us/step - loss: 0.0519 - accuracy: 0.9825\n",
      "Epoch 183/200\n",
      "171/171 [==============================] - 0s 38us/step - loss: 0.0419 - accuracy: 0.9942\n",
      "Epoch 184/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.0196 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "171/171 [==============================] - 0s 49us/step - loss: 0.0272 - accuracy: 0.9942\n",
      "Epoch 186/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.0303 - accuracy: 0.9883\n",
      "Epoch 187/200\n",
      "171/171 [==============================] - 0s 48us/step - loss: 0.0335 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "171/171 [==============================] - 0s 47us/step - loss: 0.0504 - accuracy: 0.9825\n",
      "Epoch 189/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.0353 - accuracy: 0.9942\n",
      "Epoch 190/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.0591 - accuracy: 0.9708\n",
      "Epoch 191/200\n",
      "171/171 [==============================] - 0s 48us/step - loss: 0.0322 - accuracy: 0.9942\n",
      "Epoch 192/200\n",
      "171/171 [==============================] - 0s 49us/step - loss: 0.0347 - accuracy: 0.9883\n",
      "Epoch 193/200\n",
      "171/171 [==============================] - 0s 51us/step - loss: 0.0409 - accuracy: 0.9825\n",
      "Epoch 194/200\n",
      "171/171 [==============================] - 0s 43us/step - loss: 0.0422 - accuracy: 0.9942\n",
      "Epoch 195/200\n",
      "171/171 [==============================] - 0s 46us/step - loss: 0.0336 - accuracy: 0.9942\n",
      "Epoch 196/200\n",
      "171/171 [==============================] - 0s 47us/step - loss: 0.0322 - accuracy: 0.9942\n",
      "Epoch 197/200\n",
      "171/171 [==============================] - 0s 45us/step - loss: 0.0463 - accuracy: 0.9883\n",
      "Epoch 198/200\n",
      "171/171 [==============================] - 0s 44us/step - loss: 0.0260 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "171/171 [==============================] - 0s 41us/step - loss: 0.0489 - accuracy: 0.9942\n",
      "Epoch 200/200\n",
      "171/171 [==============================] - 0s 42us/step - loss: 0.0462 - accuracy: 0.9825\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation = 'relu', input_shape = (50,)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
    "model.compile(optimizer = 'Adam',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "history = model.fit(X1, y1, epochs = 200, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59924173, 0.06160351, 0.7543989 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.71635234, 0.08764701, 0.6645556 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.7708483 , 0.18869254, 0.7353909 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.66201735, 0.12128913, 0.6184485 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.6619014 , 0.12130284, 0.6184055 , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.8197582 , 0.11365898, 0.6617935 , ..., 0.        , 0.        ,\n",
       "        0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.4658914, 0.8722467]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_on_batch(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('data/dab-tpose-other.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "modello = keras.models.load_model('data/dab-tpose-other.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dabDataset = np.load('data/test-dabs.npy')\n",
    "dabDataset[:,:,0] = dabDataset[:,:,0] / 720\n",
    "dabDataset[:,:,1] = dabDataset[:,:,1] / 1280\n",
    "dabDataset = dabDataset[:,:,:2]\n",
    "dabDataset = dabDataset.reshape(len(dabDataset), 50)\n",
    "modello.predict_classes(dabDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測結果全是1，從前面我們設定的數字，1代表dabs，預測成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 關於專案分工的部分預計資料前處理和使用模型交給另外兩個人，但費勁了洪荒之力還是做不出來，最後放棄做那些部分，剩下上訓練模型的部分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作者在他自己的blog上發這篇（https://www.makeartwithpython.com/blog/dab-and-tpose-controlled-lights/，裡頭提到了「All of the code, models, and training data are freely available on Github.」，可能在是否能公開發表上有模擬地帶，下次會注意授權問題，並且先寄信詢問。\n",
    "# 模型是做好了，但卻無法使用，由於導入pyopenpose的不成功，無法在python裡呼叫openpose來取得測試資料，沒辦法實際應用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
